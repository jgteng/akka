<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
<title>Default configuration &bull; Akka Documentation</title>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="description" content="Akka is a toolkit for building highly concurrent, distributed, and resilient message-driven applications for Java and Scala."/>
<link rel="canonical" href="https://doc.akka.io/docs/akka/current/general/configuration-reference.html"/>
<script type="text/javascript" src="../lib/jquery/jquery.min.js"></script>
<script type="text/javascript" src="../lib/foundation/dist/js/foundation.min.js"></script>
<link rel="stylesheet" type="text/css" href="../lib/normalize.css/normalize.css"/>
<link rel="stylesheet" type="text/css" href="../lib/foundation/dist/css/foundation.min.css"/>
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/docsearch.js/2/docsearch.min.css" />
<link rel="stylesheet" type="text/css" href="../css/icons.css"/>
<link rel="stylesheet" type="text/css" href="../css/page-6.css"/>
<link rel="stylesheet" type="text/css" href="../css/banner.css"/>
<link rel="shortcut icon" href="../images/favicon.ico" />
<link rel="apple-touch-icon" sizes="180x180" href="../images/apple-touch-icon.png"/>
<link rel="icon" type="image/png" sizes="32x32" href="../images/favicon-32x32.png"/>
<link rel="icon" type="image/png" sizes="16x16" href="../images/favicon-16x16.png"/>
<link rel="manifest" href="../images/manifest.json"/>
<meta name="msapplication-TileImage" content="../images/mstile-150x150.png"/>
<meta name="msapplication-TileColor" content="#15a9ce"/>
<meta name="theme-color" content="#15a9ce"/>
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>
<!-- OneTrust Cookies Consent Notice (Production Standard, akka.io, en-GB) start -->
<script src="https://optanon.blob.core.windows.net/consent/159bb13d-6748-4399-806e-ac28db879785.js" type="text/javascript" charset="UTF-8"></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice (Production Standard, akka.io, en-GB) end -->
<!--Google Analytics-->
<script type="text/plain" class="optanon-category-2">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-21117439-1']);
_gaq.push(['_setDomainName', 'akka.io']);
_gaq.push(['_trackPageview']);
(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})()
</script>
<!-- Google Tag Manager -->
<script type="text/plain" class="optanon-category-2">
(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-KBJGH35');
</script>
<!--Marketo-->
<script type="text/plain" class="optanon-category-3">
(function() {
var didInit = false;
function initMunchkin() {
if(didInit === false) {
didInit = true;
Munchkin.init('558-NCX-702', { 'asyncOnly': true, 'disableClickDelay': true });
}
}
var s = document.createElement('script');
s.type = 'text/javascript';
s.async = true;
s.src = '//munchkin.marketo.net/munchkin.js';
s.onreadystatechange = function() {
if (this.readyState == 'complete' || this.readyState == 'loaded') {
initMunchkin();
}
};
s.onload = initMunchkin;
document.getElementsByTagName('head')[0].appendChild(s);
})();
</script>
</head>

<body id="underlay" data-toggler="nav-open">
<div id="lightbend-banner" class="lightbend-banner akka full-width" data-category="OSS Lightbend Banner Impression" data-label="Akka Banner Impression">
<div class="wrapper">
<div class="brand">
<a class="oss-track-link-label" data-category="OSS Lightbend Banner Clicks" data-label="Lightbend Logo - Akka Banner" href="https://www.lightbend.com/lightbend-platform" target="_blank">
<svg class="lightbend-logo" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 372 80">
<title>Lightbend</title>
<g id="lightbend-reverse">
<path d="M1,59V76a3,3,0,0,0,3,3H88a3,3,0,0,0,3-3V59a167.38,167.38,0,0,1-45,6A167.38,167.38,0,0,1,1,59Z" fill="#fff" />
<path d="M88,1H4A3,3,0,0,0,1,4V53c14.57,4.2,29.65,7,45,7s30.43-2.8,45-7V4A3,3,0,0,0,88,1Z" fill="#fff" />
<g id="original_weight" data-name="original weight">
<path d="M107.2,20.08a2.14,2.14,0,1,1,4.27,0v32h13.6A2,2,0,0,1,127,54a1.94,1.94,0,0,1-1.94,2H109.31a2.15,2.15,0,0,1-2.11-2.16Z" fill="#fff" />
<path d="M135,19.32a2.47,2.47,0,0,1,4.91,0V20A2.47,2.47,0,0,1,135,20Zm.38,10.59a2.08,2.08,0,1,1,4.16,0V54.15a2,2,0,0,1-2.06,2.11,2.08,2.08,0,0,1-2.1-2.11Z" fill="#fff" />
<path d="M150.8,61.44a1.91,1.91,0,0,1-1.08-1.73,2,2,0,0,1,1.89-1.83,1.69,1.69,0,0,1,.92.27,17.63,17.63,0,0,0,9.88,3c6.15,0,10.15-3.4,10.15-9.93v-3.3c-2.43,3.24-5.83,5.89-11,5.89a12.9,12.9,0,0,1-13.12-13.07v-.11a13.21,13.21,0,0,1,24-7.56V29.91a2.07,2.07,0,0,1,2.06-2.11,2.11,2.11,0,0,1,2.1,2.11V51.13c0,4.32-1.29,7.61-3.56,9.88-2.49,2.48-6.21,3.73-10.64,3.73A21.87,21.87,0,0,1,150.8,61.44Zm21.87-20.73V40.6c0-5.72-5-9.45-10.26-9.45s-9.67,3.67-9.67,9.4v.1a9.45,9.45,0,0,0,9.67,9.51C167.7,50.16,172.67,46.32,172.67,40.71Z" fill="#fff" />
<path d="M186.22,18.41a2.08,2.08,0,1,1,4.16,0V32.93a10.57,10.57,0,0,1,9.56-5.45c6.75,0,10.69,4.53,10.69,11.18V54.15a2.08,2.08,0,1,1-4.16,0V39.68c0-5.18-2.81-8.42-7.72-8.42s-8.37,3.51-8.37,8.75V54.15a2,2,0,0,1-2,2.11,2.08,2.08,0,0,1-2.11-2.11Z" fill="#fff" />
<path d="M220.46,48.59V31.74h-2.27a1.89,1.89,0,0,1-1.84-1.83,1.86,1.86,0,0,1,1.84-1.84h2.27V21.48a2.06,2.06,0,0,1,2-2.1,2.14,2.14,0,0,1,2.1,2.1v6.59h7.24a1.91,1.91,0,0,1,1.89,1.84,1.86,1.86,0,0,1-1.89,1.83h-7.24V48.05c0,3.4,1.89,4.64,4.7,4.64a12,12,0,0,0,2.54-.37,1.8,1.8,0,0,1,1.78,1.78,1.73,1.73,0,0,1-1.19,1.62,10.57,10.57,0,0,1-4.1.75C223.86,56.47,220.46,54.26,220.46,48.59Z" fill="#fff" />
<path d="M242.65,18.41a2.08,2.08,0,1,1,4.16,0V33.69c2.27-3.35,5.56-6.21,10.69-6.21,6.7,0,13.34,5.29,13.34,14.47v.11c0,9.12-6.59,14.52-13.34,14.52a12.6,12.6,0,0,1-10.69-5.94v3.51a2.07,2.07,0,0,1-2.05,2.11,2.11,2.11,0,0,1-2.11-2.11Zm23.92,23.7V42c0-6.58-4.53-10.8-9.83-10.8A10.41,10.41,0,0,0,246.65,42v.11c0,6.48,4.91,10.8,10.09,10.8C262.14,52.86,266.57,48.86,266.57,42.11Z" fill="#fff" />
<path d="M290.17,56.64c-7.67,0-13.93-5.89-13.93-14.53V42c0-8,5.67-14.52,13.39-14.52,8.26,0,13,6.75,13,14.15a1.94,1.94,0,0,1-1.95,1.94H280.45c.59,6,4.86,9.45,9.83,9.45a11.4,11.4,0,0,0,8-3.24,1.83,1.83,0,0,1,1.19-.49,1.81,1.81,0,0,1,1.84,1.78,1.78,1.78,0,0,1-.65,1.35A14.2,14.2,0,0,1,290.17,56.64Zm8.26-16.15c-.43-5.07-3.35-9.5-8.91-9.5-4.86,0-8.53,4.05-9.07,9.5Z" fill="#fff" />
<path d="M309.5,29.91a2.08,2.08,0,1,1,4.16,0v3a10.57,10.57,0,0,1,9.56-5.45c6.75,0,10.69,4.53,10.69,11.18V54.15a2.08,2.08,0,1,1-4.16,0V39.68c0-5.18-2.81-8.42-7.72-8.42s-8.37,3.51-8.37,8.75V54.15a2,2,0,0,1-2.05,2.11,2.08,2.08,0,0,1-2.11-2.11Z" fill="#fff" />
<path d="M368.68,54.15a2.08,2.08,0,1,1-4.15,0V50.37c-2.27,3.35-5.57,6.21-10.7,6.21-6.69,0-13.33-5.29-13.33-14.47V42c0-9.12,6.64-14.52,13.33-14.52a12.61,12.61,0,0,1,10.7,5.94v-15a2,2,0,0,1,2.05-2.11,2.07,2.07,0,0,1,2.1,2.11ZM344.76,42v.11c0,6.58,4.59,10.8,9.83,10.8a10.43,10.43,0,0,0,10.1-10.8V42a10.38,10.38,0,0,0-10.1-10.75C349.19,31.2,344.76,35.2,344.76,42Z" fill="#fff" />
</g>
</g>
</svg>
</a>
</div>
<div class="nav">
<a class="banner-btn oss-track-link-label" data-category="OSS Lightbend Banner Clicks" data-label="See how Akka fits into Lightbend Platform [Button]" href="https://www.lightbend.com/akka-part-of-lightbend-platform" target="_blank">
<span>See how Akka fits into</span>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 274 80">
<title>Lightbend Platform</title>
<g id="lightbend-platform-reverse">
<g id="icon">
<path d="M1,59V76a3,3,0,0,0,3,3H88a3,3,0,0,0,3-3V59a167.38,167.38,0,0,1-45,6A167.38,167.38,0,0,1,1,59Z" fill="#fff" />
<path d="M88,1H4A3,3,0,0,0,1,4V53c14.57,4.2,29.65,7,45,7s30.43-2.8,45-7V4A3,3,0,0,0,88,1Z" fill="#fff" />
</g>
<g id="lightbend">
<path d="M104,14.73a1,1,0,1,1,2,0V29.4h6.24a.91.91,0,0,1,.89.92.88.88,0,0,1-.89.89H105a1,1,0,0,1-1-1Z" fill="#fff" />
<path d="M116.77,14.39a1.14,1.14,0,0,1,2.26,0v.32a1.14,1.14,0,0,1-2.26,0Zm.18,4.85a1,1,0,1,1,1.9,0V30.37a.93.93,0,0,1-.94,1,1,1,0,0,1-1-1Z" fill="#fff" />
<path d="M124,33.72a.89.89,0,0,1-.5-.8.91.91,0,0,1,.87-.84.8.8,0,0,1,.42.12,8.05,8.05,0,0,0,4.54,1.39C132.16,33.59,134,32,134,29V27.52a6,6,0,0,1-5,2.7,5.92,5.92,0,0,1-6-6v-.05a6.07,6.07,0,0,1,11-3.47V19.24a.94.94,0,0,1,.94-1,1,1,0,0,1,1,1V29a6.18,6.18,0,0,1-1.64,4.54,6.73,6.73,0,0,1-4.88,1.71A10,10,0,0,1,124,33.72Zm10-9.52v-.05a4.49,4.49,0,0,0-4.7-4.34,4.24,4.24,0,0,0-4.44,4.32v.05a4.34,4.34,0,0,0,4.44,4.36A4.52,4.52,0,0,0,134,24.2Z" fill="#fff" />
<path d="M140.26,14a1,1,0,1,1,1.91,0v6.66a4.84,4.84,0,0,1,4.39-2.5c3.1,0,4.9,2.08,4.9,5.13v7.11a1,1,0,1,1-1.9,0V23.73c0-2.38-1.29-3.87-3.55-3.87a3.77,3.77,0,0,0-3.84,4v6.49a.93.93,0,0,1-.94,1,1,1,0,0,1-1-1Z" fill="#fff" />
<path d="M156,27.82V20.09h-1a.87.87,0,0,1-.84-.85.85.85,0,0,1,.84-.84h1v-3a1,1,0,0,1,.94-1,1,1,0,0,1,1,1v3h3.32a.87.87,0,0,1,.87.84.85.85,0,0,1-.87.85h-3.32v7.48A1.9,1.9,0,0,0,160,29.7a5.31,5.31,0,0,0,1.16-.17.82.82,0,0,1,.82.82.79.79,0,0,1-.54.74,4.9,4.9,0,0,1-1.89.35A3.26,3.26,0,0,1,156,27.82Z" fill="#fff" />
<path d="M166.16,14a1,1,0,1,1,1.91,0v7A5.75,5.75,0,0,1,173,18.13c3.07,0,6.12,2.43,6.12,6.64v.05c0,4.19-3,6.67-6.12,6.67a5.78,5.78,0,0,1-4.91-2.73v1.61a1,1,0,0,1-.94,1,1,1,0,0,1-1-1Zm11,10.88V24.8c0-3-2.08-5-4.51-5A4.78,4.78,0,0,0,168,24.77v.05a4.78,4.78,0,0,0,4.64,5C175.11,29.78,177.14,27.94,177.14,24.85Z" fill="#fff" />
<path d="M188,31.51a6.37,6.37,0,0,1-6.4-6.66V24.8c0-3.7,2.61-6.67,6.15-6.67,3.79,0,5.95,3.1,5.95,6.49a.89.89,0,0,1-.89.89h-9.27A4.47,4.47,0,0,0,188,29.85a5.23,5.23,0,0,0,3.69-1.49.85.85,0,0,1,.54-.22.81.81,0,0,1,.55,1.44A6.52,6.52,0,0,1,188,31.51Zm3.79-7.41c-.2-2.33-1.54-4.36-4.09-4.36-2.23,0-3.91,1.86-4.16,4.36Z" fill="#fff" />
<path d="M196.84,19.24a1,1,0,1,1,1.91,0v1.39a4.84,4.84,0,0,1,4.38-2.5c3.1,0,4.91,2.08,4.91,5.13v7.11a1,1,0,1,1-1.91,0V23.73c0-2.38-1.29-3.87-3.54-3.87a3.77,3.77,0,0,0-3.84,4v6.49a.93.93,0,0,1-.94,1,1,1,0,0,1-1-1Z" fill="#fff" />
<path d="M224,30.37a1,1,0,1,1-1.91,0V28.64a5.77,5.77,0,0,1-4.9,2.85,6.25,6.25,0,0,1-6.13-6.64V24.8a6.29,6.29,0,0,1,6.13-6.67,5.78,5.78,0,0,1,4.9,2.73V14a.93.93,0,0,1,.94-1,1,1,0,0,1,1,1Zm-11-5.6v.05a4.64,4.64,0,0,0,4.51,5,4.79,4.79,0,0,0,4.64-5v-.05a4.76,4.76,0,0,0-4.64-4.93C215.05,19.84,213,21.67,213,24.77Z" fill="#fff" />
</g>
<path d="M103.36,41H114.8c6.68,0,10.72,4,10.72,9.68v.08c0,6.48-5,9.84-11.32,9.84h-4.68V69h-6.16Zm11,14.12c3.08,0,4.88-1.84,4.88-4.24V50.8c0-2.76-1.92-4.24-5-4.24h-4.76v8.56Z" fill="#fff" />
<path d="M128.89,39.8H135V69h-6.08Z" fill="#fff" />
<path d="M138.75,62.84v-.08c0-4.68,3.56-6.84,8.64-6.84a15.23,15.23,0,0,1,5.24.88v-.36c0-2.52-1.56-3.92-4.6-3.92a15.77,15.77,0,0,0-5.92,1.16L140.59,49a18.92,18.92,0,0,1,8.32-1.72c3.32,0,5.72.88,7.24,2.4s2.32,4,2.32,6.84V69h-5.88V66.68a8.24,8.24,0,0,1-6.48,2.72C142.07,69.4,138.75,67.08,138.75,62.84Zm14-1.4V60.36a9.43,9.43,0,0,0-3.88-.8c-2.6,0-4.2,1-4.2,3v.08c0,1.64,1.36,2.6,3.32,2.6C150.79,65.2,152.71,63.64,152.71,61.44Z" fill="#fff" />
<path d="M164,62.92V52.76h-2.56v-5.2H164V42.08h6.08v5.48h5v5.2h-5v9.16c0,1.4.6,2.08,2,2.08a6.18,6.18,0,0,0,3-.76v4.88a9,9,0,0,1-4.8,1.24C166.51,69.36,164,67.88,164,62.92Z" fill="#fff" />
<path d="M180.43,52.76h-2.52v-5h2.52V46.4a7,7,0,0,1,1.72-5.19,6.63,6.63,0,0,1,4.92-1.68,13.5,13.5,0,0,1,4.32.59v5a7.7,7.7,0,0,0-2.76-.52c-1.4,0-2.2.72-2.2,2.32v.84h4.92v5h-4.84V69h-6.08Z" fill="#fff" />
<path d="M192.84,58.4v-.08c0-6.16,5-11.16,11.64-11.16S216,52.08,216,58.24v.08c0,6.16-5,11.16-11.64,11.16S192.84,64.56,192.84,58.4Zm17.2,0v-.08a5.7,5.7,0,0,0-5.64-5.92c-3.48,0-5.56,2.68-5.56,5.84v.08a5.7,5.7,0,0,0,5.64,5.92C208,64.24,210,61.56,210,58.4Z" fill="#fff" />
<path d="M219.89,47.56H226v4.32c1.24-3,3.24-4.88,6.84-4.72v6.36h-.32c-4,0-6.52,2.44-6.52,7.56V69h-6.08Z" fill="#fff" />
<path d="M235.8,47.56h6.08v3a7.66,7.66,0,0,1,6.32-3.44,6.42,6.42,0,0,1,6,3.4,8.83,8.83,0,0,1,7-3.4c4.52,0,7.24,2.72,7.24,7.88V69h-6.08V57c0-2.88-1.28-4.36-3.56-4.36S255.2,54.16,255.2,57V69h-6.08V57c0-2.88-1.28-4.36-3.56-4.36s-3.68,1.48-3.68,4.36V69H235.8Z" fill="#fff" />
</g>
</svg>
</a>
<div class="drop-down">
<svg class="svg-chevon-circle-down" version="1.1" id="Chevron_circled_down" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 20 20" enable-background="new 0 0 20 20" xml:space="preserve">
<path fill="#ffffff" d="M12.505,8.698L10,11L7.494,8.698c-0.198-0.196-0.518-0.196-0.718,0c-0.197,0.196-0.197,0.515,0,0.71l2.864,2.807
c0.199,0.196,0.52,0.196,0.717,0l2.864-2.807c0.199-0.195,0.198-0.514,0-0.71C13.024,8.502,12.704,8.502,12.505,8.698z M10,0.4
c-5.302,0-9.6,4.298-9.6,9.6c0,5.303,4.298,9.6,9.6,9.6s9.6-4.297,9.6-9.6C19.6,4.698,15.302,0.4,10,0.4z M10,18.354
c-4.615,0-8.354-3.74-8.354-8.354c0-4.614,3.739-8.354,8.354-8.354c4.613,0,8.354,3.74,8.354,8.354
C18.354,14.614,14.613,18.354,10,18.354z" />
</svg>
<div class="drop-down-content">
<div class="lightbend-family">
<a href="https://www.lagomframework.com" class="lagom oss-track-link-label" data-category="OSS Lightbend Banner Clicks" data-label="Lagom - Logo Tag Line - Akka Banner">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 752 192">
<title>Lagom Framework</title>
<g>
<g id="Lagom">
<path d="M291.58,31.79h19.83v87.92c0,8.1,2.65,11.57,9.92,11.57a21.37,21.37,0,0,0,5.95-.66V148.3a35.73,35.73,0,0,1-9.42,1c-17.52,0-26.28-8.92-26.28-26.94Z" fill="#652b7c" />
<path d="M398.34,75.75V63.69h19.83v58.17c0,7.1,1.65,9.75,6.11,9.75,1.16,0,2.64-.17,4.13-.33v16a28.83,28.83,0,0,1-9.75,1.32c-4.79,0-8.59-.83-11.57-2.65a15.32,15.32,0,0,1-6.77-10.08C394.53,144.66,385,149,371.73,149A39.59,39.59,0,0,1,342,136.4c-7.93-8.43-11.89-18.67-11.89-31.07s4-22.64,11.89-30.9a39.59,39.59,0,0,1,29.75-12.56C385.12,61.87,395.2,67.82,398.34,75.75Zm-5.95,47.76a24.32,24.32,0,0,0,7.43-18.18,24.34,24.34,0,0,0-7.43-18.18,24.71,24.71,0,0,0-18-7.27,23.94,23.94,0,0,0-17.68,7.27c-4.63,4.8-6.94,10.91-6.94,18.18s2.31,13.39,6.94,18.18a23.94,23.94,0,0,0,17.68,7.27A24.71,24.71,0,0,0,392.39,123.51Z" fill="#652b7c" />
<path d="M495.67,63.69H515.5v69.4c0,20-2.81,32.23-14.05,41-7.93,6.11-17.68,9.25-29.41,9.25-15.54,0-28.92-4-40.32-12.06l9.58-14.71a50.5,50.5,0,0,0,28.59,9.09q11.66,0,18.34-5c5.29-3.8,7.94-10.91,7.94-21.15v-4.13c-4,7.1-13.89,12.23-27.11,12.23a40.51,40.51,0,0,1-29.74-12.23c-7.93-8.1-11.9-18.35-11.9-30.41s4-22.31,12.06-30.57a39.23,39.23,0,0,1,29.58-12.56c13.72,0,23.8,5.78,26.61,13.88ZM489.72,123a24.16,24.16,0,0,0,7.44-18,23.84,23.84,0,0,0-7.44-17.85,24.69,24.69,0,0,0-18-7.27A23.92,23.92,0,0,0,454,87.15,24.7,24.7,0,0,0,447.09,105,25,25,0,0,0,454,123a23.75,23.75,0,0,0,17.68,7.11C478.81,130.12,484.93,127.81,489.72,123Z" fill="#652b7c" />
<path d="M522.44,105.33a42.06,42.06,0,0,1,13.22-31.4c8.76-8.43,19.5-12.72,32.22-12.72s23.47,4.29,32.23,12.72a42.06,42.06,0,0,1,13.22,31.4,42,42,0,0,1-13.22,31.4c-8.76,8.43-19.5,12.72-32.23,12.72s-23.46-4.29-32.22-12.72A42,42,0,0,1,522.44,105.33ZM586.23,124a25.68,25.68,0,0,0,7.43-18.68,25,25,0,0,0-7.43-18.51,26.13,26.13,0,0,0-36.85,0,25.58,25.58,0,0,0-7.27,18.51A26.25,26.25,0,0,0,549.38,124a26.56,26.56,0,0,0,36.85,0Z" fill="#652b7c" />
<path d="M620.6,147V63.69h19.67v11.9C643.74,67.49,652,62,662.58,62,674,62,681.91,66.83,686,76.58,690.84,66.83,699.76,62,712.81,62c18,0,28.43,12.72,28.43,33.38v26.27c0,6.45,1.15,8.76,5.62,8.76a15,15,0,0,0,2.81-.33v16.69a28.48,28.48,0,0,1-8.6,1c-13.05,0-19.5-7.27-19.5-21.81V98.23c0-11.41-5.28-18.51-14.54-18.51s-16,8.09-16,19.33V147H671.34V98.23c0-11.41-5.46-18.51-14.88-18.51-9.25,0-16.19,8.09-16.19,19.33V147Z" fill="#652b7c" />
</g>
<g id="Icon">
<path d="M261,84l-70,34,70,34S260.78,84.27,261,84Z" fill="#652b7c" />
<polygon points="121 152 191 118 121 84 121 152" fill="#652b7c" />
<path d="M191,118l70,34c-.27,0-41.76,25-60.63,36.24a17.63,17.63,0,0,1-18,0C163.47,177,121,152,121,152Z" fill="#421540" />
<path d="M200.23,47.65C219.09,58.88,261,84,261,84l-70,34L121,84c.27,0,42.31-25.12,61.18-36.36A17.67,17.67,0,0,1,200.23,47.65Z" fill="#bf97c6" />
<path d="M145,20.58l-35,17,35,17S144.89,20.72,145,20.58Z" fill="#652b7c" />
<polygon points="75 54.58 110 37.58 75 20.58 75 54.58" fill="#652b7c" />
<path d="M110,37.58l35,17c-.14,0-20.88,12.5-30.31,18.12a8.81,8.81,0,0,1-9,0C96.23,67.08,75,54.58,75,54.58Z" fill="#421540" />
<path d="M114.61,2.4C124,8,145,20.58,145,20.58l-35,17-35-17c.14,0,21.16-12.56,30.59-18.18A8.84,8.84,0,0,1,114.61,2.4Z" fill="#bf97c6" />
<path d="M101,91,51,115.54l50,24.53S100.84,91.21,101,91Z" fill="#652b7c" />
<polygon points="1 140.07 51 115.54 1 91.02 1 140.07" fill="#652b7c" />
<path d="M51,115.54l50,24.53c-.19,0-29.83,18-43.3,26.14a12.48,12.48,0,0,1-12.89,0C31.34,158.1,1,140.07,1,140.07Z" fill="#421540" />
<path d="M57.59,64.79C71.06,72.9,101,91,101,91L51,115.54,1,91c.19,0,30.22-18.12,43.7-26.23A12.48,12.48,0,0,1,57.59,64.79Z" fill="#bf97c6" />
</g>
</g>
</svg>
<span>Opinionated Microservices Framework</span>
</a>
<a href="https://www.playframework.com" class="play oss-track-link-label" data-category="OSS Lightbend Banner Clicks" data-label="Play - Logo Tag Line - Akka Banner">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 517 270">
<title>Play Framework</title>
<path d="M36.92,26.44l6.19-6.16a23,23,0,0,1,33.68,1.3l85.77,100a23,23,0,0,1-.22,30.17l-85.5,96.91a23,23,0,0,1-33.49,1.05l-6.17-6.17a23,23,0,0,1-1.4-31l51.16-61.39a23,23,0,0,0,.29-29.08l-52-65A23,23,0,0,1,36.92,26.44Z" fill="#92d13d" />
<path d="M86.94,151.18,35.78,212.57a23,23,0,0,0,1.4,31l6.17,6.17a23,23,0,0,0,33.49-1.05l18.51-21a101.68,101.68,0,0,0,10.89-45.91A101.62,101.62,0,0,0,90,126.54,23,23,0,0,1,86.94,151.18Z" fill="#49691f" />
<path d="M206.64,209.51H186.72V93.81h19.92v12.12c2.82-8.13,13-13.94,26.72-13.94,11.79,0,21.75,4.15,29.72,12.61,8.13,8.3,12.12,18.59,12.12,31s-4,22.75-12.12,31.21c-8,8.3-17.93,12.45-29.72,12.45-13.77,0-23.9-5.81-26.72-13.94Zm5.81-92.13a26.46,26.46,0,0,0,0,36.52,25.42,25.42,0,0,0,18.26,7.31,23.36,23.36,0,0,0,17.59-7.31c4.82-4.81,7.14-11,7.14-18.26s-2.32-13.44-7.14-18.26a23.39,23.39,0,0,0-17.59-7.3A25.46,25.46,0,0,0,212.45,117.38Z" fill="#49691f" />
<path d="M282,61.77h19.92v88.32c0,8.13,2.66,11.62,10,11.62a21.11,21.11,0,0,0,6-.67V178.8a35.53,35.53,0,0,1-9.46,1c-17.6,0-26.4-9-26.4-27.06Z" fill="#49691f" />
<path d="M385.25,105.93V93.81h19.92v58.43c0,7.14,1.66,9.8,6.14,9.8,1.17,0,2.66-.17,4.16-.33v16.1a28.82,28.82,0,0,1-9.8,1.33c-4.81,0-8.63-.83-11.62-2.66a15.41,15.41,0,0,1-6.81-10.13c-5.8,8.8-15.43,13.12-28.71,13.12a39.74,39.74,0,0,1-29.88-12.62c-8-8.46-12-18.76-12-31.21s4-22.74,12-31A39.77,39.77,0,0,1,358.53,92C372,92,382.1,98,385.25,105.93Zm-6,48a24.39,24.39,0,0,0,7.47-18.26,24.42,24.42,0,0,0-7.47-18.26,24.82,24.82,0,0,0-18.1-7.3,24.05,24.05,0,0,0-17.76,7.3c-4.65,4.82-7,11-7,18.26s2.32,13.45,7,18.26a24,24,0,0,0,17.76,7.31A24.79,24.79,0,0,0,379.28,153.9Z" fill="#49691f" />
<path d="M422.36,194.24a29.76,29.76,0,0,0,9.29,1.33,13.13,13.13,0,0,0,7.31-1.83c1.82-1.16,3.48-3.65,4.81-7.13l2.16-6-35-86.82H431l24.57,63.08,23.07-63.08h20.09L461.2,191.09q-3.74,9.71-9,14.94c-5,4.65-11.62,7-20.09,7a34.91,34.91,0,0,1-9.79-1.33Z" fill="#49691f" />
</svg>
<span>High velocity<br> web framework</span>
</a>
<a href="https://www.scala-lang.org" class="scala oss-track-link-label" data-category="OSS Lightbend Banner Clicks" data-label="Scala - Logo Tag Line - Akka Banner">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 590 270">
<title>Scala</title>
<path d="M200.7,142.39c6,11.79,15.6,17.6,29.05,17.6,14.44,0,19.59-7.64,19.59-15.11,0-5.15-1.83-8.63-6.64-11.79-4.82-3.32-8.3-4.81-16.93-8-10.63-4-16.77-7-23.41-12.29-6.64-5.48-9.79-13-9.79-22.74a28.28,28.28,0,0,1,10.29-22.58c7-5.81,15.44-8.63,25.56-8.63,15.77,0,27.72,6.31,35.69,18.76L249.34,87.78c-4.48-6.81-11.29-10.3-20.59-10.3-9.13,0-15.77,5.15-15.77,12.29,0,4.81,2,7.14,4.82,10,1.82,1.33,6.47,3.32,8.63,4.48l6,2.32,6.8,2.66c11,4.48,18.76,9.3,23.57,14.44s7.31,12.12,7.31,20.75c0,20.42-14.11,34.2-40.51,34.2-21.41,0-37.18-10-44.48-26.4Z" fill="#380d09" />
<path d="M354.25,104.71,342,117.49a28.14,28.14,0,0,0-21.24-9.13,25,25,0,0,0-18.43,7.47,27.76,27.76,0,0,0,0,37.52,25,25,0,0,0,18.43,7.47A28.14,28.14,0,0,0,342,151.69l12.29,12.78c-9,9.63-20.09,14.44-33.53,14.44-12.79,0-23.58-4.15-32.37-12.62s-13.12-19.09-13.12-31.7,4.32-23.08,13.12-31.54,19.58-12.78,32.37-12.78C334.16,90.27,345.28,95.08,354.25,104.71Z" fill="#380d09" />
<path d="M393.88,125.62C408,124.3,413,122.47,413,116c0-5.15-4.64-9.13-13.94-9.13q-13.44,0-22.41,10.95l-12.28-10.46c8.13-11.45,19.58-17.09,34.36-17.09,20.75,0,33.7,10,33.7,27.05v37c0,5.81,2.15,6.48,7,6.48h.5v15.43c-2,1.17-5.15,1.83-9.3,1.83-4.48,0-8-1.33-10.62-4a14.06,14.06,0,0,1-3-5.48c-5.81,6.8-15.27,10.29-28.39,10.29-18.42,0-30.87-10.13-30.87-25.4C357.7,136.41,369.15,127.78,393.88,125.62ZM391.56,162c13.28,0,21.41-6,21.41-16.6v-9.3a9.75,9.75,0,0,1-4.14,2.49c-3.82,1.33-6.31,1.66-14.28,2.49-11.62,1.33-17.43,5-17.43,10.79C377.12,158.33,382.43,162,391.56,162Z" fill="#380d09" />
<path d="M444.84,60.88h19.92V149.2c0,8.13,2.66,11.62,10,11.62a21.15,21.15,0,0,0,6-.67v17.76a35.56,35.56,0,0,1-9.47,1c-17.59,0-26.39-9-26.39-27.06Z" fill="#380d09" />
<path d="M521.71,125.62c14.11-1.32,19.09-3.15,19.09-9.62,0-5.15-4.64-9.13-13.94-9.13q-13.44,0-22.41,10.95l-12.28-10.46c8.13-11.45,19.58-17.09,34.36-17.09,20.75,0,33.7,10,33.7,27.05v37c0,5.81,2.15,6.48,7,6.48h.5v15.43c-2,1.17-5.15,1.83-9.3,1.83-4.48,0-8-1.33-10.62-4a13.94,13.94,0,0,1-3-5.48c-5.81,6.8-15.27,10.29-28.39,10.29-18.42,0-30.87-10.13-30.87-25.4C485.53,136.41,497,127.78,521.71,125.62ZM519.39,162c13.28,0,21.41-6,21.41-16.6v-9.3a9.73,9.73,0,0,1-4.15,2.49c-3.81,1.33-6.3,1.66-14.27,2.49-11.62,1.33-17.43,5-17.43,10.79C505,158.33,510.26,162,519.39,162Z" fill="#380d09" />
<path d="M30.55,94.83C32.4,97.38,48,102.19,71.27,107.2c23.27,4.46,47.47,22.07,66.29,16.64,12.73-3.68,26.54-36.47,26.54-41.34V82c0-3.4-2.55-6.13-6.88-8.4-17.75-9.07-21.11-12.41-27.69-10.6C95.37,72.43,35.06,67.61,30.55,94.83Z" fill="#380d09" fill-rule="evenodd" />
<path d="M30.55,161.41C32.4,164,48,168.77,71.27,173.79c26,4.74,48.61,20.19,67.44,14.75,12.73-3.68,25.39-34.58,25.39-39.46v-.48c0-3.39-2.55-6.13-6.88-8.39-13.54-7.2-31.43-15.13-38-13.32C85,136.3,39.26,138.37,30.55,161.41Z" fill="#380d09" fill-rule="evenodd" />
<path d="M30.36,109.14v.48h0A3.73,3.73,0,0,1,30.36,109.14Z" fill="#555" fill-rule="evenodd" />
<path d="M138.66,28.78C107.2,37.87,57.29,43,30.4,43h0V94.35a.8.8,0,0,0,.19.48c18.35,0,75-6,109.18-15.4a129,129,0,0,0,17.49-5.81c4.18-1.88,6.88-3.86,6.88-5.92V15.91C164.1,20.79,151.39,25.11,138.66,28.78Z" fill="#de3423" fill-rule="evenodd" />
<path d="M138.66,95.37c-18.83,5.43-44.24,9.47-67.39,11.83-15.54,1.59-30.06,2.42-40.87,2.42h0v51.31a.8.8,0,0,0,.19.48c18.35,0,75-6,109.18-15.39a130.38,130.38,0,0,0,17.49-5.81c4.18-1.89,6.88-3.86,6.88-5.92V82.5C164.1,87.37,151.39,91.69,138.66,95.37Z" fill="#de3423" fill-rule="evenodd" />
<path d="M138.66,162c-18.83,5.43-44.24,9.46-67.39,11.83-15.56,1.59-30.1,2.42-40.91,2.42V228c18.16,0,75.1-5.95,109.37-15.39,12.63-3.48,24.37-7.44,24.37-11.74V149.08C164.1,154,151.39,158.28,138.66,162Z" fill="#de3423" fill-rule="evenodd" />
</svg>
<span>The JVM language<br> of pragmatism</span>
</a>
<div class="akka">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 658 270">
<title>Akka</title>
<g id="akka-full-color">
<path d="M349.64,105.46V93.34h19.92v58.44c0,7.13,1.66,9.79,6.14,9.79,1.17,0,2.66-.17,4.15-.33v16.1a28.71,28.71,0,0,1-9.79,1.33c-4.81,0-8.63-.83-11.62-2.66a15.41,15.41,0,0,1-6.81-10.12C345.82,174.68,336.2,179,322.92,179A39.74,39.74,0,0,1,293,166.38c-8-8.46-12-18.75-12-31.2s4-22.75,12-31.05a39.77,39.77,0,0,1,29.88-12.61C336.36,91.52,346.49,97.49,349.64,105.46Zm-6,48a24.42,24.42,0,0,0,7.47-18.26,24.39,24.39,0,0,0-7.47-18.26,24.79,24.79,0,0,0-18.1-7.31,24,24,0,0,0-17.76,7.31c-4.65,4.81-7,11-7,18.26s2.32,13.44,7,18.26a24,24,0,0,0,17.76,7.3A24.82,24.82,0,0,0,343.67,153.44Z" fill="#0b5567" />
<path d="M388.48,177V61.31h19.76v67.56l30.87-35.53H462l-32.7,37.35L465.51,177H442.93l-26.39-33.7-8.3,9.3V177Z" fill="#0b5567" />
<path d="M470.82,177V61.31h19.75v67.56l30.88-35.53h22.91l-32.7,37.35L547.84,177H525.27l-26.4-33.7-8.3,9.3V177Z" fill="#0b5567" />
<path d="M607.87,105.46V93.34h19.92v58.44c0,7.13,1.66,9.79,6.14,9.79,1.17,0,2.66-.17,4.15-.33v16.1a28.71,28.71,0,0,1-9.79,1.33c-4.81,0-8.63-.83-11.62-2.66a15.41,15.41,0,0,1-6.81-10.12c-5.81,8.79-15.43,13.11-28.71,13.11a39.74,39.74,0,0,1-29.88-12.62c-8-8.46-12-18.75-12-31.2s4-22.75,12-31.05a39.77,39.77,0,0,1,29.88-12.61C594.59,91.52,604.72,97.49,607.87,105.46Zm-6,48a24.42,24.42,0,0,0,7.47-18.26,24.39,24.39,0,0,0-7.47-18.26,24.79,24.79,0,0,0-18.1-7.31A24,24,0,0,0,566,116.92c-4.65,4.81-7,11-7,18.26s2.32,13.44,7,18.26a24,24,0,0,0,17.76,7.3A24.82,24.82,0,0,0,601.9,153.44Z" fill="#0b5567" />
<path d="M230.26,212.82c35.88,28.67,58.91-57,1.74-72.82-48-13.29-96.33,9.5-144.66,62.74C87.34,202.74,176.67,170,230.26,212.82Z" fill="#0b5567" />
<path d="M88.08,202c34.41-35.69,91.64-75.53,144.9-60.75A46.09,46.09,0,0,1,259.9,160.6L209.48,58.78c-7.2-11.46-25.58-9.15-35.95-.26L40.29,170.07a27.4,27.4,0,0,0-1.56,40.15l0,0a27.4,27.4,0,0,0,36.51,2L88.14,202Z" fill="#15a9ce" />
</g>
</svg>
<span>Actor-based,<br> cloud native toolkit</span>
</div>
<div class="platform">
<span>From the creators of <strong>Akka</strong>, get technology enhancements, monitoring, and expert support with Lightbend Platform.</span>
<a class="oss-track-link-label" data-category="OSS Lightbend Banner Clicks" data-label="See Akka In Lightbend Platform [Button]" href="https://www.lightbend.com/akka-part-of-lightbend-platform" target="_blank">See Akka In Lightbend Platform</a>
</div>
</div>
<div class="title">The Lightbend Family</div>
</div>
</div>
</div>
</div>
</div>
<header class="site-header hide-for-large">
<div class="sticky-header clearfix">
<a href="https://akka.io"><img class="logo" src="../images/akka-logo-reverse.svg"/></a>

<button class="menu-icon float-right" type="button" data-toggle="underlay overlay"></button>
</div>
<div id="overlay" class="overlay-nav" data-toggler="nav-open">
<header class="nav-header">
<div class="nav-header-title">
<h1><a href="../index.html">Akka Documentation</a></h1>
</div>
<div class="nav-header-version">
Version 2.6.3+1-dc0ae30c+20200312-2058
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Language"><option class="group" value="group-scala">Scala</option><option class="group" value="group-java">Java</option></select>
</div>
<div id="overlay-search-container" class="nav-header-search">
<input id="overlay-search" type="search" class="search" placeholder="Search" />
</div>
</header>
<nav class="nav-toc">
<ul>
  <li><a href="../security/index.html" class="page">Security Announcements</a></li>
  <li><a href="../typed/guide/index.html" class="page">Getting Started Guide</a></li>
  <li><a href="../general/index.html" class="page">General Concepts</a>
  <ul>
    <li><a href="../general/terminology.html" class="page">Terminology, Concepts</a></li>
    <li><a href="../general/actor-systems.html" class="page">Actor Systems</a></li>
    <li><a href="../general/actors.html" class="page">What is an Actor?</a></li>
    <li><a href="../general/supervision.html" class="page">Supervision and Monitoring</a></li>
    <li><a href="../general/addressing.html" class="page">Actor References, Paths and Addresses</a></li>
    <li><a href="../general/remoting.html" class="page">Location Transparency</a></li>
    <li><a href="../general/jmm.html" class="page">Akka and the Java Memory Model</a></li>
    <li><a href="../general/message-delivery-reliability.html" class="page">Message Delivery Reliability</a></li>
    <li><a href="../general/configuration.html" class="page">Configuration</a></li>
    <li><a href="../general/configuration-reference.html#default-configuration" class="active page">Default configuration</a>
    <ul>
      <li><a href="../general/configuration-reference.html#akka-actor" class="header">akka-actor</a></li>
      <li><a href="../general/configuration-reference.html#akka-actor-typed" class="header">akka-actor-typed</a></li>
      <li><a href="../general/configuration-reference.html#akka-cluster-typed" class="header">akka-cluster-typed</a></li>
      <li><a href="../general/configuration-reference.html#akka-cluster" class="header">akka-cluster</a></li>
      <li><a href="../general/configuration-reference.html#akka-discovery" class="header">akka-discovery</a></li>
      <li><a href="../general/configuration-reference.html#akka-coordination" class="header">akka-coordination</a></li>
      <li><a href="../general/configuration-reference.html#akka-multi-node-testkit" class="header">akka-multi-node-testkit</a></li>
      <li><a href="../general/configuration-reference.html#akka-persistence-typed" class="header">akka-persistence-typed</a></li>
      <li><a href="../general/configuration-reference.html#akka-persistence" class="header">akka-persistence</a></li>
      <li><a href="../general/configuration-reference.html#akka-persistence-query" class="header">akka-persistence-query</a></li>
      <li><a href="../general/configuration-reference.html#akka-remote-artery" class="header">akka-remote artery</a></li>
      <li><a href="../general/configuration-reference.html#akka-remote-classic-deprecated-" class="header">akka-remote classic (deprecated)</a></li>
      <li><a href="../general/configuration-reference.html#akka-testkit" class="header">akka-testkit</a></li>
      <li><a href="../general/configuration-reference.html#akka-cluster-metrics" class="header">akka-cluster-metrics</a></li>
      <li><a href="../general/configuration-reference.html#akka-cluster-tools" class="header">akka-cluster-tools</a></li>
      <li><a href="../general/configuration-reference.html#akka-cluster-sharding-typed" class="header">akka-cluster-sharding-typed</a></li>
      <li><a href="../general/configuration-reference.html#akka-cluster-sharding" class="header">akka-cluster-sharding</a></li>
      <li><a href="../general/configuration-reference.html#akka-distributed-data" class="header">akka-distributed-data</a></li>
      <li><a href="../general/configuration-reference.html#akka-stream" class="header">akka-stream</a></li>
      <li><a href="../general/configuration-reference.html#akka-stream-testkit" class="header">akka-stream-testkit</a></li>
    </ul></li>
  </ul></li>
  <li><a href="../typed/index.html" class="page">Actors</a></li>
  <li><a href="../typed/index-cluster.html" class="page">Cluster</a></li>
  <li><a href="../typed/index-persistence.html" class="page">Persistence</a></li>
  <li><a href="../stream/index.html" class="page">Streams</a></li>
  <li><a href="../discovery/index.html" class="page">Discovery</a></li>
  <li><a href="../index-utilities.html" class="page">Utilities</a></li>
  <li><a href="../common/other-modules.html" class="page">Other Akka modules</a></li>
  <li><a href="../additional/deploy.html" class="page">Package, Deploy and Run</a></li>
  <li><a href="../project/index.html" class="page">Project Information</a></li>
  <li><a href="../index-classic.html" class="page">Akka Classic</a></li>
</ul>
</nav>
</div>
</header>
<div class="site-content-wrapper">
<aside class="sticky-sidebar show-for-large">
<header class="nav-header sticky-sidebar-header">
<div class="nav-header-title">
<h1><a href="../index.html">Akka Documentation</a></h1>
</div>
<div class="nav-header-version">
Version 2.6.3+1-dc0ae30c+20200312-2058
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Language"><option class="group" value="group-scala">Scala</option><option class="group" value="group-java">Java</option></select>
</div>
<div class="nav-header-search">
<input id="search" type="search" class="search" placeholder="Search" />
</div>
</header>
<nav class="site-nav sticky-sidebar-contents">
<div class="nav-toc">
<ul>
  <li><a href="../security/index.html" class="page">Security Announcements</a></li>
  <li><a href="../typed/guide/index.html" class="page">Getting Started Guide</a></li>
  <li><a href="../general/index.html" class="page">General Concepts</a>
  <ul>
    <li><a href="../general/terminology.html" class="page">Terminology, Concepts</a></li>
    <li><a href="../general/actor-systems.html" class="page">Actor Systems</a></li>
    <li><a href="../general/actors.html" class="page">What is an Actor?</a></li>
    <li><a href="../general/supervision.html" class="page">Supervision and Monitoring</a></li>
    <li><a href="../general/addressing.html" class="page">Actor References, Paths and Addresses</a></li>
    <li><a href="../general/remoting.html" class="page">Location Transparency</a></li>
    <li><a href="../general/jmm.html" class="page">Akka and the Java Memory Model</a></li>
    <li><a href="../general/message-delivery-reliability.html" class="page">Message Delivery Reliability</a></li>
    <li><a href="../general/configuration.html" class="page">Configuration</a></li>
    <li><a href="../general/configuration-reference.html#default-configuration" class="active page">Default configuration</a>
    <ul>
      <li><a href="../general/configuration-reference.html#akka-actor" class="header">akka-actor</a></li>
      <li><a href="../general/configuration-reference.html#akka-actor-typed" class="header">akka-actor-typed</a></li>
      <li><a href="../general/configuration-reference.html#akka-cluster-typed" class="header">akka-cluster-typed</a></li>
      <li><a href="../general/configuration-reference.html#akka-cluster" class="header">akka-cluster</a></li>
      <li><a href="../general/configuration-reference.html#akka-discovery" class="header">akka-discovery</a></li>
      <li><a href="../general/configuration-reference.html#akka-coordination" class="header">akka-coordination</a></li>
      <li><a href="../general/configuration-reference.html#akka-multi-node-testkit" class="header">akka-multi-node-testkit</a></li>
      <li><a href="../general/configuration-reference.html#akka-persistence-typed" class="header">akka-persistence-typed</a></li>
      <li><a href="../general/configuration-reference.html#akka-persistence" class="header">akka-persistence</a></li>
      <li><a href="../general/configuration-reference.html#akka-persistence-query" class="header">akka-persistence-query</a></li>
      <li><a href="../general/configuration-reference.html#akka-remote-artery" class="header">akka-remote artery</a></li>
      <li><a href="../general/configuration-reference.html#akka-remote-classic-deprecated-" class="header">akka-remote classic (deprecated)</a></li>
      <li><a href="../general/configuration-reference.html#akka-testkit" class="header">akka-testkit</a></li>
      <li><a href="../general/configuration-reference.html#akka-cluster-metrics" class="header">akka-cluster-metrics</a></li>
      <li><a href="../general/configuration-reference.html#akka-cluster-tools" class="header">akka-cluster-tools</a></li>
      <li><a href="../general/configuration-reference.html#akka-cluster-sharding-typed" class="header">akka-cluster-sharding-typed</a></li>
      <li><a href="../general/configuration-reference.html#akka-cluster-sharding" class="header">akka-cluster-sharding</a></li>
      <li><a href="../general/configuration-reference.html#akka-distributed-data" class="header">akka-distributed-data</a></li>
      <li><a href="../general/configuration-reference.html#akka-stream" class="header">akka-stream</a></li>
      <li><a href="../general/configuration-reference.html#akka-stream-testkit" class="header">akka-stream-testkit</a></li>
    </ul></li>
  </ul></li>
  <li><a href="../typed/index.html" class="page">Actors</a></li>
  <li><a href="../typed/index-cluster.html" class="page">Cluster</a></li>
  <li><a href="../typed/index-persistence.html" class="page">Persistence</a></li>
  <li><a href="../stream/index.html" class="page">Streams</a></li>
  <li><a href="../discovery/index.html" class="page">Discovery</a></li>
  <li><a href="../index-utilities.html" class="page">Utilities</a></li>
  <li><a href="../common/other-modules.html" class="page">Other Akka modules</a></li>
  <li><a href="../additional/deploy.html" class="page">Package, Deploy and Run</a></li>
  <li><a href="../project/index.html" class="page">Project Information</a></li>
  <li><a href="../index-classic.html" class="page">Akka Classic</a></li>
</ul>
</div>
</nav>
<footer class="nav-footer sticky-sidebar-footer">
<a href="https://akka.io"><img class="logo" src="../images/akka-logo-reverse.svg"/></a>

</footer>
</aside>
<main class="fixed-shift-for-large expanded row">
<section class="site-content small-12 column">
<article class="page-content row">
<div class="small-12 column" id="docs">
<h1><a href="#default-configuration" name="default-configuration" class="anchor"><span class="anchor-link"></span></a>Default configuration</h1>
<p>Each Akka module has a <code>reference.conf</code> file with the default values.</p>
<p>Make your edits/overrides in your <code>application.conf</code>. Don&rsquo;t override default values if you are not sure of the implications. <a href="https://doc.akka.io/docs/akka-enhancements/current/config-checker.html">Akka Config Checker</a> is a useful tool for finding potential configuration issues.</p>
<p>The purpose of <code>reference.conf</code> files is for libraries, like Akka, to define default values that are used if an application doesn&rsquo;t define a more specific value. It&rsquo;s also a good place to document the existence and meaning of the configuration properties. One library must not try to override properties in its own <code>reference.conf</code> for properties originally defined by another library&rsquo;s <code>reference.conf</code>, because the effective value would be nondeterministic when loading the configuration.`</p>
<a id="config-akka-actor"></a>
<h3><a href="#akka-actor" name="akka-actor" class="anchor"><span class="anchor-link"></span></a>akka-actor</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-actor/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">####################################
# Akka Actor Reference Config File #
####################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

# Akka version, checked against the runtime version of Akka. Loaded from generated conf file.
include &quot;version&quot;

akka {
  # Home directory of Akka, modules in the deploy directory will be loaded
  home = &quot;&quot;

  # Loggers to register at boot time (akka.event.Logging$DefaultLogger logs
  # to STDOUT)
  loggers = [&quot;akka.event.Logging$DefaultLogger&quot;]

  # Filter of log events that is used by the LoggingAdapter before
  # publishing log events to the eventStream. It can perform
  # fine grained filtering based on the log source. The default
  # implementation filters on the `loglevel`.
  # FQCN of the LoggingFilter. The Class of the FQCN must implement
  # akka.event.LoggingFilter and have a public constructor with
  # (akka.actor.ActorSystem.Settings, akka.event.EventStream) parameters.
  logging-filter = &quot;akka.event.DefaultLoggingFilter&quot;

  # Specifies the default loggers dispatcher
  loggers-dispatcher = &quot;akka.actor.default-dispatcher&quot;

  # Loggers are created and registered synchronously during ActorSystem
  # start-up, and since they are actors, this timeout is used to bound the
  # waiting time
  logger-startup-timeout = 5s

  # Log level used by the configured loggers (see &quot;loggers&quot;) as soon
  # as they have been started; before that, see &quot;stdout-loglevel&quot;
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = &quot;INFO&quot;

  # Log level for the very basic logger activated during ActorSystem startup.
  # This logger prints the log messages to stdout (System.out).
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  stdout-loglevel = &quot;WARNING&quot;

  # Log the complete configuration at INFO level when the actor system is started.
  # This is useful when you are uncertain of what configuration is used.
  log-config-on-start = off

  # Log at info level when messages are sent to dead letters, or published to
  # eventStream as `DeadLetter`, `Dropped` or `UnhandledMessage`.
  # Possible values:
  # on: all dead letters are logged
  # off: no logging of dead letters
  # n: positive integer, number of dead letters that will be logged
  log-dead-letters = 10

  # Possibility to turn off logging of dead letters while the actor system
  # is shutting down. Logging is only done when enabled by &#39;log-dead-letters&#39;
  # setting.
  log-dead-letters-during-shutdown = off

  # When log-dead-letters is enabled, this will re-enable the logging after configured duration.
  # infinite: suspend the logging forever;
  # or a duration (eg: 5 minutes), after which the logging will be re-enabled.
  log-dead-letters-suspend-duration = 5 minutes

  # List FQCN of extensions which shall be loaded at actor system startup.
  # Library extensions are regular extensions that are loaded at startup and are
  # available for third party library authors to enable auto-loading of extensions when
  # present on the classpath. This is done by appending entries:
  # &#39;library-extensions += &quot;Extension&quot;&#39; in the library `reference.conf`.
  #
  # Should not be set by end user applications in &#39;application.conf&#39;, use the extensions property for that
  #
  library-extensions = ${?akka.library-extensions} [&quot;akka.serialization.SerializationExtension&quot;]

  # List FQCN of extensions which shall be loaded at actor system startup.
  # Should be on the format: &#39;extensions = [&quot;foo&quot;, &quot;bar&quot;]&#39; etc.
  # See the Akka Documentation for more info about Extensions
  extensions = []

  # Toggles whether threads created by this ActorSystem should be daemons or not
  daemonic = off

  # JVM shutdown, System.exit(-1), in case of a fatal error,
  # such as OutOfMemoryError
  jvm-exit-on-fatal-error = on

  # Akka installs JVM shutdown hooks by default, e.g. in CoordinatedShutdown and Artery. This property will
  # not disable user-provided hooks registered using `CoordinatedShutdown#addCancellableJvmShutdownHook`.
  # This property is related to `akka.coordinated-shutdown.run-by-jvm-shutdown-hook` below.
  # This property makes it possible to disable all such hooks if the application itself
  # or a higher level framework such as Play prefers to install the JVM shutdown hook and
  # terminate the ActorSystem itself, with or without using CoordinatedShutdown.
  jvm-shutdown-hooks = on

  # Version must be the same across all modules and if they are different the startup
  # will fail. It&#39;s possible but not recommended, to disable this check, and only log a warning,
  # by setting this property to `off`.
  fail-mixed-versions = on

  # Some modules (remoting only right now) can emit custom events to the Java Flight Recorder if running
  # on JDK 11 or later. If you for some reason do not want that, it can be disabled and switched to no-ops
  # with this toggle.
  java-flight-recorder {
    enabled = true
  }

  actor {

    # Either one of &quot;local&quot;, &quot;remote&quot; or &quot;cluster&quot; or the
    # FQCN of the ActorRefProvider to be used; the below is the built-in default,
    # note that &quot;remote&quot; and &quot;cluster&quot; requires the akka-remote and akka-cluster
    # artifacts to be on the classpath.
    provider = &quot;local&quot;

    # The guardian &quot;/user&quot; will use this class to obtain its supervisorStrategy.
    # It needs to be a subclass of akka.actor.SupervisorStrategyConfigurator.
    # In addition to the default there is akka.actor.StoppingSupervisorStrategy.
    guardian-supervisor-strategy = &quot;akka.actor.DefaultSupervisorStrategy&quot;

    # Timeout for Extension creation and a few other potentially blocking
    # initialization tasks.
    creation-timeout = 20s

    # Serializes and deserializes (non-primitive) messages to ensure immutability,
    # this is only intended for testing.
    serialize-messages = off

    # Serializes and deserializes creators (in Props) to ensure that they can be
    # sent over the network, this is only intended for testing. Purely local deployments
    # as marked with deploy.scope == LocalScope are exempt from verification.
    serialize-creators = off

    # If serialize-messages or serialize-creators are enabled classes that starts with
    # a prefix listed here are not verified.
    no-serialization-verification-needed-class-prefix = [&quot;akka.&quot;]

    # Timeout for send operations to top-level actors which are in the process
    # of being started. This is only relevant if using a bounded mailbox or the
    # CallingThreadDispatcher for a top-level actor.
    unstarted-push-timeout = 10s

    # TypedActor deprecated since 2.6.0.
    typed {
      # Default timeout for the depredated TypedActor (not the new actor APIs in 2.6) methods with non-void return type
      timeout = 5s
    }

    # Mapping between ´deployment.router&#39; short names to fully qualified class names
    router.type-mapping {
      from-code = &quot;akka.routing.NoRouter&quot;
      round-robin-pool = &quot;akka.routing.RoundRobinPool&quot;
      round-robin-group = &quot;akka.routing.RoundRobinGroup&quot;
      random-pool = &quot;akka.routing.RandomPool&quot;
      random-group = &quot;akka.routing.RandomGroup&quot;
      balancing-pool = &quot;akka.routing.BalancingPool&quot;
      smallest-mailbox-pool = &quot;akka.routing.SmallestMailboxPool&quot;
      broadcast-pool = &quot;akka.routing.BroadcastPool&quot;
      broadcast-group = &quot;akka.routing.BroadcastGroup&quot;
      scatter-gather-pool = &quot;akka.routing.ScatterGatherFirstCompletedPool&quot;
      scatter-gather-group = &quot;akka.routing.ScatterGatherFirstCompletedGroup&quot;
      tail-chopping-pool = &quot;akka.routing.TailChoppingPool&quot;
      tail-chopping-group = &quot;akka.routing.TailChoppingGroup&quot;
      consistent-hashing-pool = &quot;akka.routing.ConsistentHashingPool&quot;
      consistent-hashing-group = &quot;akka.routing.ConsistentHashingGroup&quot;
    }

    deployment {

      # deployment id pattern - on the format: /parent/child etc.
      default {

        # The id of the dispatcher to use for this actor.
        # If undefined or empty the dispatcher specified in code
        # (Props.withDispatcher) is used, or default-dispatcher if not
        # specified at all.
        dispatcher = &quot;&quot;

        # The id of the mailbox to use for this actor.
        # If undefined or empty the default mailbox of the configured dispatcher
        # is used or if there is no mailbox configuration the mailbox specified
        # in code (Props.withMailbox) is used.
        # If there is a mailbox defined in the configured dispatcher then that
        # overrides this setting.
        mailbox = &quot;&quot;

        # routing (load-balance) scheme to use
        # - available: &quot;from-code&quot;, &quot;round-robin&quot;, &quot;random&quot;, &quot;smallest-mailbox&quot;,
        #              &quot;scatter-gather&quot;, &quot;broadcast&quot;
        # - or:        Fully qualified class name of the router class.
        #              The class must extend akka.routing.CustomRouterConfig and
        #              have a public constructor with com.typesafe.config.Config
        #              and optional akka.actor.DynamicAccess parameter.
        # - default is &quot;from-code&quot;;
        # Whether or not an actor is transformed to a Router is decided in code
        # only (Props.withRouter). The type of router can be overridden in the
        # configuration; specifying &quot;from-code&quot; means that the values specified
        # in the code shall be used.
        # In case of routing, the actors to be routed to can be specified
        # in several ways:
        # - nr-of-instances: will create that many children
        # - routees.paths: will route messages to these paths using ActorSelection,
        #   i.e. will not create children
        # - resizer: dynamically resizable number of routees as specified in
        #   resizer below
        router = &quot;from-code&quot;

        # number of children to create in case of a router;
        # this setting is ignored if routees.paths is given
        nr-of-instances = 1

        # within is the timeout used for routers containing future calls
        within = 5 seconds

        # number of virtual nodes per node for consistent-hashing router
        virtual-nodes-factor = 10

        tail-chopping-router {
          # interval is duration between sending message to next routee
          interval = 10 milliseconds
        }

        routees {
          # Alternatively to giving nr-of-instances you can specify the full
          # paths of those actors which should be routed to. This setting takes
          # precedence over nr-of-instances
          paths = []
        }

        # To use a dedicated dispatcher for the routees of the pool you can
        # define the dispatcher configuration inline with the property name
        # &#39;pool-dispatcher&#39; in the deployment section of the router.
        # For example:
        # pool-dispatcher {
        #   fork-join-executor.parallelism-min = 5
        #   fork-join-executor.parallelism-max = 5
        # }

        # Routers with dynamically resizable number of routees; this feature is
        # enabled by including (parts of) this section in the deployment
        resizer {

          enabled = off

          # The fewest number of routees the router should ever have.
          lower-bound = 1

          # The most number of routees the router should ever have.
          # Must be greater than or equal to lower-bound.
          upper-bound = 10

          # Threshold used to evaluate if a routee is considered to be busy
          # (under pressure). Implementation depends on this value (default is 1).
          # 0:   number of routees currently processing a message.
          # 1:   number of routees currently processing a message has
          #      some messages in mailbox.
          # &gt; 1: number of routees with at least the configured pressure-threshold
          #      messages in their mailbox. Note that estimating mailbox size of
          #      default UnboundedMailbox is O(N) operation.
          pressure-threshold = 1

          # Percentage to increase capacity whenever all routees are busy.
          # For example, 0.2 would increase 20% (rounded up), i.e. if current
          # capacity is 6 it will request an increase of 2 more routees.
          rampup-rate = 0.2

          # Minimum fraction of busy routees before backing off.
          # For example, if this is 0.3, then we&#39;ll remove some routees only when
          # less than 30% of routees are busy, i.e. if current capacity is 10 and
          # 3 are busy then the capacity is unchanged, but if 2 or less are busy
          # the capacity is decreased.
          # Use 0.0 or negative to avoid removal of routees.
          backoff-threshold = 0.3

          # Fraction of routees to be removed when the resizer reaches the
          # backoffThreshold.
          # For example, 0.1 would decrease 10% (rounded up), i.e. if current
          # capacity is 9 it will request an decrease of 1 routee.
          backoff-rate = 0.1

          # Number of messages between resize operation.
          # Use 1 to resize before each message.
          messages-per-resize = 10
        }

        # Routers with dynamically resizable number of routees based on
        # performance metrics.
        # This feature is enabled by including (parts of) this section in
        # the deployment, cannot be enabled together with default resizer.
        optimal-size-exploring-resizer {

          enabled = off

          # The fewest number of routees the router should ever have.
          lower-bound = 1

          # The most number of routees the router should ever have.
          # Must be greater than or equal to lower-bound.
          upper-bound = 10

          # probability of doing a ramping down when all routees are busy
          # during exploration.
          chance-of-ramping-down-when-full = 0.2

          # Interval between each resize attempt
          action-interval = 5s

          # If the routees have not been fully utilized (i.e. all routees busy)
          # for such length, the resizer will downsize the pool.
          downsize-after-underutilized-for = 72h

          # Duration exploration, the ratio between the largest step size and
          # current pool size. E.g. if the current pool size is 50, and the
          # explore-step-size is 0.1, the maximum pool size change during
          # exploration will be +- 5
          explore-step-size = 0.1

          # Probability of doing an exploration v.s. optimization.
          chance-of-exploration = 0.4

          # When downsizing after a long streak of underutilization, the resizer
          # will downsize the pool to the highest utiliziation multiplied by a
          # a downsize ratio. This downsize ratio determines the new pools size
          # in comparison to the highest utilization.
          # E.g. if the highest utilization is 10, and the down size ratio
          # is 0.8, the pool will be downsized to 8
          downsize-ratio = 0.8

          # When optimizing, the resizer only considers the sizes adjacent to the
          # current size. This number indicates how many adjacent sizes to consider.
          optimization-range = 16

          # The weight of the latest metric over old metrics when collecting
          # performance metrics.
          # E.g. if the last processing speed is 10 millis per message at pool
          # size 5, and if the new processing speed collected is 6 millis per
          # message at pool size 5. Given a weight of 0.3, the metrics
          # representing pool size 5 will be 6 * 0.3 + 10 * 0.7, i.e. 8.8 millis
          # Obviously, this number should be between 0 and 1.
          weight-of-latest-metric = 0.5
        }
      }

      &quot;/IO-DNS/inet-address&quot; {
        mailbox = &quot;unbounded&quot;
        router = &quot;consistent-hashing-pool&quot;
        nr-of-instances = 4
      }

      &quot;/IO-DNS/inet-address/*&quot; {
        dispatcher = &quot;akka.actor.default-blocking-io-dispatcher&quot;
      }

      &quot;/IO-DNS/async-dns&quot; {
        mailbox = &quot;unbounded&quot;
        router = &quot;round-robin-pool&quot;
        nr-of-instances = 1
      }
    }

    default-dispatcher {
      # Must be one of the following
      # Dispatcher, PinnedDispatcher, or a FQCN to a class inheriting
      # MessageDispatcherConfigurator with a public constructor with
      # both com.typesafe.config.Config parameter and
      # akka.dispatch.DispatcherPrerequisites parameters.
      # PinnedDispatcher must be used together with executor=thread-pool-executor.
      type = &quot;Dispatcher&quot;

      # Which kind of ExecutorService to use for this dispatcher
      # Valid options:
      #  - &quot;default-executor&quot; requires a &quot;default-executor&quot; section
      #  - &quot;fork-join-executor&quot; requires a &quot;fork-join-executor&quot; section
      #  - &quot;thread-pool-executor&quot; requires a &quot;thread-pool-executor&quot; section
      #  - &quot;affinity-pool-executor&quot; requires an &quot;affinity-pool-executor&quot; section
      #  - A FQCN of a class extending ExecutorServiceConfigurator
      executor = &quot;default-executor&quot;

      # This will be used if you have set &quot;executor = &quot;default-executor&quot;&quot;.
      # If an ActorSystem is created with a given ExecutionContext, this
      # ExecutionContext will be used as the default executor for all
      # dispatchers in the ActorSystem configured with
      # executor = &quot;default-executor&quot;. Note that &quot;default-executor&quot;
      # is the default value for executor, and therefore used if not
      # specified otherwise. If no ExecutionContext is given,
      # the executor configured in &quot;fallback&quot; will be used.
      default-executor {
        fallback = &quot;fork-join-executor&quot;
      }

      # This will be used if you have set &quot;executor = &quot;affinity-pool-executor&quot;&quot;
      # Underlying thread pool implementation is akka.dispatch.affinity.AffinityPool.
      # This executor is classified as &quot;ApiMayChange&quot;.
      affinity-pool-executor {
        # Min number of threads to cap factor-based parallelism number to
        parallelism-min = 4

        # The parallelism factor is used to determine thread pool size using the
        # following formula: ceil(available processors * factor). Resulting size
        # is then bounded by the parallelism-min and parallelism-max values.
        parallelism-factor = 0.8

        # Max number of threads to cap factor-based parallelism number to.
        parallelism-max = 64

        # Each worker in the pool uses a separate bounded MPSC queue. This value
        # indicates the upper bound of the queue. Whenever an attempt to enqueue
        # a task is made and the queue does not have capacity to accommodate
        # the task, the rejection handler created by the rejection handler specified
        # in &quot;rejection-handler&quot; is invoked.
        task-queue-size = 512

        # FQCN of the Rejection handler used in the pool.
        # Must have an empty public constructor and must
        # implement akka.actor.affinity.RejectionHandlerFactory.
        rejection-handler = &quot;akka.dispatch.affinity.ThrowOnOverflowRejectionHandler&quot;

        # Level of CPU time used, on a scale between 1 and 10, during backoff/idle.
        # The tradeoff is that to have low latency more CPU time must be used to be
        # able to react quickly on incoming messages or send as fast as possible after
        # backoff backpressure.
        # Level 1 strongly prefer low CPU consumption over low latency.
        # Level 10 strongly prefer low latency over low CPU consumption.
        idle-cpu-level = 5

        # FQCN of the akka.dispatch.affinity.QueueSelectorFactory.
        # The Class of the FQCN must have a public constructor with a
        # (com.typesafe.config.Config) parameter.
        # A QueueSelectorFactory create instances of akka.dispatch.affinity.QueueSelector,
        # that is responsible for determining which task queue a Runnable should be enqueued in.
        queue-selector = &quot;akka.dispatch.affinity.FairDistributionHashCache&quot;

        # When using the &quot;akka.dispatch.affinity.FairDistributionHashCache&quot; queue selector
        # internally the AffinityPool uses two methods to determine which task
        # queue to allocate a Runnable to:
        # - map based - maintains a round robin counter and a map of Runnable
        # hashcodes to queues that they have been associated with. This ensures
        # maximum fairness in terms of work distribution, meaning that each worker
        # will get approximately equal amount of mailboxes to execute. This is suitable
        # in cases where we have a small number of actors that will be scheduled on
        # the pool and we want to ensure the maximum possible utilization of the
        # available threads.
        # - hash based - the task - queue in which the runnable should go is determined
        # by using an uniformly distributed int to int hash function which uses the
        # hash code of the Runnable as an input. This is preferred in situations where we
        # have enough number of distinct actors to ensure statistically uniform
        # distribution of work across threads or we are ready to sacrifice the
        # former for the added benefit of avoiding map look-ups.
        fair-work-distribution {
          # The value serves as a threshold which determines the point at which the
          # pool switches from the first to the second work distribution schemes.
          # For example, if the value is set to 128, the pool can observe up to
          # 128 unique actors and schedule their mailboxes using the map based
          # approach. Once this number is reached the pool switches to hash based
          # task distribution mode. If the value is set to 0, the map based
          # work distribution approach is disabled and only the hash based is
          # used irrespective of the number of unique actors. Valid range is
          # 0 to 2048 (inclusive)
          threshold = 128
        }
      }

      # This will be used if you have set &quot;executor = &quot;fork-join-executor&quot;&quot;
      # Underlying thread pool implementation is java.util.concurrent.ForkJoinPool
      fork-join-executor {
        # Min number of threads to cap factor-based parallelism number to
        parallelism-min = 8

        # The parallelism factor is used to determine thread pool size using the
        # following formula: ceil(available processors * factor). Resulting size
        # is then bounded by the parallelism-min and parallelism-max values.
        parallelism-factor = 1.0

        # Max number of threads to cap factor-based parallelism number to
        parallelism-max = 64

        # Setting to &quot;FIFO&quot; to use queue like peeking mode which &quot;poll&quot; or &quot;LIFO&quot; to use stack
        # like peeking mode which &quot;pop&quot;.
        task-peeking-mode = &quot;FIFO&quot;
      }

      # This will be used if you have set &quot;executor = &quot;thread-pool-executor&quot;&quot;
      # Underlying thread pool implementation is java.util.concurrent.ThreadPoolExecutor
      thread-pool-executor {
        # Keep alive time for threads
        keep-alive-time = 60s

        # Define a fixed thread pool size with this property. The corePoolSize
        # and the maximumPoolSize of the ThreadPoolExecutor will be set to this
        # value, if it is defined. Then the other pool-size properties will not
        # be used.
        #
        # Valid values are: `off` or a positive integer.
        fixed-pool-size = off

        # Min number of threads to cap factor-based corePoolSize number to
        core-pool-size-min = 8

        # The core-pool-size-factor is used to determine corePoolSize of the
        # ThreadPoolExecutor using the following formula:
        # ceil(available processors * factor).
        # Resulting size is then bounded by the core-pool-size-min and
        # core-pool-size-max values.
        core-pool-size-factor = 3.0

        # Max number of threads to cap factor-based corePoolSize number to
        core-pool-size-max = 64

        # Minimum number of threads to cap factor-based maximumPoolSize number to
        max-pool-size-min = 8

        # The max-pool-size-factor is used to determine maximumPoolSize of the
        # ThreadPoolExecutor using the following formula:
        # ceil(available processors * factor)
        # The maximumPoolSize will not be less than corePoolSize.
        # It is only used if using a bounded task queue.
        max-pool-size-factor  = 3.0

        # Max number of threads to cap factor-based maximumPoolSize number to
        max-pool-size-max = 64

        # Specifies the bounded capacity of the task queue (&lt; 1 == unbounded)
        task-queue-size = -1

        # Specifies which type of task queue will be used, can be &quot;array&quot; or
        # &quot;linked&quot; (default)
        task-queue-type = &quot;linked&quot;

        # Allow core threads to time out
        allow-core-timeout = on
      }

      # How long time the dispatcher will wait for new actors until it shuts down
      shutdown-timeout = 1s

      # Throughput defines the number of messages that are processed in a batch
      # before the thread is returned to the pool. Set to 1 for as fair as possible.
      throughput = 5

      # Throughput deadline for Dispatcher, set to 0 or negative for no deadline
      throughput-deadline-time = 0ms

      # For BalancingDispatcher: If the balancing dispatcher should attempt to
      # schedule idle actors using the same dispatcher when a message comes in,
      # and the dispatchers ExecutorService is not fully busy already.
      attempt-teamwork = on

      # If this dispatcher requires a specific type of mailbox, specify the
      # fully-qualified class name here; the actually created mailbox will
      # be a subtype of this type. The empty string signifies no requirement.
      mailbox-requirement = &quot;&quot;
    }

    # Default separate internal dispatcher to run Akka internal tasks and actors on
    # protecting them against starvation because of accidental blocking in user actors (which run on the
    # default dispatcher)
    internal-dispatcher {
      type = &quot;Dispatcher&quot;
      executor = &quot;fork-join-executor&quot;
      throughput = 5
      fork-join-executor {
        parallelism-min = 4
        parallelism-factor = 1.0
        parallelism-max = 64
      }
    }

    default-blocking-io-dispatcher {
      type = &quot;Dispatcher&quot;
      executor = &quot;thread-pool-executor&quot;
      throughput = 1

      thread-pool-executor {
        fixed-pool-size = 16
      }
    }

    default-mailbox {
      # FQCN of the MailboxType. The Class of the FQCN must have a public
      # constructor with
      # (akka.actor.ActorSystem.Settings, com.typesafe.config.Config) parameters.
      mailbox-type = &quot;akka.dispatch.UnboundedMailbox&quot;

      # If the mailbox is bounded then it uses this setting to determine its
      # capacity. The provided value must be positive.
      # NOTICE:
      # Up to version 2.1 the mailbox type was determined based on this setting;
      # this is no longer the case, the type must explicitly be a bounded mailbox.
      mailbox-capacity = 1000

      # If the mailbox is bounded then this is the timeout for enqueueing
      # in case the mailbox is full. Negative values signify infinite
      # timeout, which should be avoided as it bears the risk of dead-lock.
      mailbox-push-timeout-time = 10s

      # For Actor with Stash: The default capacity of the stash.
      # If negative (or zero) then an unbounded stash is used (default)
      # If positive then a bounded stash is used and the capacity is set using
      # the property
      stash-capacity = -1
    }

    mailbox {
      # Mapping between message queue semantics and mailbox configurations.
      # Used by akka.dispatch.RequiresMessageQueue[T] to enforce different
      # mailbox types on actors.
      # If your Actor implements RequiresMessageQueue[T], then when you create
      # an instance of that actor its mailbox type will be decided by looking
      # up a mailbox configuration via T in this mapping
      requirements {
        &quot;akka.dispatch.UnboundedMessageQueueSemantics&quot; =
          akka.actor.mailbox.unbounded-queue-based
        &quot;akka.dispatch.BoundedMessageQueueSemantics&quot; =
          akka.actor.mailbox.bounded-queue-based
        &quot;akka.dispatch.DequeBasedMessageQueueSemantics&quot; =
          akka.actor.mailbox.unbounded-deque-based
        &quot;akka.dispatch.UnboundedDequeBasedMessageQueueSemantics&quot; =
          akka.actor.mailbox.unbounded-deque-based
        &quot;akka.dispatch.BoundedDequeBasedMessageQueueSemantics&quot; =
          akka.actor.mailbox.bounded-deque-based
        &quot;akka.dispatch.MultipleConsumerSemantics&quot; =
          akka.actor.mailbox.unbounded-queue-based
        &quot;akka.dispatch.ControlAwareMessageQueueSemantics&quot; =
          akka.actor.mailbox.unbounded-control-aware-queue-based
        &quot;akka.dispatch.UnboundedControlAwareMessageQueueSemantics&quot; =
          akka.actor.mailbox.unbounded-control-aware-queue-based
        &quot;akka.dispatch.BoundedControlAwareMessageQueueSemantics&quot; =
          akka.actor.mailbox.bounded-control-aware-queue-based
        &quot;akka.event.LoggerMessageQueueSemantics&quot; =
          akka.actor.mailbox.logger-queue
      }

      unbounded-queue-based {
        # FQCN of the MailboxType, The Class of the FQCN must have a public
        # constructor with (akka.actor.ActorSystem.Settings,
        # com.typesafe.config.Config) parameters.
        mailbox-type = &quot;akka.dispatch.UnboundedMailbox&quot;
      }

      bounded-queue-based {
        # FQCN of the MailboxType, The Class of the FQCN must have a public
        # constructor with (akka.actor.ActorSystem.Settings,
        # com.typesafe.config.Config) parameters.
        mailbox-type = &quot;akka.dispatch.BoundedMailbox&quot;
      }

      unbounded-deque-based {
        # FQCN of the MailboxType, The Class of the FQCN must have a public
        # constructor with (akka.actor.ActorSystem.Settings,
        # com.typesafe.config.Config) parameters.
        mailbox-type = &quot;akka.dispatch.UnboundedDequeBasedMailbox&quot;
      }

      bounded-deque-based {
        # FQCN of the MailboxType, The Class of the FQCN must have a public
        # constructor with (akka.actor.ActorSystem.Settings,
        # com.typesafe.config.Config) parameters.
        mailbox-type = &quot;akka.dispatch.BoundedDequeBasedMailbox&quot;
      }

      unbounded-control-aware-queue-based {
        # FQCN of the MailboxType, The Class of the FQCN must have a public
        # constructor with (akka.actor.ActorSystem.Settings,
        # com.typesafe.config.Config) parameters.
        mailbox-type = &quot;akka.dispatch.UnboundedControlAwareMailbox&quot;
      }

      bounded-control-aware-queue-based {
        # FQCN of the MailboxType, The Class of the FQCN must have a public
        # constructor with (akka.actor.ActorSystem.Settings,
        # com.typesafe.config.Config) parameters.
        mailbox-type = &quot;akka.dispatch.BoundedControlAwareMailbox&quot;
      }

      # The LoggerMailbox will drain all messages in the mailbox
      # when the system is shutdown and deliver them to the StandardOutLogger.
      # Do not change this unless you know what you are doing.
      logger-queue {
        mailbox-type = &quot;akka.event.LoggerMailboxType&quot;
      }
    }

    debug {
      # enable function of Actor.loggable(), which is to log any received message
      # at DEBUG level, see the “Testing Actor Systems” section of the Akka
      # Documentation at http://akka.io/docs
      receive = off

      # enable DEBUG logging of all AutoReceiveMessages (Kill, PoisonPill etc.)
      autoreceive = off

      # enable DEBUG logging of actor lifecycle changes
      lifecycle = off

      # enable DEBUG logging of all LoggingFSMs for events, transitions and timers
      fsm = off

      # enable DEBUG logging of subscription changes on the eventStream
      event-stream = off

      # enable DEBUG logging of unhandled messages
      unhandled = off

      # enable WARN logging of misconfigured routers
      router-misconfiguration = off
    }

    # SECURITY BEST-PRACTICE is to disable java serialization for its multiple
    # known attack surfaces.
    #
    # This setting is a short-cut to
    # - using DisabledJavaSerializer instead of JavaSerializer
    #
    # Completely disable the use of `akka.serialization.JavaSerialization` by the
    # Akka Serialization extension, instead DisabledJavaSerializer will
    # be inserted which will fail explicitly if attempts to use java serialization are made.
    #
    # The log messages emitted by such serializer SHOULD be treated as potential
    # attacks which the serializer prevented, as they MAY indicate an external operator
    # attempting to send malicious messages intending to use java serialization as attack vector.
    # The attempts are logged with the SECURITY marker.
    #
    # Please note that this option does not stop you from manually invoking java serialization
    #
    allow-java-serialization = off

    # Log warnings when the Java serialization is used to serialize messages.
    # Java serialization is not very performant and should not be used in production
    # environments unless you don&#39;t care about performance and security. In that case
    # you can turn this off.
    warn-about-java-serializer-usage = on

    # To be used with the above warn-about-java-serializer-usage
    # When warn-about-java-serializer-usage = on, and this warn-on-no-serialization-verification = off,
    # warnings are suppressed for classes extending NoSerializationVerificationNeeded
    # to reduce noise.
    warn-on-no-serialization-verification = on

    # Entries for pluggable serializers and their bindings.
    serializers {
      java = &quot;akka.serialization.JavaSerializer&quot;
      bytes = &quot;akka.serialization.ByteArraySerializer&quot;
      primitive-long = &quot;akka.serialization.LongSerializer&quot;
      primitive-int = &quot;akka.serialization.IntSerializer&quot;
      primitive-string = &quot;akka.serialization.StringSerializer&quot;
      primitive-bytestring = &quot;akka.serialization.ByteStringSerializer&quot;
      primitive-boolean = &quot;akka.serialization.BooleanSerializer&quot;
    }

    # Class to Serializer binding. You only need to specify the name of an
    # interface or abstract base class of the messages. In case of ambiguity it
    # is using the most specific configured class, or giving a warning and
    # choosing the “first” one.
    #
    # To disable one of the default serializers, assign its class to &quot;none&quot;, like
    # &quot;java.io.Serializable&quot; = none
    serialization-bindings {
      &quot;[B&quot; = bytes
      &quot;java.io.Serializable&quot; = java

      &quot;java.lang.String&quot; = primitive-string
      &quot;akka.util.ByteString$ByteString1C&quot; = primitive-bytestring
      &quot;akka.util.ByteString$ByteString1&quot; = primitive-bytestring
      &quot;akka.util.ByteString$ByteStrings&quot; = primitive-bytestring
      &quot;java.lang.Long&quot; = primitive-long
      &quot;scala.Long&quot; = primitive-long
      &quot;java.lang.Integer&quot; = primitive-int
      &quot;scala.Int&quot; = primitive-int
      &quot;java.lang.Boolean&quot; = primitive-boolean
      &quot;scala.Boolean&quot; = primitive-boolean
    }

    # Configuration namespace of serialization identifiers.
    # Each serializer implementation must have an entry in the following format:
    # `akka.actor.serialization-identifiers.&quot;FQCN&quot; = ID`
    # where `FQCN` is fully qualified class name of the serializer implementation
    # and `ID` is globally unique serializer identifier number.
    # Identifier values from 0 to 40 are reserved for Akka internal usage.
    serialization-identifiers {
      &quot;akka.serialization.JavaSerializer&quot; = 1
      &quot;akka.serialization.ByteArraySerializer&quot; = 4

      primitive-long = 18
      primitive-int = 19
      primitive-string = 20
      primitive-bytestring = 21
      primitive-boolean = 35
    }

  }

  serialization.protobuf {

    # Additional classes that are allowed even if they are not defined in `serialization-bindings`.
    # It can be exact class name or name of super class or interfaces (one level).
    # This is useful when a class is not used for serialization any more and therefore removed
    # from `serialization-bindings`, but should still be possible to deserialize.
    whitelist-class = [
      &quot;com.google.protobuf.GeneratedMessage&quot;,
      &quot;com.google.protobuf.GeneratedMessageV3&quot;,
      &quot;scalapb.GeneratedMessageCompanion&quot;,
      &quot;akka.protobuf.GeneratedMessage&quot;,
      &quot;akka.protobufv3.internal.GeneratedMessageV3&quot;
    ]
  }

  # Used to set the behavior of the scheduler.
  # Changing the default values may change the system behavior drastically so make
  # sure you know what you&#39;re doing! See the Scheduler section of the Akka
  # Documentation for more details.
  scheduler {
    # The LightArrayRevolverScheduler is used as the default scheduler in the
    # system. It does not execute the scheduled tasks on exact time, but on every
    # tick, it will run everything that is (over)due. You can increase or decrease
    # the accuracy of the execution timing by specifying smaller or larger tick
    # duration. If you are scheduling a lot of tasks you should consider increasing
    # the ticks per wheel.
    # Note that it might take up to 1 tick to stop the Timer, so setting the
    # tick-duration to a high value will make shutting down the actor system
    # take longer.
    tick-duration = 10ms

    # The timer uses a circular wheel of buckets to store the timer tasks.
    # This should be set such that the majority of scheduled timeouts (for high
    # scheduling frequency) will be shorter than one rotation of the wheel
    # (ticks-per-wheel * ticks-duration)
    # THIS MUST BE A POWER OF TWO!
    ticks-per-wheel = 512

    # This setting selects the timer implementation which shall be loaded at
    # system start-up.
    # The class given here must implement the akka.actor.Scheduler interface
    # and offer a public constructor which takes three arguments:
    #  1) com.typesafe.config.Config
    #  2) akka.event.LoggingAdapter
    #  3) java.util.concurrent.ThreadFactory
    implementation = akka.actor.LightArrayRevolverScheduler

    # When shutting down the scheduler, there will typically be a thread which
    # needs to be stopped, and this timeout determines how long to wait for
    # that to happen. In case of timeout the shutdown of the actor system will
    # proceed without running possibly still enqueued tasks.
    shutdown-timeout = 5s
  }

  io {

    # By default the select loops run on dedicated threads, hence using a
    # PinnedDispatcher
    pinned-dispatcher {
      type = &quot;PinnedDispatcher&quot;
      executor = &quot;thread-pool-executor&quot;
      thread-pool-executor.allow-core-timeout = off
    }

    tcp {

      # The number of selectors to stripe the served channels over; each of
      # these will use one select loop on the selector-dispatcher.
      nr-of-selectors = 1

      # Maximum number of open channels supported by this TCP module; there is
      # no intrinsic general limit, this setting is meant to enable DoS
      # protection by limiting the number of concurrently connected clients.
      # Also note that this is a &quot;soft&quot; limit; in certain cases the implementation
      # will accept a few connections more or a few less than the number configured
      # here. Must be an integer &gt; 0 or &quot;unlimited&quot;.
      max-channels = 256000

      # When trying to assign a new connection to a selector and the chosen
      # selector is at full capacity, retry selector choosing and assignment
      # this many times before giving up
      selector-association-retries = 10

      # The maximum number of connection that are accepted in one go,
      # higher numbers decrease latency, lower numbers increase fairness on
      # the worker-dispatcher
      batch-accept-limit = 10

      # The number of bytes per direct buffer in the pool used to read or write
      # network data from the kernel.
      direct-buffer-size = 128 KiB

      # The maximal number of direct buffers kept in the direct buffer pool for
      # reuse.
      direct-buffer-pool-limit = 1000

      # The duration a connection actor waits for a `Register` message from
      # its commander before aborting the connection.
      register-timeout = 5s

      # The maximum number of bytes delivered by a `Received` message. Before
      # more data is read from the network the connection actor will try to
      # do other work.
      # The purpose of this setting is to impose a smaller limit than the
      # configured receive buffer size. When using value &#39;unlimited&#39; it will
      # try to read all from the receive buffer.
      max-received-message-size = unlimited

      # Enable fine grained logging of what goes on inside the implementation.
      # Be aware that this may log more than once per message sent to the actors
      # of the tcp implementation.
      trace-logging = off

      # Fully qualified config path which holds the dispatcher configuration
      # to be used for running the select() calls in the selectors
      selector-dispatcher = &quot;akka.io.pinned-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # for the read/write worker actors
      worker-dispatcher = &quot;akka.actor.internal-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # for the selector management actors
      management-dispatcher = &quot;akka.actor.internal-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # on which file IO tasks are scheduled
      file-io-dispatcher = &quot;akka.actor.default-blocking-io-dispatcher&quot;

      # The maximum number of bytes (or &quot;unlimited&quot;) to transfer in one batch
      # when using `WriteFile` command which uses `FileChannel.transferTo` to
      # pipe files to a TCP socket. On some OS like Linux `FileChannel.transferTo`
      # may block for a long time when network IO is faster than file IO.
      # Decreasing the value may improve fairness while increasing may improve
      # throughput.
      file-io-transferTo-limit = 512 KiB

      # The number of times to retry the `finishConnect` call after being notified about
      # OP_CONNECT. Retries are needed if the OP_CONNECT notification doesn&#39;t imply that
      # `finishConnect` will succeed, which is the case on Android.
      finish-connect-retries = 5

      # On Windows connection aborts are not reliably detected unless an OP_READ is
      # registered on the selector _after_ the connection has been reset. This
      # workaround enables an OP_CONNECT which forces the abort to be visible on Windows.
      # Enabling this setting on other platforms than Windows will cause various failures
      # and undefined behavior.
      # Possible values of this key are on, off and auto where auto will enable the
      # workaround if Windows is detected automatically.
      windows-connection-abort-workaround-enabled = off
    }

    udp {

      # The number of selectors to stripe the served channels over; each of
      # these will use one select loop on the selector-dispatcher.
      nr-of-selectors = 1

      # Maximum number of open channels supported by this UDP module Generally
      # UDP does not require a large number of channels, therefore it is
      # recommended to keep this setting low.
      max-channels = 4096

      # The select loop can be used in two modes:
      # - setting &quot;infinite&quot; will select without a timeout, hogging a thread
      # - setting a positive timeout will do a bounded select call,
      #   enabling sharing of a single thread between multiple selectors
      #   (in this case you will have to use a different configuration for the
      #   selector-dispatcher, e.g. using &quot;type=Dispatcher&quot; with size 1)
      # - setting it to zero means polling, i.e. calling selectNow()
      select-timeout = infinite

      # When trying to assign a new connection to a selector and the chosen
      # selector is at full capacity, retry selector choosing and assignment
      # this many times before giving up
      selector-association-retries = 10

      # The maximum number of datagrams that are read in one go,
      # higher numbers decrease latency, lower numbers increase fairness on
      # the worker-dispatcher
      receive-throughput = 3

      # The number of bytes per direct buffer in the pool used to read or write
      # network data from the kernel.
      direct-buffer-size = 128 KiB

      # The maximal number of direct buffers kept in the direct buffer pool for
      # reuse.
      direct-buffer-pool-limit = 1000

      # Enable fine grained logging of what goes on inside the implementation.
      # Be aware that this may log more than once per message sent to the actors
      # of the tcp implementation.
      trace-logging = off

      # Fully qualified config path which holds the dispatcher configuration
      # to be used for running the select() calls in the selectors
      selector-dispatcher = &quot;akka.io.pinned-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # for the read/write worker actors
      worker-dispatcher = &quot;akka.actor.internal-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # for the selector management actors
      management-dispatcher = &quot;akka.actor.internal-dispatcher&quot;
    }

    udp-connected {

      # The number of selectors to stripe the served channels over; each of
      # these will use one select loop on the selector-dispatcher.
      nr-of-selectors = 1

      # Maximum number of open channels supported by this UDP module Generally
      # UDP does not require a large number of channels, therefore it is
      # recommended to keep this setting low.
      max-channels = 4096

      # The select loop can be used in two modes:
      # - setting &quot;infinite&quot; will select without a timeout, hogging a thread
      # - setting a positive timeout will do a bounded select call,
      #   enabling sharing of a single thread between multiple selectors
      #   (in this case you will have to use a different configuration for the
      #   selector-dispatcher, e.g. using &quot;type=Dispatcher&quot; with size 1)
      # - setting it to zero means polling, i.e. calling selectNow()
      select-timeout = infinite

      # When trying to assign a new connection to a selector and the chosen
      # selector is at full capacity, retry selector choosing and assignment
      # this many times before giving up
      selector-association-retries = 10

      # The maximum number of datagrams that are read in one go,
      # higher numbers decrease latency, lower numbers increase fairness on
      # the worker-dispatcher
      receive-throughput = 3

      # The number of bytes per direct buffer in the pool used to read or write
      # network data from the kernel.
      direct-buffer-size = 128 KiB

      # The maximal number of direct buffers kept in the direct buffer pool for
      # reuse.
      direct-buffer-pool-limit = 1000

      # Enable fine grained logging of what goes on inside the implementation.
      # Be aware that this may log more than once per message sent to the actors
      # of the tcp implementation.
      trace-logging = off

      # Fully qualified config path which holds the dispatcher configuration
      # to be used for running the select() calls in the selectors
      selector-dispatcher = &quot;akka.io.pinned-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # for the read/write worker actors
      worker-dispatcher = &quot;akka.actor.internal-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # for the selector management actors
      management-dispatcher = &quot;akka.actor.internal-dispatcher&quot;
    }

    dns {
      # Fully qualified config path which holds the dispatcher configuration
      # for the manager and resolver router actors.
      # For actual router configuration see akka.actor.deployment./IO-DNS/*
      dispatcher = &quot;akka.actor.internal-dispatcher&quot;

      # Name of the subconfig at path akka.io.dns, see inet-address below
      #
      # Change to `async-dns` to use the new &quot;native&quot; DNS resolver,
      # which is also capable of resolving SRV records.
      resolver = &quot;inet-address&quot;

      # To-be-deprecated DNS resolver implementation which uses the Java InetAddress to resolve DNS records.
      # To be replaced by `akka.io.dns.async` which implements the DNS protocol natively and without blocking (which InetAddress does)
      inet-address {
        # Must implement akka.io.DnsProvider
        provider-object = &quot;akka.io.InetAddressDnsProvider&quot;

        # To set the time to cache name resolutions
        # Possible values:
        # default: sun.net.InetAddressCachePolicy.get() and getNegative()
        # forever: cache forever
        # never: no caching
        # n [time unit]: positive timeout with unit, for example 30s
        positive-ttl = default
        negative-ttl = default

        # How often to sweep out expired cache entries.
        # Note that this interval has nothing to do with TTLs
        cache-cleanup-interval = 120s
      }

      async-dns {
        provider-object = &quot;akka.io.dns.internal.AsyncDnsProvider&quot;

        # Set upper bound for caching successfully resolved dns entries
        # if the DNS record has a smaller TTL value than the setting that
        # will be used. Default is to use the record TTL with no cap.
        # Possible values:
        # forever: always use the minimum TTL from the found records
        # never: never cache
        # n [time unit] = cap the caching to this value
        positive-ttl = forever

        # Set how long the fact that a DNS record could not be found is
        # cached. If a new resolution is done while the fact is cached it will
        # be failed and not result in an actual DNS resolution. Default is
        # to never cache.
        # Possible values:
        # never: never cache
        # forever: cache a missing DNS record forever (you probably will not want to do this)
        # n [time unit] = cache for this long
        negative-ttl = never

        # Configures nameservers to query during DNS resolution.
        # Defaults to the nameservers that would be used by the JVM by default.
        # Set to a list of IPs to override the servers, e.g. [ &quot;8.8.8.8&quot;, &quot;8.8.4.4&quot; ] for Google&#39;s servers
        # If multiple are defined then they are tried in order until one responds
        nameservers = default

        # The time that a request is allowed to live before being discarded
        # given no reply. The lower bound of this should always be the amount
        # of time to reasonably expect a DNS server to reply within.
        # If multiple name servers are provided then each gets this long to response before trying
        # the next one
        resolve-timeout = 5s

        # How often to sweep out expired cache entries.
        # Note that this interval has nothing to do with TTLs
        cache-cleanup-interval = 120s

        # Configures the list of search domains.
        # Defaults to a system dependent lookup (on Unix like OSes, will attempt to parse /etc/resolv.conf, on
        # other platforms, will not make any attempt to lookup the search domains). Set to a single domain, or
        # a list of domains, eg, [ &quot;example.com&quot;, &quot;example.net&quot; ].
        search-domains = default

        # Any hosts that have a number of dots less than this will not be looked up directly, instead, a search on
        # the search domains will be tried first. This corresponds to the ndots option in /etc/resolv.conf, see
        # https://linux.die.net/man/5/resolver for more info.
        # Defaults to a system dependent lookup (on Unix like OSes, will attempt to parse /etc/resolv.conf, on
        # other platforms, will default to 1).
        ndots = default
      }
    }
  }


  # CoordinatedShutdown is an extension that will perform registered
  # tasks in the order that is defined by the phases. It is started
  # by calling CoordinatedShutdown(system).run(). This can be triggered
  # by different things, for example:
  # - JVM shutdown hook will by default run CoordinatedShutdown
  # - Cluster node will automatically run CoordinatedShutdown when it
  #   sees itself as Exiting
  # - A management console or other application specific command can
  #   run CoordinatedShutdown
  coordinated-shutdown {
    # The timeout that will be used for a phase if not specified with
    # &#39;timeout&#39; in the phase
    default-phase-timeout = 5 s

    # Terminate the ActorSystem in the last phase actor-system-terminate.
    terminate-actor-system = on

    # Exit the JVM (System.exit(0)) in the last phase actor-system-terminate
    # if this is set to &#39;on&#39;. It is done after termination of the
    # ActorSystem if terminate-actor-system=on, otherwise it is done
    # immediately when the last phase is reached.
    exit-jvm = off

    # Exit status to use on System.exit(int) when &#39;exit-jvm&#39; is &#39;on&#39;.
    exit-code = 0

    # Run the coordinated shutdown when the JVM process exits, e.g.
    # via kill SIGTERM signal (SIGINT ctrl-c doesn&#39;t work).
    # This property is related to `akka.jvm-shutdown-hooks` above.
    run-by-jvm-shutdown-hook = on

    # Run the coordinated shutdown when ActorSystem.terminate is called.
    # Enabling this and disabling terminate-actor-system is not a supported
    # combination (will throw ConfigurationException at startup).
    run-by-actor-system-terminate = on

    # When Coordinated Shutdown is triggered an instance of `Reason` is
    # required. That value can be used to override the default settings.
    # Only &#39;exit-jvm&#39;, &#39;exit-code&#39; and &#39;terminate-actor-system&#39; may be
    # overridden depending on the reason.
    reason-overrides {
      # Overrides are applied using the `reason.getClass.getName`.
      # Overrides the `exit-code` when the `Reason` is a cluster
      # Downing or a Cluster Join Unsuccessful event
      &quot;akka.actor.CoordinatedShutdown$ClusterDowningReason$&quot; {
        exit-code = -1
      }
      &quot;akka.actor.CoordinatedShutdown$ClusterJoinUnsuccessfulReason$&quot; {
        exit-code = -1
      }
    }

    #//#coordinated-shutdown-phases
    # CoordinatedShutdown is enabled by default and will run the tasks that
    # are added to these phases by individual Akka modules and user logic.
    #
    # The phases are ordered as a DAG by defining the dependencies between the phases
    # to make sure shutdown tasks are run in the right order.
    #
    # In general user tasks belong in the first few phases, but there may be use
    # cases where you would want to hook in new phases or register tasks later in
    # the DAG.
    #
    # Each phase is defined as a named config section with the
    # following optional properties:
    # - timeout=15s: Override the default-phase-timeout for this phase.
    # - recover=off: If the phase fails the shutdown is aborted
    #                and depending phases will not be executed.
    # - enabled=off: Skip all tasks registered in this phase. DO NOT use
    #                this to disable phases unless you are absolutely sure what the
    #                consequences are. Many of the built in tasks depend on other tasks
    #                having been executed in earlier phases and may break if those are disabled.
    # depends-on=[]: Run the phase after the given phases
    phases {

      # The first pre-defined phase that applications can add tasks to.
      # Note that more phases can be added in the application&#39;s
      # configuration by overriding this phase with an additional
      # depends-on.
      before-service-unbind {
      }

      # Stop accepting new incoming connections.
      # This is where you can register tasks that makes a server stop accepting new connections. Already
      # established connections should be allowed to continue and complete if possible.
      service-unbind {
        depends-on = [before-service-unbind]
      }

      # Wait for requests that are in progress to be completed.
      # This is where you register tasks that will wait for already established connections to complete, potentially
      # also first telling them that it is time to close down.
      service-requests-done {
        depends-on = [service-unbind]
      }

      # Final shutdown of service endpoints.
      # This is where you would add tasks that forcefully kill connections that are still around.
      service-stop {
        depends-on = [service-requests-done]
      }

      # Phase for custom application tasks that are to be run
      # after service shutdown and before cluster shutdown.
      before-cluster-shutdown {
        depends-on = [service-stop]
      }

      # Graceful shutdown of the Cluster Sharding regions.
      # This phase is not meant for users to add tasks to.
      cluster-sharding-shutdown-region {
        timeout = 10 s
        depends-on = [before-cluster-shutdown]
      }

      # Emit the leave command for the node that is shutting down.
      # This phase is not meant for users to add tasks to.
      cluster-leave {
        depends-on = [cluster-sharding-shutdown-region]
      }

      # Shutdown cluster singletons
      # This is done as late as possible to allow the shard region shutdown triggered in
      # the &quot;cluster-sharding-shutdown-region&quot; phase to complete before the shard coordinator is shut down.
      # This phase is not meant for users to add tasks to.
      cluster-exiting {
        timeout = 10 s
        depends-on = [cluster-leave]
      }

      # Wait until exiting has been completed
      # This phase is not meant for users to add tasks to.
      cluster-exiting-done {
        depends-on = [cluster-exiting]
      }

      # Shutdown the cluster extension
      # This phase is not meant for users to add tasks to.
      cluster-shutdown {
        depends-on = [cluster-exiting-done]
      }

      # Phase for custom application tasks that are to be run
      # after cluster shutdown and before ActorSystem termination.
      before-actor-system-terminate {
        depends-on = [cluster-shutdown]
      }

      # Last phase. See terminate-actor-system and exit-jvm above.
      # Don&#39;t add phases that depends on this phase because the
      # dispatcher and scheduler of the ActorSystem have been shutdown.
      # This phase is not meant for users to add tasks to.
      actor-system-terminate {
        timeout = 10 s
        depends-on = [before-actor-system-terminate]
      }
    }
    #//#coordinated-shutdown-phases
  }

}</code></pre>
<a id="config-akka-actor-typed"></a>
<h3><a href="#akka-actor-typed" name="akka-actor-typed" class="anchor"><span class="anchor-link"></span></a>akka-actor-typed</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-actor-typed/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">akka.actor.typed {

  # List FQCN of `akka.actor.typed.ExtensionId`s which shall be loaded at actor system startup.
  # Should be on the format: &#39;extensions = [&quot;com.example.MyExtId1&quot;, &quot;com.example.MyExtId2&quot;]&#39; etc.
  # See the Akka Documentation for more info about Extensions
  extensions = []

  # List FQCN of extensions which shall be loaded at actor system startup.
  # Library extensions are regular extensions that are loaded at startup and are
  # available for third party library authors to enable auto-loading of extensions when
  # present on the classpath. This is done by appending entries:
  # &#39;library-extensions += &quot;Extension&quot;&#39; in the library `reference.conf`.
  #
  # Should not be set by end user applications in &#39;application.conf&#39;, use the extensions property for that
  #
  library-extensions = ${?akka.actor.typed.library-extensions} []

  # Receptionist is started eagerly to allow clustered receptionist to gather remote registrations early on.
  library-extensions += &quot;akka.actor.typed.receptionist.Receptionist&quot;

  # While an actor is restarted (waiting for backoff to expire and children to stop)
  # incoming messages and signals are stashed, and delivered later to the newly restarted
  # behavior. This property defines the capacity in number of messages of the stash
  # buffer. If the capacity is exceed then additional incoming messages are dropped.
  restart-stash-capacity = 1000

  # Typed mailbox defaults to the single consumber mailbox as balancing dispatcher is not supported
  default-mailbox {
    mailbox-type = &quot;akka.dispatch.SingleConsumerOnlyUnboundedMailbox&quot;
  }
}

# Load typed extensions by a classic extension.
akka.library-extensions += &quot;akka.actor.typed.internal.adapter.ActorSystemAdapter$LoadTypedExtensions&quot;

akka.actor {
  serializers {
    typed-misc = &quot;akka.actor.typed.internal.MiscMessageSerializer&quot;
    service-key = &quot;akka.actor.typed.internal.receptionist.ServiceKeySerializer&quot;
  }

  serialization-identifiers {
    &quot;akka.actor.typed.internal.MiscMessageSerializer&quot; = 24
    &quot;akka.actor.typed.internal.receptionist.ServiceKeySerializer&quot; = 26
  }

  serialization-bindings {
    &quot;akka.actor.typed.ActorRef&quot; = typed-misc
    &quot;akka.actor.typed.internal.adapter.ActorRefAdapter&quot; = typed-misc
    &quot;akka.actor.typed.internal.receptionist.DefaultServiceKey&quot; = service-key
  }
}

# When using Akka Typed (having akka-actor-typed in classpath) the
# akka.event.slf4j.Slf4jLogger is enabled instead of the DefaultLogger
# even though it has not been explicitly defined in `akka.loggers`
# configuration.
#
# Slf4jLogger will be used for all Akka classic logging via eventStream,
# including logging from Akka internals. The Slf4jLogger is then using
# an ordinary org.slf4j.Logger to emit the log events.
#
# The Slf4jLoggingFilter is also enabled automatically.
#
# This behavior can be disabled by setting this property to `off`.
akka.use-slf4j = on</code></pre>
<a id="config-akka-cluster-typed"></a>
<h3><a href="#akka-cluster-typed" name="akka-cluster-typed" class="anchor"><span class="anchor-link"></span></a>akka-cluster-typed</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-cluster-typed/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">############################################
# Akka Cluster Typed Reference Config File #
############################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

akka.cluster.typed.receptionist {
  # Updates with Distributed Data are done with this consistency level.
  # Possible values: local, majority, all, 2, 3, 4 (n)
  write-consistency = local

  # Period task to remove actor references that are hosted by removed nodes,
  # in case of abrupt termination.
  pruning-interval = 3 s

  # Shard the services over this many Distributed Data keys, with large amounts of different
  # service keys storing all of them in the same Distributed Data entry would lead to large updates
  # etc. instead the keys are sharded across this number of keys. This must be the same on all nodes
  # in a cluster, changing it requires a full cluster restart (stopping all nodes before starting them again)
  distributed-key-count = 5

  # Settings for the Distributed Data replicator used by Receptionist.
  # Same layout as akka.cluster.distributed-data.
  distributed-data = ${akka.cluster.distributed-data}
  # make sure that by default it&#39;s for all roles (Play loads config in different way)
  distributed-data.role = &quot;&quot;
}

akka.cluster.ddata.typed {
  # The timeout to use for ask operations in ReplicatorMessageAdapter.
  # This should be longer than the timeout given in Replicator.WriteConsistency and
  # Replicator.ReadConsistency. The replicator will always send a reply within those
  # timeouts so the unexpected ask timeout should not occur, but for cleanup in a
  # failure situation it must still exist.
  # If askUpdate, askGet or askDelete takes longer then this timeout a
  # java.util.concurrent.TimeoutException will be thrown by the requesting actor and
  # may be handled by supervision.
  replicator-message-adapter-unexpected-ask-timeout = 20 s
}

akka {
  actor {
    serialization-identifiers {
      &quot;akka.cluster.typed.internal.AkkaClusterTypedSerializer&quot; = 28
    }
    serializers {
      typed-cluster = &quot;akka.cluster.typed.internal.AkkaClusterTypedSerializer&quot;
    }
    serialization-bindings {
      &quot;akka.cluster.typed.internal.receptionist.ClusterReceptionist$Entry&quot; = typed-cluster
    }
  }
  cluster.configuration-compatibility-check.checkers {
    receptionist = &quot;akka.cluster.typed.internal.receptionist.ClusterReceptionistConfigCompatChecker&quot;
  }
}</code></pre>
<a id="config-akka-cluster"></a>
<h3><a href="#akka-cluster" name="akka-cluster" class="anchor"><span class="anchor-link"></span></a>akka-cluster</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-cluster/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">######################################
# Akka Cluster Reference Config File #
######################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

akka {

  cluster {
    # Initial contact points of the cluster.
    # The nodes to join automatically at startup.
    # Comma separated full URIs defined by a string on the form of
    # &quot;akka://system@hostname:port&quot;
    # Leave as empty if the node is supposed to be joined manually.
    seed-nodes = []

    # How long to wait for one of the seed nodes to reply to initial join request.
    # When this is the first seed node and there is no positive reply from the other
    # seed nodes within this timeout it will join itself to bootstrap the cluster.
    # When this is not the first seed node the join attempts will be performed with
    # this interval.  
    seed-node-timeout = 5s

    # If a join request fails it will be retried after this period.
    # Disable join retry by specifying &quot;off&quot;.
    retry-unsuccessful-join-after = 10s
    
    # The joining of given seed nodes will by default be retried indefinitely until
    # a successful join. That process can be aborted if unsuccessful by defining this
    # timeout. When aborted it will run CoordinatedShutdown, which by default will
    # terminate the ActorSystem. CoordinatedShutdown can also be configured to exit
    # the JVM. It is useful to define this timeout if the seed-nodes are assembled
    # dynamically and a restart with new seed-nodes should be tried after unsuccessful
    # attempts.   
    shutdown-after-unsuccessful-join-seed-nodes = off

    # Time margin after which shards or singletons that belonged to a downed/removed
    # partition are created in surviving partition. The purpose of this margin is that
    # in case of a network partition the persistent actors in the non-surviving partitions
    # must be stopped before corresponding persistent actors are started somewhere else.
    # This is useful if you implement downing strategies that handle network partitions,
    # e.g. by keeping the larger side of the partition and shutting down the smaller side.
    # Disable with &quot;off&quot; or specify a duration to enable.
    down-removal-margin = off

    # Pluggable support for downing of nodes in the cluster.
    # If this setting is left empty the `NoDowning` provider is used and no automatic downing will be performed.
    #
    # If specified the value must be the fully qualified class name of a subclass of
    # `akka.cluster.DowningProvider` having a public one argument constructor accepting an `ActorSystem`
    downing-provider-class = &quot;&quot;

    # Artery only setting
    # When a node has been gracefully removed, let this time pass (to allow for example
    # cluster singleton handover to complete) and then quarantine the removed node.
    quarantine-removed-node-after = 5s

    # If this is set to &quot;off&quot;, the leader will not move &#39;Joining&#39; members to &#39;Up&#39; during a network
    # split. This feature allows the leader to accept &#39;Joining&#39; members to be &#39;WeaklyUp&#39;
    # so they become part of the cluster even during a network split. The leader will
    # move `Joining` members to &#39;WeaklyUp&#39; after 3 rounds of &#39;leader-actions-interval&#39;
    # without convergence.
    # The leader will move &#39;WeaklyUp&#39; members to &#39;Up&#39; status once convergence has been reached.
    allow-weakly-up-members = on

    # The roles of this member. List of strings, e.g. roles = [&quot;A&quot;, &quot;B&quot;].
    # The roles are part of the membership information and can be used by
    # routers or other services to distribute work to certain member types,
    # e.g. front-end and back-end nodes.
    # Roles are not allowed to start with &quot;dc-&quot; as that is reserved for the
    # special role assigned from the data-center a node belongs to (see the
    # multi-data-center section below)
    roles = []
    
    # Run the coordinated shutdown from phase &#39;cluster-shutdown&#39; when the cluster
    # is shutdown for other reasons than when leaving, e.g. when downing. This
    # will terminate the ActorSystem when the cluster extension is shutdown.
    run-coordinated-shutdown-when-down = on

    role {
      # Minimum required number of members of a certain role before the leader
      # changes member status of &#39;Joining&#39; members to &#39;Up&#39;. Typically used together
      # with &#39;Cluster.registerOnMemberUp&#39; to defer some action, such as starting
      # actors, until the cluster has reached a certain size.
      # E.g. to require 2 nodes with role &#39;frontend&#39; and 3 nodes with role &#39;backend&#39;:
      #   frontend.min-nr-of-members = 2
      #   backend.min-nr-of-members = 3
      #&lt;role-name&gt;.min-nr-of-members = 1
    }

    # Minimum required number of members before the leader changes member status
    # of &#39;Joining&#39; members to &#39;Up&#39;. Typically used together with
    # &#39;Cluster.registerOnMemberUp&#39; to defer some action, such as starting actors,
    # until the cluster has reached a certain size.
    min-nr-of-members = 1

    # Enable/disable info level logging of cluster events.
    # These are logged with logger name `akka.cluster.Cluster`.
    log-info = on

    # Enable/disable verbose info-level logging of cluster events
    # for temporary troubleshooting. Defaults to &#39;off&#39;.
    # These are logged with logger name `akka.cluster.Cluster`.
    log-info-verbose = off

    # Enable or disable JMX MBeans for management of the cluster
    jmx.enabled = on

    # Enable or disable multiple JMX MBeans in the same JVM
    # If this is disabled, the MBean Object name is &quot;akka:type=Cluster&quot;
    # If this is enabled, them MBean Object names become &quot;akka:type=Cluster,port=$clusterPortNumber&quot;
    jmx.multi-mbeans-in-same-jvm = off

    # how long should the node wait before starting the periodic tasks
    # maintenance tasks?
    periodic-tasks-initial-delay = 1s

    # how often should the node send out gossip information?
    gossip-interval = 1s
    
    # discard incoming gossip messages if not handled within this duration
    gossip-time-to-live = 2s

    # how often should the leader perform maintenance tasks?
    leader-actions-interval = 1s

    # how often should the node move nodes, marked as unreachable by the failure
    # detector, out of the membership ring?
    unreachable-nodes-reaper-interval = 1s

    # How often the current internal stats should be published.
    # A value of 0s can be used to always publish the stats, when it happens.
    # Disable with &quot;off&quot;.
    publish-stats-interval = off

    # The id of the dispatcher to use for cluster actors.
    # If specified you need to define the settings of the actual dispatcher.
    use-dispatcher = &quot;akka.actor.internal-dispatcher&quot;

    # Gossip to random node with newer or older state information, if any with
    # this probability. Otherwise Gossip to any random live node.
    # Probability value is between 0.0 and 1.0. 0.0 means never, 1.0 means always.
    gossip-different-view-probability = 0.8
    
    # Reduced the above probability when the number of nodes in the cluster
    # greater than this value.
    reduce-gossip-different-view-probability = 400

    # When a node is removed the removal is marked with a tombstone
    # which is kept at least this long, after which it is pruned, if there is a partition
    # longer than this it could lead to removed nodes being re-added to the cluster
    prune-gossip-tombstones-after = 24h

    # Settings for the Phi accrual failure detector (http://www.jaist.ac.jp/~defago/files/pdf/IS_RR_2004_010.pdf
    # [Hayashibara et al]) used by the cluster subsystem to detect unreachable
    # members.
    # The default PhiAccrualFailureDetector will trigger if there are no heartbeats within
    # the duration heartbeat-interval + acceptable-heartbeat-pause + threshold_adjustment,
    # i.e. around 5.5 seconds with default settings.
    failure-detector {

      # FQCN of the failure detector implementation.
      # It must implement akka.remote.FailureDetector and have
      # a public constructor with a com.typesafe.config.Config and
      # akka.actor.EventStream parameter.
      implementation-class = &quot;akka.remote.PhiAccrualFailureDetector&quot;

      # How often keep-alive heartbeat messages should be sent to each connection.
      heartbeat-interval = 1 s

      # Defines the failure detector threshold.
      # A low threshold is prone to generate many wrong suspicions but ensures
      # a quick detection in the event of a real crash. Conversely, a high
      # threshold generates fewer mistakes but needs more time to detect
      # actual crashes.
      threshold = 8.0

      # Number of the samples of inter-heartbeat arrival times to adaptively
      # calculate the failure timeout for connections.
      max-sample-size = 1000

      # Minimum standard deviation to use for the normal distribution in
      # AccrualFailureDetector. Too low standard deviation might result in
      # too much sensitivity for sudden, but normal, deviations in heartbeat
      # inter arrival times.
      min-std-deviation = 100 ms

      # Number of potentially lost/delayed heartbeats that will be
      # accepted before considering it to be an anomaly.
      # This margin is important to be able to survive sudden, occasional,
      # pauses in heartbeat arrivals, due to for example garbage collect or
      # network drop.
      acceptable-heartbeat-pause = 3 s

      # Number of member nodes that each member will send heartbeat messages to,
      # i.e. each node will be monitored by this number of other nodes.
      monitored-by-nr-of-members = 9
      
      # After the heartbeat request has been sent the first failure detection
      # will start after this period, even though no heartbeat message has
      # been received.
      expected-response-after = 1 s

    }

    # Configures multi-dc specific heartbeating and other mechanisms,
    # many of them have a direct counter-part in &quot;one datacenter mode&quot;,
    # in which case these settings would not be used at all - they only apply,
    # if your cluster nodes are configured with at-least 2 different `akka.cluster.data-center` values.
    multi-data-center {

      # Defines which data center this node belongs to. It is typically used to make islands of the
      # cluster that are colocated. This can be used to make the cluster aware that it is running
      # across multiple availability zones or regions. It can also be used for other logical
      # grouping of nodes.
      self-data-center = &quot;default&quot;


      # Try to limit the number of connections between data centers. Used for gossip and heartbeating.
      # This will not limit connections created for the messaging of the application.
      # If the cluster does not span multiple data centers, this value has no effect.
      cross-data-center-connections = 5

      # The n oldest nodes in a data center will choose to gossip to another data center with
      # this probability. Must be a value between 0.0 and 1.0 where 0.0 means never, 1.0 means always.
      # When a data center is first started (nodes &lt; 5) a higher probability is used so other data
      # centers find out about the new nodes more quickly
      cross-data-center-gossip-probability = 0.2

      failure-detector {
        # FQCN of the failure detector implementation.
        # It must implement akka.remote.FailureDetector and have
        # a public constructor with a com.typesafe.config.Config and
        # akka.actor.EventStream parameter.
        implementation-class = &quot;akka.remote.DeadlineFailureDetector&quot;
  
        # Number of potentially lost/delayed heartbeats that will be
        # accepted before considering it to be an anomaly.
        # This margin is important to be able to survive sudden, occasional,
        # pauses in heartbeat arrivals, due to for example garbage collect or
        # network drop.
        acceptable-heartbeat-pause = 10 s
        
        # How often keep-alive heartbeat messages should be sent to each connection.
        heartbeat-interval = 3 s
  
        # After the heartbeat request has been sent the first failure detection
        # will start after this period, even though no heartbeat message has
        # been received.
        expected-response-after = 1 s
      }
    }

    # If the tick-duration of the default scheduler is longer than the
    # tick-duration configured here a dedicated scheduler will be used for
    # periodic tasks of the cluster, otherwise the default scheduler is used.
    # See akka.scheduler settings for more details.
    scheduler {
      tick-duration = 33ms
      ticks-per-wheel = 512
    }

    debug {
      # Log heartbeat events (very verbose, useful mostly when debugging heartbeating issues).
      # These are logged with logger name `akka.cluster.ClusterHeartbeat`.
      verbose-heartbeat-logging = off

      # log verbose details about gossip
      verbose-gossip-logging = off
    }

    configuration-compatibility-check {

      # Enforce configuration compatibility checks when joining a cluster.
      # Set to off to allow joining nodes to join a cluster even when configuration incompatibilities are detected or
      # when the cluster does not support this feature. Compatibility checks are always performed and warning and
      # error messages are logged.
      #
      # This is particularly useful for rolling updates on clusters that do not support that feature. Since the old
      # cluster won&#39;t be able to send the compatibility confirmation to the joining node, the joining node won&#39;t be able
      # to &#39;know&#39; if its allowed to join.
      enforce-on-join = on

      # Add named entry to this section with fully qualified class name of the JoinConfigCompatChecker
      # to enable.
      # Checkers defined in reference.conf can be disabled by application by using empty string value
      # for the named entry.
      checkers {
        akka-cluster = &quot;akka.cluster.JoinConfigCompatCheckCluster&quot;
      }

      # Some configuration properties might not be appropriate to transfer between nodes
      # and such properties can be excluded from the configuration compatibility check by adding
      # the paths of the properties to this list. Sensitive paths are grouped by key. Modules and third-party libraries
      # can define their own set of sensitive paths without clashing with each other (as long they use unique keys).
      #
      # All properties starting with the paths defined here are excluded, i.e. you can add the path of a whole
      # section here to skip everything inside that section.
      sensitive-config-paths {
        akka = [
          &quot;user.home&quot;, &quot;user.name&quot;, &quot;user.dir&quot;,
          &quot;socksNonProxyHosts&quot;, &quot;http.nonProxyHosts&quot;, &quot;ftp.nonProxyHosts&quot;,
          &quot;akka.remote.secure-cookie&quot;,
          &quot;akka.remote.classic.netty.ssl.security&quot;,
          # Pre 2.6 path, keep around to avoid sending things misconfigured with old paths
          &quot;akka.remote.netty.ssl.security&quot;,
          &quot;akka.remote.artery.ssl&quot;
        ]
      }

    }
  }

  actor.deployment.default.cluster {
    # enable cluster aware router that deploys to nodes in the cluster
    enabled = off

    # Maximum number of routees that will be deployed on each cluster
    # member node.
    # Note that max-total-nr-of-instances defines total number of routees, but
    # number of routees per node will not be exceeded, i.e. if you
    # define max-total-nr-of-instances = 50 and max-nr-of-instances-per-node = 2
    # it will deploy 2 routees per new member in the cluster, up to
    # 25 members.
    max-nr-of-instances-per-node = 1
    
    # Maximum number of routees that will be deployed, in total
    # on all nodes. See also description of max-nr-of-instances-per-node.
    # For backwards compatibility reasons, nr-of-instances
    # has the same purpose as max-total-nr-of-instances for cluster
    # aware routers and nr-of-instances (if defined by user) takes
    # precedence over max-total-nr-of-instances. 
    max-total-nr-of-instances = 10000

    # Defines if routees are allowed to be located on the same node as
    # the head router actor, or only on remote nodes.
    # Useful for master-worker scenario where all routees are remote.
    allow-local-routees = on

    # Use members with all specified roles, or all members if undefined or empty.
    use-roles = []

    # Deprecated, since Akka 2.5.4, replaced by use-roles
    # Use members with specified role, or all members if undefined or empty.
    use-role = &quot;&quot;
  }

  # Protobuf serializer for cluster messages
  actor {
    serializers {
      akka-cluster = &quot;akka.cluster.protobuf.ClusterMessageSerializer&quot;
    }

    serialization-bindings {
      &quot;akka.cluster.ClusterMessage&quot; = akka-cluster
      &quot;akka.cluster.routing.ClusterRouterPool&quot; = akka-cluster
    }
    
    serialization-identifiers {
      &quot;akka.cluster.protobuf.ClusterMessageSerializer&quot; = 5
    }
    
  }

}</code></pre>
<a id="config-akka-discovery"></a>
<h3><a href="#akka-discovery" name="akka-discovery" class="anchor"><span class="anchor-link"></span></a>akka-discovery</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-discovery/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">######################################################
# Akka Discovery Config                              #
######################################################

akka.actor.deployment {
  &quot;/SD-DNS/async-dns&quot; {
    mailbox = &quot;unbounded&quot;
    router = &quot;round-robin-pool&quot;
    nr-of-instances = 1
  }
}

akka.discovery {

  # Users MUST configure this value to set the default discovery method.
  #
  # The value can be an implementation config path name, such as &quot;akka-dns&quot;,
  # which would attempt to resolve as `akka.discovery.akka-dns` which is expected
  # to contain a `class` setting. As fallback, the root `akka-dns` setting scope
  # would be used. If none of those contained a `class` setting, then the value is
  # assumed to be a class name, and an attempt is made to instantiate it.
  method = &quot;&lt;method&gt;&quot;

  # Config based service discovery
  config {
    class = akka.discovery.config.ConfigServiceDiscovery

    # Location of the services in configuration
    services-path = &quot;akka.discovery.config.services&quot;

    # A map of services to resolve from configuration.
    # See docs for more examples.
    # A list of endpoints with host/port where port is optional e.g.
    # services {
    #  service1 {
    #    endpoints = [
    #      {
    #        host = &quot;cat.com&quot;
    #        port = 1233
    #      },
    #      {
    #        host = &quot;dog.com&quot;
    #      }
    #    ]
    #  },
    #  service2 {
    #    endpoints = [
    #    {
    #        host = &quot;fish.com&quot;
    #        port = 1233
    #      }
    #    ]
    #  }
    # }
    services = {

    }
  }

  # Aggregate multiple service discovery mechanisms
  aggregate {
    class = akka.discovery.aggregate.AggregateServiceDiscovery

    # List of service discovery methods to try in order. E.g config then fall back to DNS
    # [&quot;config&quot;, &quot;akka-dns&quot;]
    discovery-methods = []

  }

  # DNS based service discovery
  akka-dns {
    class = akka.discovery.dns.DnsServiceDiscovery
  }
}
</code></pre>
<a id="config-akka-coordination"></a>
<h3><a href="#akka-coordination" name="akka-coordination" class="anchor"><span class="anchor-link"></span></a>akka-coordination</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-coordination/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">akka.coordination {

  # Defaults for any lease implementation that doesn&#39;t include these properties
  lease {

    # FQCN of the implementation of the Lease
    lease-class = &quot;&quot;

    #defaults
    # if the node that acquired the leases crashes, how long should the lease be held before another owner can get it
    heartbeat-timeout = 120s

    # interval for communicating with the third party to confirm the lease is still held
    heartbeat-interval = 12s

    # lease implementations are expected to time out acquire and release calls or document
    # that they do not implement an operation timeout
    lease-operation-timeout = 5s

    #defaults
  }
}</code></pre>
<a id="config-akka-multi-node-testkit"></a>
<h3><a href="#akka-multi-node-testkit" name="akka-multi-node-testkit" class="anchor"><span class="anchor-link"></span></a>akka-multi-node-testkit</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-multi-node-testkit/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">#############################################
# Akka Remote Testing Reference Config File #
#############################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

akka {
  testconductor {

    # Timeout for joining a barrier: this is the maximum time any participants
    # waits for everybody else to join a named barrier.
    barrier-timeout = 30s
    
    # Timeout for interrogation of TestConductor’s Controller actor
    query-timeout = 10s
    
    # Threshold for packet size in time unit above which the failure injector will
    # split the packet and deliver in smaller portions; do not give value smaller
    # than HashedWheelTimer resolution (would not make sense)
    packet-split-threshold = 100ms
    
    # amount of time for the ClientFSM to wait for the connection to the conductor
    # to be successful
    connect-timeout = 20s
    
    # Number of connect attempts to be made to the conductor controller
    client-reconnects = 30
    
    # minimum time interval which is to be inserted between reconnect attempts
    reconnect-backoff = 1s

    netty {
      # (I&amp;O) Used to configure the number of I/O worker threads on server sockets
      server-socket-worker-pool {
        # Min number of threads to cap factor-based number to
        pool-size-min = 1

        # The pool size factor is used to determine thread pool size
        # using the following formula: ceil(available processors * factor).
        # Resulting size is then bounded by the pool-size-min and
        # pool-size-max values.
        pool-size-factor = 1.0

        # Max number of threads to cap factor-based number to
        pool-size-max = 2
      }

      # (I&amp;O) Used to configure the number of I/O worker threads on client sockets
      client-socket-worker-pool {
        # Min number of threads to cap factor-based number to
        pool-size-min = 1

        # The pool size factor is used to determine thread pool size
        # using the following formula: ceil(available processors * factor).
        # Resulting size is then bounded by the pool-size-min and
        # pool-size-max values.
        pool-size-factor = 1.0

        # Max number of threads to cap factor-based number to
        pool-size-max = 2
      }
    }
  }
}</code></pre>
<a id="config-akka-persistence-typed"></a>
<h3><a href="#akka-persistence-typed" name="akka-persistence-typed" class="anchor"><span class="anchor-link"></span></a>akka-persistence-typed</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-persistence-typed/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">akka.persistence.typed {

  # Persistent actors stash while recovering or persisting events,
  # this setting configures the default capacity of this stash.
  #
  # Stashing is always bounded to the size that is defined in this setting.
  # You can set it to large values, however &quot;unbounded&quot; buffering is not supported.
  # Negative or 0 values are not allowed.
  stash-capacity = 4096

  # Configure how to react when the event sourced stash overflows. This can happen in two scenarios:
  # when a event sourced actor is doing recovery, persisting or snapshotting and it gets more than
  # &#39;stash-capacity&#39; commands, or if more than &#39;stash-capacity&#39; commands are manually stashed with the
  # &#39;stash&#39; effect.
  #
  # Possible options
  # - drop - the message is published as a akka.actor.typed.Dropped message on the event bus
  # - fail - an exception is thrown so that the actor is failed
  stash-overflow-strategy = &quot;drop&quot;

  # enables automatic DEBUG level logging of messages stashed automatically by an EventSourcedBehavior,
  # this may happen while it receives commands while it is recovering events or while it is persisting events
  log-stashing = off

}</code></pre>
<a id="config-akka-persistence"></a>
<h3><a href="#akka-persistence" name="akka-persistence" class="anchor"><span class="anchor-link"></span></a>akka-persistence</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-persistence/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">###########################################################
# Akka Persistence Extension Reference Configuration File #
###########################################################

# This is the reference config file that contains all the default settings.
# Make your edits in your application.conf in order to override these settings.

# Directory of persistence journal and snapshot store plugins is available at the 
# Akka Community Projects page http://akka.io/community/

# Default persistence extension settings.
akka.persistence {

    # When starting many persistent actors at the same time the journal
    # and its data store is protected from being overloaded by limiting number
    # of recoveries that can be in progress at the same time. When
    # exceeding the limit the actors will wait until other recoveries have
    # been completed.   
    max-concurrent-recoveries = 50

    # Fully qualified class name providing a default internal stash overflow strategy.
    # It needs to be a subclass of akka.persistence.StashOverflowStrategyConfigurator.
    # The default strategy throws StashOverflowException.
    internal-stash-overflow-strategy = &quot;akka.persistence.ThrowExceptionConfigurator&quot;
    journal {
        # Absolute path to the journal plugin configuration entry used by 
        # persistent actor by default.
        # Persistent actor can override `journalPluginId` method 
        # in order to rely on a different journal plugin.
        plugin = &quot;&quot;
        # List of journal plugins to start automatically. Use &quot;&quot; for the default journal plugin.
        auto-start-journals = []
    }
    snapshot-store {
        # Absolute path to the snapshot plugin configuration entry used by
        # persistent actor by default.
        # Persistent actor can override `snapshotPluginId` method
        # in order to rely on a different snapshot plugin.
        # It is not mandatory to specify a snapshot store plugin.
        # If you don&#39;t use snapshots you don&#39;t have to configure it.
        # Note that Cluster Sharding is using snapshots, so if you
        # use Cluster Sharding you need to define a snapshot store plugin. 
        plugin = &quot;&quot;
        # List of snapshot stores to start automatically. Use &quot;&quot; for the default snapshot store.
        auto-start-snapshot-stores = []
    }
    # used as default-snapshot store if no plugin configured 
    # (see `akka.persistence.snapshot-store`)
    no-snapshot-store {
      class = &quot;akka.persistence.snapshot.NoSnapshotStore&quot;
    }
    # Default reliable delivery settings.
    at-least-once-delivery {
        # Interval between re-delivery attempts.
        redeliver-interval = 5s
        # Maximum number of unconfirmed messages that will be sent in one 
        # re-delivery burst.
        redelivery-burst-limit = 10000
        # After this number of delivery attempts a 
        # `ReliableRedelivery.UnconfirmedWarning`, message will be sent to the actor.
        warn-after-number-of-unconfirmed-attempts = 5
        # Maximum number of unconfirmed messages that an actor with 
        # AtLeastOnceDelivery is allowed to hold in memory.
        max-unconfirmed-messages = 100000
    }
    # Default persistent extension thread pools.
    dispatchers {
        # Dispatcher used by every plugin which does not declare explicit
        # `plugin-dispatcher` field.
        default-plugin-dispatcher {
            type = PinnedDispatcher
            executor = &quot;thread-pool-executor&quot;
        }
        # Default dispatcher for message replay.
        default-replay-dispatcher {
            type = Dispatcher
            executor = &quot;fork-join-executor&quot;
            fork-join-executor {
                parallelism-min = 2
                parallelism-max = 8
            }
        }
        # Default dispatcher for streaming snapshot IO
        default-stream-dispatcher {
            type = Dispatcher
            executor = &quot;fork-join-executor&quot;
            fork-join-executor {
                parallelism-min = 2
                parallelism-max = 8
            }
        }
    }

    # Fallback settings for journal plugin configurations.
    # These settings are used if they are not defined in plugin config section.
    journal-plugin-fallback {

      # Fully qualified class name providing journal plugin api implementation.
      # It is mandatory to specify this property.
      # The class must have a constructor without parameters or constructor with
      # one `com.typesafe.config.Config` parameter.
      class = &quot;&quot;

      # Dispatcher for the plugin actor.
      plugin-dispatcher = &quot;akka.persistence.dispatchers.default-plugin-dispatcher&quot;

      # Dispatcher for message replay.
      replay-dispatcher = &quot;akka.persistence.dispatchers.default-replay-dispatcher&quot;

      # Removed: used to be the Maximum size of a persistent message batch written to the journal.
      # Now this setting is without function, PersistentActor will write as many messages
      # as it has accumulated since the last write.
      max-message-batch-size = 200

      # If there is more time in between individual events gotten from the journal
      # recovery than this the recovery will fail.
      # Note that it also affects reading the snapshot before replaying events on
      # top of it, even though it is configured for the journal.
      recovery-event-timeout = 30s

      circuit-breaker {
        max-failures = 10
        call-timeout = 10s
        reset-timeout = 30s
      }

      # The replay filter can detect a corrupt event stream by inspecting
      # sequence numbers and writerUuid when replaying events.
      replay-filter {
        # What the filter should do when detecting invalid events.
        # Supported values:
        # `repair-by-discard-old` : discard events from old writers,
        #                           warning is logged
        # `fail` : fail the replay, error is logged
        # `warn` : log warning but emit events untouched
        # `off` : disable this feature completely
        mode = repair-by-discard-old

        # It uses a look ahead buffer for analyzing the events.
        # This defines the size (in number of events) of the buffer.
        window-size = 100

        # How many old writerUuid to remember
        max-old-writers = 10

        # Set this to `on` to enable detailed debug logging of each
        # replayed event.
        debug = off
      }
    }

    # Fallback settings for snapshot store plugin configurations
    # These settings are used if they are not defined in plugin config section.
    snapshot-store-plugin-fallback {

      # Fully qualified class name providing snapshot store plugin api
      # implementation. It is mandatory to specify this property if
      # snapshot store is enabled.
      # The class must have a constructor without parameters or constructor with
      # one `com.typesafe.config.Config` parameter.
      class = &quot;&quot;

      # Dispatcher for the plugin actor.
      plugin-dispatcher = &quot;akka.persistence.dispatchers.default-plugin-dispatcher&quot;

      circuit-breaker {
        max-failures = 5
        call-timeout = 20s
        reset-timeout = 60s
      }
    }

  fsm {
    # PersistentFSM saves snapshots after this number of persistent
    # events. Snapshots are used to reduce recovery times.
    # When you disable this feature, specify snapshot-after = off.
    # To enable the feature, specify a number like snapshot-after = 1000
    # which means a snapshot is taken after persisting every 1000 events.
    snapshot-after = off
  }
}

# Protobuf serialization for the persistent extension messages.
akka.actor {
    serializers {
        akka-persistence-message = &quot;akka.persistence.serialization.MessageSerializer&quot;
        akka-persistence-snapshot = &quot;akka.persistence.serialization.SnapshotSerializer&quot;
    }
    serialization-bindings {
        &quot;akka.persistence.serialization.Message&quot; = akka-persistence-message
        &quot;akka.persistence.serialization.Snapshot&quot; = akka-persistence-snapshot
    }
    serialization-identifiers {
        &quot;akka.persistence.serialization.MessageSerializer&quot; = 7
        &quot;akka.persistence.serialization.SnapshotSerializer&quot; = 8
    }
}


###################################################
# Persistence plugins included with the extension #
###################################################

# In-memory journal plugin.
akka.persistence.journal.inmem {
    # Class name of the plugin.
    class = &quot;akka.persistence.journal.inmem.InmemJournal&quot;
    # Dispatcher for the plugin actor.
    plugin-dispatcher = &quot;akka.actor.default-dispatcher&quot;

    # Turn this on to test serialization of the events
    test-serialization = off
}

# Local file system snapshot store plugin.
akka.persistence.snapshot-store.local {
    # Class name of the plugin.
    class = &quot;akka.persistence.snapshot.local.LocalSnapshotStore&quot;
    # Dispatcher for the plugin actor.
    plugin-dispatcher = &quot;akka.persistence.dispatchers.default-plugin-dispatcher&quot;
    # Dispatcher for streaming snapshot IO.
    stream-dispatcher = &quot;akka.persistence.dispatchers.default-stream-dispatcher&quot;
    # Storage location of snapshot files.
    dir = &quot;snapshots&quot;
    # Number load attempts when recovering from the latest snapshot fails
    # yet older snapshot files are available. Each recovery attempt will try
    # to recover using an older than previously failed-on snapshot file 
    # (if any are present). If all attempts fail the recovery will fail and
    # the persistent actor will be stopped.
    max-load-attempts = 3
}

# LevelDB journal plugin.
# Note: this plugin requires explicit LevelDB dependency, see below. 
akka.persistence.journal.leveldb {
    # Class name of the plugin.
    class = &quot;akka.persistence.journal.leveldb.LeveldbJournal&quot;
    # Dispatcher for the plugin actor.
    plugin-dispatcher = &quot;akka.persistence.dispatchers.default-plugin-dispatcher&quot;
    # Dispatcher for message replay.
    replay-dispatcher = &quot;akka.persistence.dispatchers.default-replay-dispatcher&quot;
    # Storage location of LevelDB files.
    dir = &quot;journal&quot;
    # Use fsync on write.
    fsync = on
    # Verify checksum on read.
    checksum = off
    # Native LevelDB (via JNI) or LevelDB Java port.
    native = on
    # Number of deleted messages per persistence id that will trigger journal compaction
    compaction-intervals {
    }
}

# Shared LevelDB journal plugin (for testing only).
# Note: this plugin requires explicit LevelDB dependency, see below. 
akka.persistence.journal.leveldb-shared {
    # Class name of the plugin.
    class = &quot;akka.persistence.journal.leveldb.SharedLeveldbJournal&quot;
    # Dispatcher for the plugin actor.
    plugin-dispatcher = &quot;akka.actor.default-dispatcher&quot;
    # Timeout for async journal operations.
    timeout = 10s
    store {
        # Dispatcher for shared store actor.
        store-dispatcher = &quot;akka.persistence.dispatchers.default-plugin-dispatcher&quot;
        # Dispatcher for message replay.
        replay-dispatcher = &quot;akka.persistence.dispatchers.default-replay-dispatcher&quot;
        # Storage location of LevelDB files.
        dir = &quot;journal&quot;
        # Use fsync on write.
        fsync = on
        # Verify checksum on read.
        checksum = off
        # Native LevelDB (via JNI) or LevelDB Java port.
        native = on
        # Number of deleted messages per persistence id that will trigger journal compaction
        compaction-intervals {
        }
    }
}

akka.persistence.journal.proxy {
  # Class name of the plugin.
  class = &quot;akka.persistence.journal.PersistencePluginProxy&quot;
  # Dispatcher for the plugin actor.
  plugin-dispatcher = &quot;akka.actor.default-dispatcher&quot;
  # Set this to on in the configuration of the ActorSystem
  # that will host the target journal
  start-target-journal = off
  # The journal plugin config path to use for the target journal
  target-journal-plugin = &quot;&quot;
  # The address of the proxy to connect to from other nodes. Optional setting.
  target-journal-address = &quot;&quot;
  # Initialization timeout of target lookup
  init-timeout = 10s
}

akka.persistence.snapshot-store.proxy {
  # Class name of the plugin.
  class = &quot;akka.persistence.journal.PersistencePluginProxy&quot;
  # Dispatcher for the plugin actor.
  plugin-dispatcher = &quot;akka.actor.default-dispatcher&quot;
  # Set this to on in the configuration of the ActorSystem
  # that will host the target snapshot-store
  start-target-snapshot-store = off
  # The journal plugin config path to use for the target snapshot-store
  target-snapshot-store-plugin = &quot;&quot;
  # The address of the proxy to connect to from other nodes. Optional setting.
  target-snapshot-store-address = &quot;&quot;
  # Initialization timeout of target lookup
  init-timeout = 10s
}

# LevelDB persistence requires the following dependency declarations:
#
# SBT:
#       &quot;org.iq80.leveldb&quot;            % &quot;leveldb&quot;          % &quot;0.7&quot;
#       &quot;org.fusesource.leveldbjni&quot;   % &quot;leveldbjni-all&quot;   % &quot;1.8&quot;
#
# Maven:
#        &lt;dependency&gt;
#            &lt;groupId&gt;org.iq80.leveldb&lt;/groupId&gt;
#            &lt;artifactId&gt;leveldb&lt;/artifactId&gt;
#            &lt;version&gt;0.7&lt;/version&gt;
#        &lt;/dependency&gt;
#        &lt;dependency&gt;
#            &lt;groupId&gt;org.fusesource.leveldbjni&lt;/groupId&gt;
#            &lt;artifactId&gt;leveldbjni-all&lt;/artifactId&gt;
#            &lt;version&gt;1.8&lt;/version&gt;
#        &lt;/dependency&gt;</code></pre>
<a id="config-akka-persistence-query"></a>
<h3><a href="#akka-persistence-query" name="akka-persistence-query" class="anchor"><span class="anchor-link"></span></a>akka-persistence-query</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-persistence-query/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">#######################################################
# Akka Persistence Query Reference Configuration File #
#######################################################

# This is the reference config file that contains all the default settings.
# Make your edits in your application.conf in order to override these settings.

#//#query-leveldb
# Configuration for the LeveldbReadJournal
akka.persistence.query.journal.leveldb {
  # Implementation class of the LevelDB ReadJournalProvider
  class = &quot;akka.persistence.query.journal.leveldb.LeveldbReadJournalProvider&quot;
  
  # Absolute path to the write journal plugin configuration entry that this 
  # query journal will connect to. That must be a LeveldbJournal or SharedLeveldbJournal.
  # If undefined (or &quot;&quot;) it will connect to the default journal as specified by the
  # akka.persistence.journal.plugin property.
  write-plugin = &quot;&quot;
  
  # The LevelDB write journal is notifying the query side as soon as things
  # are persisted, but for efficiency reasons the query side retrieves the events 
  # in batches that sometimes can be delayed up to the configured `refresh-interval`.
  refresh-interval = 3s
  
  # How many events to fetch in one query (replay) and keep buffered until they
  # are delivered downstreams.
  max-buffer-size = 100
}
#//#query-leveldb</code></pre>
<a id="config-akka-remote-artery"></a>
<h3><a href="#akka-remote-artery" name="akka-remote-artery" class="anchor"><span class="anchor-link"></span></a>akka-remote artery</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-remote/src/main/resources/reference.conf#L2-L253" target="_blank" title="Go to snippet source"></a><code class="language-none">#####################################
# Akka Remote Reference Config File #
#####################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

# comments about akka.actor settings left out where they are already in akka-
# actor.jar, because otherwise they would be repeated in config rendering.
#
# For the configuration of the new remoting implementation (Artery) please look
# at the bottom section of this file as it is listed separately.

akka {

  actor {

    serializers {
      akka-containers = &quot;akka.remote.serialization.MessageContainerSerializer&quot;
      akka-misc = &quot;akka.remote.serialization.MiscMessageSerializer&quot;
      artery = &quot;akka.remote.serialization.ArteryMessageSerializer&quot;
      proto = &quot;akka.remote.serialization.ProtobufSerializer&quot;
      daemon-create = &quot;akka.remote.serialization.DaemonMsgCreateSerializer&quot;
      akka-system-msg = &quot;akka.remote.serialization.SystemMessageSerializer&quot;
    }

    serialization-bindings {
      &quot;akka.actor.ActorSelectionMessage&quot; = akka-containers

      &quot;akka.remote.DaemonMsgCreate&quot; = daemon-create

      &quot;akka.remote.artery.ArteryMessage&quot; = artery

      # Since akka.protobuf.Message does not extend Serializable but
      # GeneratedMessage does, need to use the more specific one here in order
      # to avoid ambiguity.
      # This is only loaded if akka-protobuf is on the classpath
      # It should not be used and users should migrate to using the protobuf classes
      # directly
      # Remove in 2.7
      &quot;akka.protobuf.GeneratedMessage&quot; = proto

      &quot;akka.protobufv3.internal.GeneratedMessageV3&quot; = proto

      # Since com.google.protobuf.Message does not extend Serializable but
      # GeneratedMessage does, need to use the more specific one here in order
      # to avoid ambiguity.
      # This com.google.protobuf serialization binding is only used if the class can be loaded,
      # i.e. com.google.protobuf dependency has been added in the application project.
      &quot;com.google.protobuf.GeneratedMessage&quot; = proto
      &quot;com.google.protobuf.GeneratedMessageV3&quot; = proto

      &quot;akka.actor.Identify&quot; = akka-misc
      &quot;akka.actor.ActorIdentity&quot; = akka-misc
      &quot;scala.Some&quot; = akka-misc
      &quot;scala.None$&quot; = akka-misc
      &quot;java.util.Optional&quot; = akka-misc
      &quot;akka.actor.Status$Success&quot; = akka-misc
      &quot;akka.actor.Status$Failure&quot; = akka-misc
      &quot;akka.actor.ActorRef&quot; = akka-misc
      &quot;akka.actor.PoisonPill$&quot; = akka-misc
      &quot;akka.actor.Kill$&quot; = akka-misc
      &quot;akka.remote.RemoteWatcher$Heartbeat$&quot; = akka-misc
      &quot;akka.remote.RemoteWatcher$HeartbeatRsp&quot; = akka-misc
      &quot;akka.Done&quot; = akka-misc
      &quot;akka.NotUsed&quot; = akka-misc
      &quot;akka.actor.Address&quot; = akka-misc
      &quot;akka.remote.UniqueAddress&quot; = akka-misc

      &quot;akka.actor.ActorInitializationException&quot; = akka-misc
      &quot;akka.actor.IllegalActorStateException&quot; = akka-misc
      &quot;akka.actor.ActorKilledException&quot; = akka-misc
      &quot;akka.actor.InvalidActorNameException&quot; = akka-misc
      &quot;akka.actor.InvalidMessageException&quot; = akka-misc
      &quot;java.util.concurrent.TimeoutException&quot; = akka-misc
      &quot;akka.remote.serialization.ThrowableNotSerializableException&quot; = akka-misc

      &quot;akka.actor.LocalScope$&quot; = akka-misc
      &quot;akka.remote.RemoteScope&quot; = akka-misc

      &quot;com.typesafe.config.impl.SimpleConfig&quot; = akka-misc
      &quot;com.typesafe.config.Config&quot; = akka-misc

      &quot;akka.routing.FromConfig&quot; = akka-misc
      &quot;akka.routing.DefaultResizer&quot; = akka-misc
      &quot;akka.routing.BalancingPool&quot; = akka-misc
      &quot;akka.routing.BroadcastGroup&quot; = akka-misc
      &quot;akka.routing.BroadcastPool&quot; = akka-misc
      &quot;akka.routing.RandomGroup&quot; = akka-misc
      &quot;akka.routing.RandomPool&quot; = akka-misc
      &quot;akka.routing.RoundRobinGroup&quot; = akka-misc
      &quot;akka.routing.RoundRobinPool&quot; = akka-misc
      &quot;akka.routing.ScatterGatherFirstCompletedGroup&quot; = akka-misc
      &quot;akka.routing.ScatterGatherFirstCompletedPool&quot; = akka-misc
      &quot;akka.routing.SmallestMailboxPool&quot; = akka-misc
      &quot;akka.routing.TailChoppingGroup&quot; = akka-misc
      &quot;akka.routing.TailChoppingPool&quot; = akka-misc
      &quot;akka.remote.routing.RemoteRouterConfig&quot; = akka-misc

      &quot;akka.dispatch.sysmsg.SystemMessage&quot; = akka-system-msg

      # Java Serializer is by default used for exceptions and will by default
      # not be allowed to be serialized, but in certain cases they are replaced
      # by `akka.remote.serialization.ThrowableNotSerializableException` if
      # no specific serializer has been defined:
      # - when wrapped in `akka.actor.Status.Failure` for ask replies
      # - when wrapped in system messages for exceptions from remote deployed child actors
      #
      # It&#39;s recommended that you implement custom serializer for exceptions that are
      # sent remotely, You can add binding to akka-misc (MiscMessageSerializer) for the
      # exceptions that have a constructor with single message String or constructor with
      # message String as first parameter and cause Throwable as second parameter. Note that it&#39;s not
      # safe to add this binding for general exceptions such as IllegalArgumentException
      # because it may have a subclass without required constructor.
      &quot;java.lang.Throwable&quot; = java
    }

    serialization-identifiers {
      &quot;akka.remote.serialization.ProtobufSerializer&quot; = 2
      &quot;akka.remote.serialization.DaemonMsgCreateSerializer&quot; = 3
      &quot;akka.remote.serialization.MessageContainerSerializer&quot; = 6
      &quot;akka.remote.serialization.MiscMessageSerializer&quot; = 16
      &quot;akka.remote.serialization.ArteryMessageSerializer&quot; = 17

      &quot;akka.remote.serialization.SystemMessageSerializer&quot; = 22

      # deprecated in 2.6.0, moved to akka-actor
      &quot;akka.remote.serialization.LongSerializer&quot; = 18
      # deprecated in 2.6.0, moved to akka-actor
      &quot;akka.remote.serialization.IntSerializer&quot; = 19
      # deprecated in 2.6.0, moved to akka-actor
      &quot;akka.remote.serialization.StringSerializer&quot; = 20
      # deprecated in 2.6.0, moved to akka-actor
      &quot;akka.remote.serialization.ByteStringSerializer&quot; = 21
    }

    deployment {

      default {

        # if this is set to a valid remote address, the named actor will be
        # deployed at that node e.g. &quot;akka://sys@host:port&quot;
        remote = &quot;&quot;

        target {

          # A list of hostnames and ports for instantiating the children of a
          # router
          #   The format should be on &quot;akka://sys@host:port&quot;, where:
          #    - sys is the remote actor system name
          #    - hostname can be either hostname or IP address the remote actor
          #      should connect to
          #    - port should be the port for the remote server on the other node
          # The number of actor instances to be spawned is still taken from the
          # nr-of-instances setting as for local routers; the instances will be
          # distributed round-robin among the given nodes.
          nodes = []

        }
      }
    }
  }

  remote {
    ### Settings shared by classic remoting and Artery (the new implementation of remoting)

    # Using remoting directly is typically not desirable, so a warning will
    # be shown to make this clear. Set this setting to &#39;off&#39; to suppress that
    # warning.
    warn-about-direct-use = on


    # If Cluster is not used, remote watch and deployment are disabled.
    # To optionally use them while not using Cluster, set to &#39;on&#39;.
    use-unsafe-remote-features-outside-cluster = off

    # A warning will be logged on remote watch attempts if Cluster
    # is not in use and &#39;use-unsafe-remote-features-outside-cluster&#39;
    # is &#39;off&#39;. Set this to &#39;off&#39; to suppress these.
    warn-unsafe-watch-outside-cluster = on

    # Settings for the Phi accrual failure detector (http://www.jaist.ac.jp/~defago/files/pdf/IS_RR_2004_010.pdf
    # [Hayashibara et al]) used for remote death watch.
    # The default PhiAccrualFailureDetector will trigger if there are no heartbeats within
    # the duration heartbeat-interval + acceptable-heartbeat-pause + threshold_adjustment,
    # i.e. around 12.5 seconds with default settings.
    watch-failure-detector {

      # FQCN of the failure detector implementation.
      # It must implement akka.remote.FailureDetector and have
      # a public constructor with a com.typesafe.config.Config and
      # akka.actor.EventStream parameter.
      implementation-class = &quot;akka.remote.PhiAccrualFailureDetector&quot;

      # How often keep-alive heartbeat messages should be sent to each connection.
      heartbeat-interval = 1 s

      # Defines the failure detector threshold.
      # A low threshold is prone to generate many wrong suspicions but ensures
      # a quick detection in the event of a real crash. Conversely, a high
      # threshold generates fewer mistakes but needs more time to detect
      # actual crashes.
      threshold = 10.0

      # Number of the samples of inter-heartbeat arrival times to adaptively
      # calculate the failure timeout for connections.
      max-sample-size = 200

      # Minimum standard deviation to use for the normal distribution in
      # AccrualFailureDetector. Too low standard deviation might result in
      # too much sensitivity for sudden, but normal, deviations in heartbeat
      # inter arrival times.
      min-std-deviation = 100 ms

      # Number of potentially lost/delayed heartbeats that will be
      # accepted before considering it to be an anomaly.
      # This margin is important to be able to survive sudden, occasional,
      # pauses in heartbeat arrivals, due to for example garbage collect or
      # network drop.
      acceptable-heartbeat-pause = 10 s


      # How often to check for nodes marked as unreachable by the failure
      # detector
      unreachable-nodes-reaper-interval = 1s

      # After the heartbeat request has been sent the first failure detection
      # will start after this period, even though no heartbeat mesage has
      # been received.
      expected-response-after = 1 s

    }

    # remote deployment configuration section
    deployment {
      # If true, will only allow specific classes to be instanciated on this system via remote deployment
      enable-whitelist = off

      whitelist = []
    }

    ### Default dispatcher for the remoting subsystem
    default-remote-dispatcher {
      type = Dispatcher
      executor = &quot;fork-join-executor&quot;
      fork-join-executor {
        parallelism-min = 2
        parallelism-factor = 0.5
        parallelism-max = 16
      }
      throughput = 10
    }
akka {

  remote {

    ### Configuration for Artery, the new implementation of remoting
    artery {

      # Disable artery with this flag
      enabled = on

      # Select the underlying transport implementation.
      #
      # Possible values: aeron-udp, tcp, tls-tcp
      # See https://doc.akka.io/docs/akka/current/remoting-artery.html#selecting-a-transport for the tradeoffs
      # for each transport
      transport = tcp

      # Canonical address is the address other clients should connect to.
      # Artery transport will expect messages to this address.
      canonical {

        # The default remote server port clients should connect to.
        # Default is 25520, use 0 if you want a random available port
        # This port needs to be unique for each actor system on the same machine.
        port = 25520

        # Hostname clients should connect to. Can be set to an ip, hostname
        # or one of the following special values:
        #   &quot;&lt;getHostAddress&gt;&quot;   InetAddress.getLocalHost.getHostAddress
        #   &quot;&lt;getHostName&gt;&quot;      InetAddress.getLocalHost.getHostName
        #
        hostname = &quot;&lt;getHostAddress&gt;&quot;
      }

      # Use these settings to bind a network interface to a different address
      # than artery expects messages at. This may be used when running Akka
      # nodes in a separated networks (under NATs or in containers). If canonical
      # and bind addresses are different, then network configuration that relays
      # communications from canonical to bind addresses is expected.
      bind {

        # Port to bind a network interface to. Can be set to a port number
        # of one of the following special values:
        #   0    random available port
        #   &quot;&quot;   akka.remote.artery.canonical.port
        #
        port = &quot;&quot;

        # Hostname to bind a network interface to. Can be set to an ip, hostname
        # or one of the following special values:
        #   &quot;0.0.0.0&quot;            all interfaces
        #   &quot;&quot;                   akka.remote.artery.canonical.hostname
        #   &quot;&lt;getHostAddress&gt;&quot;   InetAddress.getLocalHost.getHostAddress
        #   &quot;&lt;getHostName&gt;&quot;      InetAddress.getLocalHost.getHostName
        #
        hostname = &quot;&quot;

        # Time to wait for Aeron/TCP to bind
        bind-timeout = 3s
      }


      # Actor paths to use the large message stream for when a message
      # is sent to them over remoting. The large message stream dedicated
      # is separate from &quot;normal&quot; and system messages so that sending a
      # large message does not interfere with them.
      # Entries should be the full path to the actor. Wildcards in the form of &quot;*&quot;
      # can be supplied at any place and matches any name at that segment -
      # &quot;/user/supervisor/actor/*&quot; will match any direct child to actor,
      # while &quot;/supervisor/*/child&quot; will match any grandchild to &quot;supervisor&quot; that
      # has the name &quot;child&quot;
      # Entries have to be specified on both the sending and receiving side.
      # Messages sent to ActorSelections will not be passed through the large message
      # stream, to pass such messages through the large message stream the selections
      # but must be resolved to ActorRefs first.
      large-message-destinations = []

      # Enable untrusted mode, which discards inbound system messages, PossiblyHarmful and
      # ActorSelection messages. E.g. remote watch and remote deployment will not work.
      # ActorSelection messages can be enabled for specific paths with the trusted-selection-paths
      untrusted-mode = off

      # When &#39;untrusted-mode=on&#39; inbound actor selections are by default discarded.
      # Actors with paths defined in this white list are granted permission to receive actor
      # selections messages.
      # E.g. trusted-selection-paths = [&quot;/user/receptionist&quot;, &quot;/user/namingService&quot;]
      trusted-selection-paths = []

      # If this is &quot;on&quot;, all inbound remote messages will be logged at DEBUG level,
      # if off then they are not logged
      log-received-messages = off

      # If this is &quot;on&quot;, all outbound remote messages will be logged at DEBUG level,
      # if off then they are not logged
      log-sent-messages = off

      advanced {

        # Maximum serialized message size, including header data.
        maximum-frame-size = 256 KiB

        # Direct byte buffers are reused in a pool with this maximum size.
        # Each buffer has the size of &#39;maximum-frame-size&#39;.
        # This is not a hard upper limit on number of created buffers. Additional
        # buffers will be created if needed, e.g. when using many outbound
        # associations at the same time. Such additional buffers will be garbage
        # collected, which is not as efficient as reusing buffers in the pool.
        buffer-pool-size = 128

        # Maximum serialized message size for the large messages, including header data.
        # It is currently restricted to 1/8th the size of a term buffer that can be
        # configured by setting the &#39;aeron.term.buffer.length&#39; system property.
        # See &#39;large-message-destinations&#39;.
        maximum-large-frame-size = 2 MiB

        # Direct byte buffers for the large messages are reused in a pool with this maximum size.
        # Each buffer has the size of &#39;maximum-large-frame-size&#39;.
        # See &#39;large-message-destinations&#39;.
        # This is not a hard upper limit on number of created buffers. Additional
        # buffers will be created if needed, e.g. when using many outbound
        # associations at the same time. Such additional buffers will be garbage
        # collected, which is not as efficient as reusing buffers in the pool.
        large-buffer-pool-size = 32

        # For enabling testing features, such as blackhole in akka-remote-testkit.
        test-mode = off

        # Settings for the materializer that is used for the remote streams.
        materializer = ${akka.stream.materializer}

        # Remoting will use the given dispatcher for the ordinary and large message
        # streams.
        use-dispatcher = &quot;akka.remote.default-remote-dispatcher&quot;

        # Remoting will use the given dispatcher for the control stream.
        # It can be good to not use the same dispatcher for the control stream as
        # the dispatcher for the ordinary message stream so that heartbeat messages
        # are not disturbed.
        use-control-stream-dispatcher = &quot;akka.actor.internal-dispatcher&quot;


        # Total number of inbound lanes, shared among all inbound associations. A value
        # greater than 1 means that deserialization can be performed in parallel for
        # different destination actors. The selection of lane is based on consistent
        # hashing of the recipient ActorRef to preserve message ordering per receiver.
        # Lowest latency can be achieved with inbound-lanes=1 because of one less
        # asynchronous boundary.
        inbound-lanes = 4

        # Number of outbound lanes for each outbound association. A value greater than 1
        # means that serialization and other work can be performed in parallel for different
        # destination actors. The selection of lane is based on consistent hashing of the
        # recipient ActorRef to preserve message ordering per receiver. Note that messages
        # for different destination systems (hosts) are handled by different streams also
        # when outbound-lanes=1. Lowest latency can be achieved with outbound-lanes=1
        # because of one less asynchronous boundary.
        outbound-lanes = 1

        # Size of the send queue for outgoing messages. Messages will be dropped if
        # the queue becomes full. This may happen if you send a burst of many messages
        # without end-to-end flow control. Note that there is one such queue per
        # outbound association. The trade-off of using a larger queue size is that
        # it consumes more memory, since the queue is based on preallocated array with
        # fixed size.
        outbound-message-queue-size = 3072

        # Size of the send queue for outgoing control messages, such as system messages.
        # If this limit is reached the remote system is declared to be dead and its UID
        # marked as quarantined. Note that there is one such queue per outbound association.
        # It is a linked queue so it will not use more memory than needed but by increasing
        # too much you may risk OutOfMemoryError in the worst case.
        outbound-control-queue-size = 20000

        # Size of the send queue for outgoing large messages. Messages will be dropped if
        # the queue becomes full. This may happen if you send a burst of many messages
        # without end-to-end flow control. Note that there is one such queue per
        # outbound association.
        # It is a linked queue so it will not use more memory than needed but by increasing
        # too much you may risk OutOfMemoryError, especially since the message payload
        # of these messages may be large.
        outbound-large-message-queue-size = 256

        # This setting defines the maximum number of unacknowledged system messages
        # allowed for a remote system. If this limit is reached the remote system is
        # declared to be dead and its UID marked as quarantined.
        system-message-buffer-size = 20000

        # unacknowledged system messages are re-delivered with this interval
        system-message-resend-interval = 1 second



        # The timeout for outbound associations to perform the initial handshake.
        # This timeout must be greater than the &#39;image-liveness-timeout&#39; when
        # transport is aeron-udp.
        handshake-timeout = 20 seconds

        # incomplete initial handshake attempt is retried with this interval
        handshake-retry-interval = 1 second

        # Handshake requests are performed periodically with this interval,
        # also after the handshake has been completed to be able to establish
        # a new session with a restarted destination system.
        inject-handshake-interval = 1 second


        # System messages that are not acknowledged after re-sending for this period are
        # dropped and will trigger quarantine. The value should be longer than the length
        # of a network partition that you need to survive.
        give-up-system-message-after = 6 hours

        # Outbound streams are stopped when they haven&#39;t been used for this duration.
        # They are started again when new messages are sent.
        stop-idle-outbound-after = 5 minutes

        # Outbound streams are quarantined when they haven&#39;t been used for this duration
        # to cleanup resources used by the association, such as compression tables.
        # This will cleanup association to crashed systems that didn&#39;t announce their
        # termination.
        # The value should be longer than the length of a network partition that you
        # need to survive.
        # The value must also be greater than stop-idle-outbound-after.
        # Once every 1/10 of this duration an extra handshake message will be sent.
        # Therfore it&#39;s also recommended to use a value that is greater than 10 times
        # the stop-idle-outbound-after, since otherwise the idle streams will not be
        # stopped.
        quarantine-idle-outbound-after = 6 hours

        # Stop outbound stream of a quarantined association after this idle timeout, i.e.
        # when not used any more.
        stop-quarantined-after-idle = 3 seconds

        # After catastrophic communication failures that could result in the loss of system
        # messages or after the remote DeathWatch triggers the remote system gets
        # quarantined to prevent inconsistent behavior.
        # This setting controls how long the quarantined association will be kept around
        # before being removed to avoid long-term memory leaks. It must be quarantined
        # and also unused for this duration before it&#39;s removed. When removed the historical
        # information about which UIDs that were quarantined for that hostname:port is
        # gone which could result in communication with a previously quarantined node
        # if it wakes up again. Therfore this shouldn&#39;t be set too low.
        remove-quarantined-association-after = 1 h

        # during ActorSystem termination the remoting will wait this long for
        # an acknowledgment by the destination system that flushing of outstanding
        # remote messages has been completed
        shutdown-flush-timeout = 1 second

        # See &#39;inbound-max-restarts&#39;
        inbound-restart-timeout = 5 seconds

        # Max number of restarts within &#39;inbound-restart-timeout&#39; for the inbound streams.
        # If more restarts occurs the ActorSystem will be terminated.
        inbound-max-restarts = 5

        # Retry outbound connection after this backoff.
        # Only used when transport is tcp or tls-tcp.
        outbound-restart-backoff = 1 second

        # See &#39;outbound-max-restarts&#39;
        outbound-restart-timeout = 5 seconds

        # Max number of restarts within &#39;outbound-restart-timeout&#39; for the outbound streams.
        # If more restarts occurs the ActorSystem will be terminated.
        outbound-max-restarts = 5

        # compression of common strings in remoting messages, like actor destinations, serializers etc
        compression {

          actor-refs {
            # Max number of compressed actor-refs
            # Note that compression tables are &quot;rolling&quot; (i.e. a new table replaces the old
            # compression table once in a while), and this setting is only about the total number
            # of compressions within a single such table.
            # Must be a positive natural number.
            max = 256

            # interval between new table compression advertisements.
            # this means the time during which we collect heavy-hitter data and then turn it into a compression table.
            advertisement-interval = 1 minute
          }
          manifests {
            # Max number of compressed manifests
            # Note that compression tables are &quot;rolling&quot; (i.e. a new table replaces the old
            # compression table once in a while), and this setting is only about the total number
            # of compressions within a single such table.
            # Must be a positive natural number.
            max = 256

            # interval between new table compression advertisements.
            # this means the time during which we collect heavy-hitter data and then turn it into a compression table.
            advertisement-interval = 1 minute
          }
        }

        # List of fully qualified class names of remote instruments which should
        # be initialized and used for monitoring of remote messages.
        # The class must extend akka.remote.artery.RemoteInstrument and
        # have a public constructor with empty parameters or one ExtendedActorSystem
        # parameter.
        # A new instance of RemoteInstrument will be created for each encoder and decoder.
        # It&#39;s only called from the stage, so if it dosn&#39;t delegate to any shared instance
        # it doesn&#39;t have to be thread-safe.
        # Refer to `akka.remote.artery.RemoteInstrument` for more information.
        instruments = ${?akka.remote.artery.advanced.instruments} []

        # Only used when transport is aeron-udp
        aeron {
          # Only used when transport is aeron-udp.
          log-aeron-counters = false

          # Controls whether to start the Aeron media driver in the same JVM or use external
          # process. Set to &#39;off&#39; when using external media driver, and then also set the
          # &#39;aeron-dir&#39;.
          # Only used when transport is aeron-udp.
          embedded-media-driver = on

          # Directory used by the Aeron media driver. It&#39;s mandatory to define the &#39;aeron-dir&#39;
          # if using external media driver, i.e. when &#39;embedded-media-driver = off&#39;.
          # Embedded media driver will use a this directory, or a temporary directory if this
          # property is not defined (empty).
          # Only used when transport is aeron-udp.
          aeron-dir = &quot;&quot;

          # Whether to delete aeron embedded driver directory upon driver stop.
          # Only used when transport is aeron-udp.
          delete-aeron-dir = yes

          # Level of CPU time used, on a scale between 1 and 10, during backoff/idle.
          # The tradeoff is that to have low latency more CPU time must be used to be
          # able to react quickly on incoming messages or send as fast as possible after
          # backoff backpressure.
          # Level 1 strongly prefer low CPU consumption over low latency.
          # Level 10 strongly prefer low latency over low CPU consumption.
          # Only used when transport is aeron-udp.
          idle-cpu-level = 5

          # messages that are not accepted by Aeron are dropped after retrying for this period
          # Only used when transport is aeron-udp.
          give-up-message-after = 60 seconds

          # Timeout after which aeron driver has not had keepalive messages
          # from a client before it considers the client dead.
          # Only used when transport is aeron-udp.
          client-liveness-timeout = 20 seconds

          # Timout after after which an uncommitted publication will be unblocked
          # Only used when transport is aeron-udp.
          publication-unblock-timeout = 40 seconds

          # Timeout for each the INACTIVE and LINGER stages an aeron image
          # will be retained for when it is no longer referenced.
          # This timeout must be less than the &#39;handshake-timeout&#39;.
          # Only used when transport is aeron-udp.
          image-liveness-timeout = 10 seconds

          # Timeout after which the aeron driver is considered dead
          # if it does not update its C&#39;n&#39;C timestamp.
          # Only used when transport is aeron-udp.
          driver-timeout = 20 seconds
        }

        # Only used when transport is tcp or tls-tcp.
        tcp {
          # Timeout of establishing outbound connections.
          connection-timeout = 5 seconds
        }


      }

      # SSL configuration that is used when transport=tls-tcp.
      ssl {
        # Factory of SSLEngine.
        # Must implement akka.remote.artery.tcp.SSLEngineProvider and have a public
        # constructor with an ActorSystem parameter.
        # The default ConfigSSLEngineProvider is configured by properties in section
        # akka.remote.artery.ssl.config-ssl-engine
        ssl-engine-provider = akka.remote.artery.tcp.ConfigSSLEngineProvider

        # Config of akka.remote.artery.tcp.ConfigSSLEngineProvider
        config-ssl-engine {

          # This is the Java Key Store used by the server connection
          key-store = &quot;keystore&quot;

          # This password is used for decrypting the key store
          # Use substitution from environment variables for passwords. Don&#39;t define
          # real passwords in config files. key-store-password=${SSL_KEY_STORE_PASSWORD}
          key-store-password = &quot;changeme&quot;

          # This password is used for decrypting the key
          # Use substitution from environment variables for passwords. Don&#39;t define
          # real passwords in config files. key-password=${SSL_KEY_PASSWORD}
          key-password = &quot;changeme&quot;

          # This is the Java Key Store used by the client connection
          trust-store = &quot;truststore&quot;

          # This password is used for decrypting the trust store
          # Use substitution from environment variables for passwords. Don&#39;t define
          # real passwords in config files. trust-store-password=${SSL_TRUST_STORE_PASSWORD}
          trust-store-password = &quot;changeme&quot;

          # Protocol to use for SSL encryption, choose from:
          # TLS 1.2 is available since JDK7, and default since JDK8:
          # https://blogs.oracle.com/java-platform-group/entry/java_8_will_use_tls
          protocol = &quot;TLSv1.2&quot;

          # Example: [&quot;TLS_RSA_WITH_AES_128_CBC_SHA&quot;, &quot;TLS_RSA_WITH_AES_256_CBC_SHA&quot;]
          # You need to install the JCE Unlimited Strength Jurisdiction Policy
          # Files to use AES 256.
          # More info here:
          enabled-algorithms = [&quot;TLS_RSA_WITH_AES_128_CBC_SHA&quot;]

          # There are two options, and the default SecureRandom is recommended:
          # &quot;&quot; or &quot;SecureRandom&quot; =&gt; (default)
          # &quot;SHA1PRNG&quot; =&gt; Can be slow because of blocking issues on Linux
          #
          # Setting a value here may require you to supply the appropriate cipher
          # suite (see enabled-algorithms section above)
          random-number-generator = &quot;&quot;

          # Require mutual authentication between TLS peers
          #
          # Without mutual authentication only the peer that actively establishes a connection (TLS client side)
          # checks if the passive side (TLS server side) sends over a trusted certificate. With the flag turned on,
          # the passive side will also request and verify a certificate from the connecting peer.
          #
          # To prevent man-in-the-middle attacks this setting is enabled by default.
          require-mutual-authentication = on

          # Set this to `on` to verify hostnames with sun.security.util.HostnameChecker
          hostname-verification = off
        }

      }
    }
  }

}</code></pre>
<a id="config-akka-remote"></a>
<h3><a href="#akka-remote-classic-deprecated-" name="akka-remote-classic-deprecated-" class="anchor"><span class="anchor-link"></span></a>akka-remote classic (deprecated)</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-remote/src/main/resources/reference.conf#L2-L253" target="_blank" title="Go to snippet source"></a><code class="language-none">#####################################
# Akka Remote Reference Config File #
#####################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

# comments about akka.actor settings left out where they are already in akka-
# actor.jar, because otherwise they would be repeated in config rendering.
#
# For the configuration of the new remoting implementation (Artery) please look
# at the bottom section of this file as it is listed separately.

akka {

  actor {

    serializers {
      akka-containers = &quot;akka.remote.serialization.MessageContainerSerializer&quot;
      akka-misc = &quot;akka.remote.serialization.MiscMessageSerializer&quot;
      artery = &quot;akka.remote.serialization.ArteryMessageSerializer&quot;
      proto = &quot;akka.remote.serialization.ProtobufSerializer&quot;
      daemon-create = &quot;akka.remote.serialization.DaemonMsgCreateSerializer&quot;
      akka-system-msg = &quot;akka.remote.serialization.SystemMessageSerializer&quot;
    }

    serialization-bindings {
      &quot;akka.actor.ActorSelectionMessage&quot; = akka-containers

      &quot;akka.remote.DaemonMsgCreate&quot; = daemon-create

      &quot;akka.remote.artery.ArteryMessage&quot; = artery

      # Since akka.protobuf.Message does not extend Serializable but
      # GeneratedMessage does, need to use the more specific one here in order
      # to avoid ambiguity.
      # This is only loaded if akka-protobuf is on the classpath
      # It should not be used and users should migrate to using the protobuf classes
      # directly
      # Remove in 2.7
      &quot;akka.protobuf.GeneratedMessage&quot; = proto

      &quot;akka.protobufv3.internal.GeneratedMessageV3&quot; = proto

      # Since com.google.protobuf.Message does not extend Serializable but
      # GeneratedMessage does, need to use the more specific one here in order
      # to avoid ambiguity.
      # This com.google.protobuf serialization binding is only used if the class can be loaded,
      # i.e. com.google.protobuf dependency has been added in the application project.
      &quot;com.google.protobuf.GeneratedMessage&quot; = proto
      &quot;com.google.protobuf.GeneratedMessageV3&quot; = proto

      &quot;akka.actor.Identify&quot; = akka-misc
      &quot;akka.actor.ActorIdentity&quot; = akka-misc
      &quot;scala.Some&quot; = akka-misc
      &quot;scala.None$&quot; = akka-misc
      &quot;java.util.Optional&quot; = akka-misc
      &quot;akka.actor.Status$Success&quot; = akka-misc
      &quot;akka.actor.Status$Failure&quot; = akka-misc
      &quot;akka.actor.ActorRef&quot; = akka-misc
      &quot;akka.actor.PoisonPill$&quot; = akka-misc
      &quot;akka.actor.Kill$&quot; = akka-misc
      &quot;akka.remote.RemoteWatcher$Heartbeat$&quot; = akka-misc
      &quot;akka.remote.RemoteWatcher$HeartbeatRsp&quot; = akka-misc
      &quot;akka.Done&quot; = akka-misc
      &quot;akka.NotUsed&quot; = akka-misc
      &quot;akka.actor.Address&quot; = akka-misc
      &quot;akka.remote.UniqueAddress&quot; = akka-misc

      &quot;akka.actor.ActorInitializationException&quot; = akka-misc
      &quot;akka.actor.IllegalActorStateException&quot; = akka-misc
      &quot;akka.actor.ActorKilledException&quot; = akka-misc
      &quot;akka.actor.InvalidActorNameException&quot; = akka-misc
      &quot;akka.actor.InvalidMessageException&quot; = akka-misc
      &quot;java.util.concurrent.TimeoutException&quot; = akka-misc
      &quot;akka.remote.serialization.ThrowableNotSerializableException&quot; = akka-misc

      &quot;akka.actor.LocalScope$&quot; = akka-misc
      &quot;akka.remote.RemoteScope&quot; = akka-misc

      &quot;com.typesafe.config.impl.SimpleConfig&quot; = akka-misc
      &quot;com.typesafe.config.Config&quot; = akka-misc

      &quot;akka.routing.FromConfig&quot; = akka-misc
      &quot;akka.routing.DefaultResizer&quot; = akka-misc
      &quot;akka.routing.BalancingPool&quot; = akka-misc
      &quot;akka.routing.BroadcastGroup&quot; = akka-misc
      &quot;akka.routing.BroadcastPool&quot; = akka-misc
      &quot;akka.routing.RandomGroup&quot; = akka-misc
      &quot;akka.routing.RandomPool&quot; = akka-misc
      &quot;akka.routing.RoundRobinGroup&quot; = akka-misc
      &quot;akka.routing.RoundRobinPool&quot; = akka-misc
      &quot;akka.routing.ScatterGatherFirstCompletedGroup&quot; = akka-misc
      &quot;akka.routing.ScatterGatherFirstCompletedPool&quot; = akka-misc
      &quot;akka.routing.SmallestMailboxPool&quot; = akka-misc
      &quot;akka.routing.TailChoppingGroup&quot; = akka-misc
      &quot;akka.routing.TailChoppingPool&quot; = akka-misc
      &quot;akka.remote.routing.RemoteRouterConfig&quot; = akka-misc

      &quot;akka.dispatch.sysmsg.SystemMessage&quot; = akka-system-msg

      # Java Serializer is by default used for exceptions and will by default
      # not be allowed to be serialized, but in certain cases they are replaced
      # by `akka.remote.serialization.ThrowableNotSerializableException` if
      # no specific serializer has been defined:
      # - when wrapped in `akka.actor.Status.Failure` for ask replies
      # - when wrapped in system messages for exceptions from remote deployed child actors
      #
      # It&#39;s recommended that you implement custom serializer for exceptions that are
      # sent remotely, You can add binding to akka-misc (MiscMessageSerializer) for the
      # exceptions that have a constructor with single message String or constructor with
      # message String as first parameter and cause Throwable as second parameter. Note that it&#39;s not
      # safe to add this binding for general exceptions such as IllegalArgumentException
      # because it may have a subclass without required constructor.
      &quot;java.lang.Throwable&quot; = java
    }

    serialization-identifiers {
      &quot;akka.remote.serialization.ProtobufSerializer&quot; = 2
      &quot;akka.remote.serialization.DaemonMsgCreateSerializer&quot; = 3
      &quot;akka.remote.serialization.MessageContainerSerializer&quot; = 6
      &quot;akka.remote.serialization.MiscMessageSerializer&quot; = 16
      &quot;akka.remote.serialization.ArteryMessageSerializer&quot; = 17

      &quot;akka.remote.serialization.SystemMessageSerializer&quot; = 22

      # deprecated in 2.6.0, moved to akka-actor
      &quot;akka.remote.serialization.LongSerializer&quot; = 18
      # deprecated in 2.6.0, moved to akka-actor
      &quot;akka.remote.serialization.IntSerializer&quot; = 19
      # deprecated in 2.6.0, moved to akka-actor
      &quot;akka.remote.serialization.StringSerializer&quot; = 20
      # deprecated in 2.6.0, moved to akka-actor
      &quot;akka.remote.serialization.ByteStringSerializer&quot; = 21
    }

    deployment {

      default {

        # if this is set to a valid remote address, the named actor will be
        # deployed at that node e.g. &quot;akka://sys@host:port&quot;
        remote = &quot;&quot;

        target {

          # A list of hostnames and ports for instantiating the children of a
          # router
          #   The format should be on &quot;akka://sys@host:port&quot;, where:
          #    - sys is the remote actor system name
          #    - hostname can be either hostname or IP address the remote actor
          #      should connect to
          #    - port should be the port for the remote server on the other node
          # The number of actor instances to be spawned is still taken from the
          # nr-of-instances setting as for local routers; the instances will be
          # distributed round-robin among the given nodes.
          nodes = []

        }
      }
    }
  }

  remote {
    ### Settings shared by classic remoting and Artery (the new implementation of remoting)

    # Using remoting directly is typically not desirable, so a warning will
    # be shown to make this clear. Set this setting to &#39;off&#39; to suppress that
    # warning.
    warn-about-direct-use = on


    # If Cluster is not used, remote watch and deployment are disabled.
    # To optionally use them while not using Cluster, set to &#39;on&#39;.
    use-unsafe-remote-features-outside-cluster = off

    # A warning will be logged on remote watch attempts if Cluster
    # is not in use and &#39;use-unsafe-remote-features-outside-cluster&#39;
    # is &#39;off&#39;. Set this to &#39;off&#39; to suppress these.
    warn-unsafe-watch-outside-cluster = on

    # Settings for the Phi accrual failure detector (http://www.jaist.ac.jp/~defago/files/pdf/IS_RR_2004_010.pdf
    # [Hayashibara et al]) used for remote death watch.
    # The default PhiAccrualFailureDetector will trigger if there are no heartbeats within
    # the duration heartbeat-interval + acceptable-heartbeat-pause + threshold_adjustment,
    # i.e. around 12.5 seconds with default settings.
    watch-failure-detector {

      # FQCN of the failure detector implementation.
      # It must implement akka.remote.FailureDetector and have
      # a public constructor with a com.typesafe.config.Config and
      # akka.actor.EventStream parameter.
      implementation-class = &quot;akka.remote.PhiAccrualFailureDetector&quot;

      # How often keep-alive heartbeat messages should be sent to each connection.
      heartbeat-interval = 1 s

      # Defines the failure detector threshold.
      # A low threshold is prone to generate many wrong suspicions but ensures
      # a quick detection in the event of a real crash. Conversely, a high
      # threshold generates fewer mistakes but needs more time to detect
      # actual crashes.
      threshold = 10.0

      # Number of the samples of inter-heartbeat arrival times to adaptively
      # calculate the failure timeout for connections.
      max-sample-size = 200

      # Minimum standard deviation to use for the normal distribution in
      # AccrualFailureDetector. Too low standard deviation might result in
      # too much sensitivity for sudden, but normal, deviations in heartbeat
      # inter arrival times.
      min-std-deviation = 100 ms

      # Number of potentially lost/delayed heartbeats that will be
      # accepted before considering it to be an anomaly.
      # This margin is important to be able to survive sudden, occasional,
      # pauses in heartbeat arrivals, due to for example garbage collect or
      # network drop.
      acceptable-heartbeat-pause = 10 s


      # How often to check for nodes marked as unreachable by the failure
      # detector
      unreachable-nodes-reaper-interval = 1s

      # After the heartbeat request has been sent the first failure detection
      # will start after this period, even though no heartbeat mesage has
      # been received.
      expected-response-after = 1 s

    }

    # remote deployment configuration section
    deployment {
      # If true, will only allow specific classes to be instanciated on this system via remote deployment
      enable-whitelist = off

      whitelist = []
    }

    ### Default dispatcher for the remoting subsystem
    default-remote-dispatcher {
      type = Dispatcher
      executor = &quot;fork-join-executor&quot;
      fork-join-executor {
        parallelism-min = 2
        parallelism-factor = 0.5
        parallelism-max = 16
      }
      throughput = 10
    }

    ### Configuration for classic remoting. Classic remoting is deprecated, use artery.


    # If set to a nonempty string remoting will use the given dispatcher for
    # its internal actors otherwise the default dispatcher is used. Please note
    # that since remoting can load arbitrary 3rd party drivers (see
    # &quot;enabled-transport&quot; and &quot;adapters&quot; entries) it is not guaranteed that
    # every module will respect this setting.
    use-dispatcher = &quot;akka.remote.default-remote-dispatcher&quot;

    # Settings for the failure detector to monitor connections.
    # For TCP it is not important to have fast failure detection, since
    # most connection failures are captured by TCP itself.
    # The default DeadlineFailureDetector will trigger if there are no heartbeats within
    # the duration heartbeat-interval + acceptable-heartbeat-pause, i.e. 124 seconds
    # with the default settings.
    transport-failure-detector {

      # FQCN of the failure detector implementation.
      # It must implement akka.remote.FailureDetector and have
      # a public constructor with a com.typesafe.config.Config and
      # akka.actor.EventStream parameter.
      implementation-class = &quot;akka.remote.DeadlineFailureDetector&quot;

      # How often keep-alive heartbeat messages should be sent to each connection.
      heartbeat-interval = 4 s

      # Number of potentially lost/delayed heartbeats that will be
      # accepted before considering it to be an anomaly.
      # A margin to the `heartbeat-interval` is important to be able to survive sudden,
      # occasional, pauses in heartbeat arrivals, due to for example garbage collect or
      # network drop.
      acceptable-heartbeat-pause = 120 s
    }


    # Timeout after which the startup of the remoting subsystem is considered
    # to be failed. Increase this value if your transport drivers (see the
    # enabled-transports section) need longer time to be loaded.
    startup-timeout = 10 s

    # Timout after which the graceful shutdown of the remoting subsystem is
    # considered to be failed. After the timeout the remoting system is
    # forcefully shut down. Increase this value if your transport drivers
    # (see the enabled-transports section) need longer time to stop properly.
    shutdown-timeout = 10 s

    # Before shutting down the drivers, the remoting subsystem attempts to flush
    # all pending writes. This setting controls the maximum time the remoting is
    # willing to wait before moving on to shut down the drivers.
    flush-wait-on-shutdown = 2 s

    # Reuse inbound connections for outbound messages
    use-passive-connections = on

    # Controls the backoff interval after a refused write is reattempted.
    # (Transports may refuse writes if their internal buffer is full)
    backoff-interval = 5 ms

    # Acknowledgment timeout of management commands sent to the transport stack.
    command-ack-timeout = 30 s

    # The timeout for outbound associations to perform the handshake.
    # If the transport is akka.remote.classic.netty.tcp or akka.remote.classic.netty.ssl
    # the configured connection-timeout for the transport will be used instead.
    handshake-timeout = 15 s

    ### Security settings

    # Enable untrusted mode for full security of server managed actors, prevents
    # system messages to be send by clients, e.g. messages like &#39;Create&#39;,
    # &#39;Suspend&#39;, &#39;Resume&#39;, &#39;Terminate&#39;, &#39;Supervise&#39;, &#39;Link&#39; etc.
    untrusted-mode = off

    # When &#39;untrusted-mode=on&#39; inbound actor selections are by default discarded.
    # Actors with paths defined in this white list are granted permission to receive actor
    # selections messages.
    # E.g. trusted-selection-paths = [&quot;/user/receptionist&quot;, &quot;/user/namingService&quot;]
    trusted-selection-paths = []

    ### Logging

    # If this is &quot;on&quot;, Akka will log all inbound messages at DEBUG level,
    # if off then they are not logged
    log-received-messages = off

    # If this is &quot;on&quot;, Akka will log all outbound messages at DEBUG level,
    # if off then they are not logged
    log-sent-messages = off

    # Sets the log granularity level at which Akka logs remoting events. This setting
    # can take the values OFF, ERROR, WARNING, INFO, DEBUG, or ON. For compatibility
    # reasons the setting &quot;on&quot; will default to &quot;debug&quot; level. Please note that the effective
    # logging level is still determined by the global logging level of the actor system:
    # for example debug level remoting events will be only logged if the system
    # is running with debug level logging.
    # Failures to deserialize received messages also fall under this flag.
    log-remote-lifecycle-events = on

    # Logging of message types with payload size in bytes larger than
    # this value. Maximum detected size per message type is logged once,
    # with an increase threshold of 10%.
    # By default this feature is turned off. Activate it by setting the property to
    # a value in bytes, such as 1000b. Note that for all messages larger than this
    # limit there will be extra performance and scalability cost.
    log-frame-size-exceeding = off

    # Log warning if the number of messages in the backoff buffer in the endpoint
    # writer exceeds this limit. It can be disabled by setting the value to off.
    log-buffer-size-exceeding = 50000

    # After failed to establish an outbound connection, the remoting will mark the
    # address as failed. This configuration option controls how much time should
    # be elapsed before reattempting a new connection. While the address is
    # gated, all messages sent to the address are delivered to dead-letters.
    # Since this setting limits the rate of reconnects setting it to a
    # very short interval (i.e. less than a second) may result in a storm of
    # reconnect attempts.
    retry-gate-closed-for = 5 s

    # After catastrophic communication failures that result in the loss of system
    # messages or after the remote DeathWatch triggers the remote system gets
    # quarantined to prevent inconsistent behavior.
    # This setting controls how long the Quarantine marker will be kept around
    # before being removed to avoid long-term memory leaks.
    # WARNING: DO NOT change this to a small value to re-enable communication with
    # quarantined nodes. Such feature is not supported and any behavior between
    # the affected systems after lifting the quarantine is undefined.
    prune-quarantine-marker-after = 5 d

    # If system messages have been exchanged between two systems (i.e. remote death
    # watch or remote deployment has been used) a remote system will be marked as
    # quarantined after the two system has no active association, and no
    # communication happens during the time configured here.
    # The only purpose of this setting is to avoid storing system message redelivery
    # data (sequence number state, etc.) for an undefined amount of time leading to long
    # term memory leak. Instead, if a system has been gone for this period,
    # or more exactly
    # - there is no association between the two systems (TCP connection, if TCP transport is used)
    # - neither side has been attempting to communicate with the other
    # - there are no pending system messages to deliver
    # for the amount of time configured here, the remote system will be quarantined and all state
    # associated with it will be dropped.
    #
    # Maximum value depends on the scheduler&#39;s max limit (default 248 days) and if configured
    # to a longer duration this feature will effectively be disabled. Setting the value to
    # &#39;off&#39; will also disable the feature. Note that if disabled there is a risk of a long
    # term memory leak.
    quarantine-after-silence = 2 d

    # This setting defines the maximum number of unacknowledged system messages
    # allowed for a remote system. If this limit is reached the remote system is
    # declared to be dead and its UID marked as tainted.
    system-message-buffer-size = 20000

    # This setting defines the maximum idle time after an individual
    # acknowledgement for system messages is sent. System message delivery
    # is guaranteed by explicit acknowledgement messages. These acks are
    # piggybacked on ordinary traffic messages. If no traffic is detected
    # during the time period configured here, the remoting will send out
    # an individual ack.
    system-message-ack-piggyback-timeout = 0.3 s

    # This setting defines the time after internal management signals
    # between actors (used for DeathWatch and supervision) that have not been
    # explicitly acknowledged or negatively acknowledged are resent.
    # Messages that were negatively acknowledged are always immediately
    # resent.
    resend-interval = 2 s

    # Maximum number of unacknowledged system messages that will be resent
    # each &#39;resend-interval&#39;. If you watch many (&gt; 1000) remote actors you can
    # increase this value to for example 600, but a too large limit (e.g. 10000)
    # may flood the connection and might cause false failure detection to trigger.
    # Test such a configuration by watching all actors at the same time and stop
    # all watched actors at the same time.
    resend-limit = 200

    # WARNING: this setting should not be not changed unless all of its consequences
    # are properly understood which assumes experience with remoting internals
    # or expert advice.
    # This setting defines the time after redelivery attempts of internal management
    # signals are stopped to a remote system that has been not confirmed to be alive by
    # this system before.
    initial-system-message-delivery-timeout = 3 m

    ### Transports and adapters

    # List of the transport drivers that will be loaded by the remoting.
    # A list of fully qualified config paths must be provided where
    # the given configuration path contains a transport-class key
    # pointing to an implementation class of the Transport interface.
    # If multiple transports are provided, the address of the first
    # one will be used as a default address.
    enabled-transports = [&quot;akka.remote.classic.netty.tcp&quot;]

    # Transport drivers can be augmented with adapters by adding their
    # name to the applied-adapters setting in the configuration of a
    # transport. The available adapters should be configured in this
    # section by providing a name, and the fully qualified name of
    # their corresponding implementation. The class given here
    # must implement akka.akka.remote.transport.TransportAdapterProvider
    # and have public constructor without parameters.
    adapters {
      gremlin = &quot;akka.remote.transport.FailureInjectorProvider&quot;
      trttl = &quot;akka.remote.transport.ThrottlerProvider&quot;
    }

    ### Default configuration for the Netty based transport drivers

    netty.tcp {
      # The class given here must implement the akka.remote.transport.Transport
      # interface and offer a public constructor which takes two arguments:
      #  1) akka.actor.ExtendedActorSystem
      #  2) com.typesafe.config.Config
      transport-class = &quot;akka.remote.transport.netty.NettyTransport&quot;

      # Transport drivers can be augmented with adapters by adding their
      # name to the applied-adapters list. The last adapter in the
      # list is the adapter immediately above the driver, while
      # the first one is the top of the stack below the standard
      # Akka protocol
      applied-adapters = []

      # The default remote server port clients should connect to.
      # Default is 2552 (AKKA), use 0 if you want a random available port
      # This port needs to be unique for each actor system on the same machine.
      port = 2552

      # The hostname or ip clients should connect to.
      # InetAddress.getLocalHost.getHostAddress is used if empty
      hostname = &quot;&quot;

      # Use this setting to bind a network interface to a different port
      # than remoting protocol expects messages at. This may be used
      # when running akka nodes in a separated networks (under NATs or docker containers).
      # Use 0 if you want a random available port. Examples:
      #
      # akka.remote.classic.netty.tcp.port = 2552
      # akka.remote.classic.netty.tcp.bind-port = 2553
      # Network interface will be bound to the 2553 port, but remoting protocol will
      # expect messages sent to port 2552.
      #
      # akka.remote.classic.netty.tcp.port = 0
      # akka.remote.classic.netty.tcp.bind-port = 0
      # Network interface will be bound to a random port, and remoting protocol will
      # expect messages sent to the bound port.
      #
      # akka.remote.classic.netty.tcp.port = 2552
      # akka.remote.classic.netty.tcp.bind-port = 0
      # Network interface will be bound to a random port, but remoting protocol will
      # expect messages sent to port 2552.
      #
      # akka.remote.classic.netty.tcp.port = 0
      # akka.remote.classic.netty.tcp.bind-port = 2553
      # Network interface will be bound to the 2553 port, and remoting protocol will
      # expect messages sent to the bound port.
      #
      # akka.remote.classic.netty.tcp.port = 2552
      # akka.remote.classic.netty.tcp.bind-port = &quot;&quot;
      # Network interface will be bound to the 2552 port, and remoting protocol will
      # expect messages sent to the bound port.
      #
      # akka.remote.classic.netty.tcp.port if empty
      bind-port = &quot;&quot;

      # Use this setting to bind a network interface to a different hostname or ip
      # than remoting protocol expects messages at.
      # Use &quot;0.0.0.0&quot; to bind to all interfaces.
      # akka.remote.classic.netty.tcp.hostname if empty
      bind-hostname = &quot;&quot;

      # Enables SSL support on this transport
      enable-ssl = false

      # Sets the connectTimeoutMillis of all outbound connections,
      # i.e. how long a connect may take until it is timed out
      connection-timeout = 15 s

      # If set to &quot;&lt;id.of.dispatcher&gt;&quot; then the specified dispatcher
      # will be used to accept inbound connections, and perform IO. If &quot;&quot; then
      # dedicated threads will be used.
      # Please note that the Netty driver only uses this configuration and does
      # not read the &quot;akka.remote.use-dispatcher&quot; entry. Instead it has to be
      # configured manually to point to the same dispatcher if needed.
      use-dispatcher-for-io = &quot;&quot;

      # Sets the high water mark for the in and outbound sockets,
      # set to 0b for platform default
      write-buffer-high-water-mark = 0b

      # Sets the low water mark for the in and outbound sockets,
      # set to 0b for platform default
      write-buffer-low-water-mark = 0b

      # Sets the send buffer size of the Sockets,
      # set to 0b for platform default
      send-buffer-size = 256000b

      # Sets the receive buffer size of the Sockets,
      # set to 0b for platform default
      receive-buffer-size = 256000b

      # Maximum message size the transport will accept, but at least
      # 32000 bytes.
      # Please note that UDP does not support arbitrary large datagrams,
      # so this setting has to be chosen carefully when using UDP.
      # Both send-buffer-size and receive-buffer-size settings has to
      # be adjusted to be able to buffer messages of maximum size.
      maximum-frame-size = 128000b

      # Sets the size of the connection backlog
      backlog = 4096

      # Enables the TCP_NODELAY flag, i.e. disables Nagle’s algorithm
      tcp-nodelay = on

      # Enables TCP Keepalive, subject to the O/S kernel’s configuration
      tcp-keepalive = on

      # Enables SO_REUSEADDR, which determines when an ActorSystem can open
      # the specified listen port (the meaning differs between *nix and Windows)
      # Valid values are &quot;on&quot;, &quot;off&quot; and &quot;off-for-windows&quot;
      # due to the following Windows bug: http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4476378
      # &quot;off-for-windows&quot; of course means that it&#39;s &quot;on&quot; for all other platforms
      tcp-reuse-addr = off-for-windows

      # Used to configure the number of I/O worker threads on server sockets
      server-socket-worker-pool {
        # Min number of threads to cap factor-based number to
        pool-size-min = 2

        # The pool size factor is used to determine thread pool size
        # using the following formula: ceil(available processors * factor).
        # Resulting size is then bounded by the pool-size-min and
        # pool-size-max values.
        pool-size-factor = 1.0

        # Max number of threads to cap factor-based number to
        pool-size-max = 2
      }

      # Used to configure the number of I/O worker threads on client sockets
      client-socket-worker-pool {
        # Min number of threads to cap factor-based number to
        pool-size-min = 2

        # The pool size factor is used to determine thread pool size
        # using the following formula: ceil(available processors * factor).
        # Resulting size is then bounded by the pool-size-min and
        # pool-size-max values.
        pool-size-factor = 1.0

        # Max number of threads to cap factor-based number to
        pool-size-max = 2
      }


    }

    netty.ssl = ${akka.remote.classic.netty.tcp}
    netty.ssl = {
      # Enable SSL/TLS encryption.
      # This must be enabled on both the client and server to work.
      enable-ssl = true

      # Factory of SSLEngine.
      # Must implement akka.remote.transport.netty.SSLEngineProvider and have a public
      # constructor with an ActorSystem parameter.
      # The default ConfigSSLEngineProvider is configured by properties in section
      # akka.remote.classic.netty.ssl.security
      #
      # The SSLEngineProvider can also be defined via ActorSystemSetup with
      # SSLEngineProviderSetup  when starting the ActorSystem. That is useful when
      # the SSLEngineProvider implementation requires other external constructor
      # parameters or is created before the ActorSystem is created.
      # If such SSLEngineProviderSetup is defined this config property is not used.
      ssl-engine-provider = akka.remote.transport.netty.ConfigSSLEngineProvider

      security {
        # This is the Java Key Store used by the server connection
        key-store = &quot;keystore&quot;

        # This password is used for decrypting the key store
        key-store-password = &quot;changeme&quot;

        # This password is used for decrypting the key
        key-password = &quot;changeme&quot;

        # This is the Java Key Store used by the client connection
        trust-store = &quot;truststore&quot;

        # This password is used for decrypting the trust store
        trust-store-password = &quot;changeme&quot;

        # Protocol to use for SSL encryption, choose from:
        # TLS 1.2 is available since JDK7, and default since JDK8:
        # https://blogs.oracle.com/java-platform-group/entry/java_8_will_use_tls
        protocol = &quot;TLSv1.2&quot;

        # Example: [&quot;TLS_RSA_WITH_AES_128_CBC_SHA&quot;, &quot;TLS_RSA_WITH_AES_256_CBC_SHA&quot;]
        # You need to install the JCE Unlimited Strength Jurisdiction Policy
        # Files to use AES 256.
        # More info here:
        enabled-algorithms = [&quot;TLS_RSA_WITH_AES_128_CBC_SHA&quot;]

        # There are two options, and the default SecureRandom is recommended:
        # &quot;&quot; or &quot;SecureRandom&quot; =&gt; (default)
        # &quot;SHA1PRNG&quot; =&gt; Can be slow because of blocking issues on Linux
        #
        # Setting a value here may require you to supply the appropriate cipher
        # suite (see enabled-algorithms section above)
        random-number-generator = &quot;&quot;

        # Require mutual authentication between TLS peers
        #
        # Without mutual authentication only the peer that actively establishes a connection (TLS client side)
        # checks if the passive side (TLS server side) sends over a trusted certificate. With the flag turned on,
        # the passive side will also request and verify a certificate from the connecting peer.
        #
        # To prevent man-in-the-middle attacks this setting is enabled by default.
        #
        # Note: Nodes that are configured with this setting to &#39;on&#39; might not be able to receive messages from nodes that
        # run on older versions of akka-remote. This is because in versions of Akka &lt; 2.4.12 the active side of the remoting
        # connection will not send over certificates even if asked.
        #
        # However, starting with Akka 2.4.12, even with this setting &quot;off&quot;, the active side (TLS client side)
        # will use the given key-store to send over a certificate if asked. A rolling upgrade from versions of
        # Akka &lt; 2.4.12 can therefore work like this:
        #   - upgrade all nodes to an Akka version &gt;= 2.4.12, in the best case the latest version, but keep this setting at &quot;off&quot;
        #   - then switch this flag to &quot;on&quot; and do again a rolling upgrade of all nodes
        # The first step ensures that all nodes will send over a certificate when asked to. The second
        # step will ensure that all nodes finally enforce the secure checking of client certificates.
        require-mutual-authentication = on
      }
    }

    ### Default configuration for the failure injector transport adapter

    gremlin {
      # Enable debug logging of the failure injector transport adapter
      debug = off
    }

    backoff-remote-dispatcher {
      type = Dispatcher
      executor = &quot;fork-join-executor&quot;
      fork-join-executor {
        # Min number of threads to cap factor-based parallelism number to
        parallelism-min = 2
        parallelism-max = 2
      }
    }
  }
}</code></pre>
<a id="config-akka-testkit"></a>
<h3><a href="#akka-testkit" name="akka-testkit" class="anchor"><span class="anchor-link"></span></a>akka-testkit</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-testkit/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">######################################
# Akka Testkit Reference Config File #
######################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

akka {
  test {
    # factor by which to scale timeouts during tests, e.g. to account for shared
    # build system load
    timefactor =  1.0

    # duration of EventFilter.intercept waits after the block is finished until
    # all required messages are received
    filter-leeway = 3s

    # duration to wait in expectMsg and friends outside of within() block
    # by default, will be dilated by the timefactor.
    single-expect-default = 3s

    # duration to wait in expectNoMessage by default,
    # will be dilated by the timefactor.
    expect-no-message-default = 100ms

    # The timeout that is added as an implicit by DefaultTimeout trait
    default-timeout = 5s

    calling-thread-dispatcher {
      type = akka.testkit.CallingThreadDispatcherConfigurator
    }
  }

  actor {

    serializers {
      java-test = &quot;akka.testkit.TestJavaSerializer&quot;
    }

    serialization-identifiers {
      &quot;akka.testkit.TestJavaSerializer&quot; = 23
    }

    serialization-bindings {
      &quot;akka.testkit.JavaSerializable&quot; = java-test
    }
  }
}</code></pre>
<a id="config-cluster-metrics"></a>
<h3><a href="#akka-cluster-metrics" name="akka-cluster-metrics" class="anchor"><span class="anchor-link"></span></a>akka-cluster-metrics</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-cluster-metrics/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">##############################################
# Akka Cluster Metrics Reference Config File #
##############################################

# This is the reference config file that contains all the default settings.
# Make your edits in your application.conf in order to override these settings.

# Sigar provisioning:
#
#  User can provision sigar classes and native library in one of the following ways:
# 
#  1) Use https://github.com/kamon-io/sigar-loader Kamon sigar-loader as a project dependency for the user project.
#  Metrics extension will extract and load sigar library on demand with help of Kamon sigar provisioner.
# 
#  2) Use https://github.com/kamon-io/sigar-loader Kamon sigar-loader as java agent: `java -javaagent:/path/to/sigar-loader.jar`
#  Kamon sigar loader agent will extract and load sigar library during JVM start.
# 
#  3) Place `sigar.jar` on the `classpath` and sigar native library for the o/s on the `java.library.path`
#  User is required to manage both project dependency and library deployment manually.

# Cluster metrics extension.
# Provides periodic statistics collection and publication throughout the cluster.
akka.cluster.metrics {
  # Full path of dispatcher configuration key.
  dispatcher = &quot;akka.actor.default-dispatcher&quot;
  # How long should any actor wait before starting the periodic tasks.
  periodic-tasks-initial-delay = 1s
  # Sigar native library extract location.
  # Use per-application-instance scoped location, such as program working directory.
  native-library-extract-folder = ${user.dir}&quot;/native&quot;
  # Metrics supervisor actor.
  supervisor {
    # Actor name. Example name space: /system/cluster-metrics
    name = &quot;cluster-metrics&quot;
    # Supervision strategy.
    strategy {
      #
      # FQCN of class providing `akka.actor.SupervisorStrategy`.
      # Must have a constructor with signature `&lt;init&gt;(com.typesafe.config.Config)`.
      # Default metrics strategy provider is a configurable extension of `OneForOneStrategy`.
      provider = &quot;akka.cluster.metrics.ClusterMetricsStrategy&quot;
      #
      # Configuration of the default strategy provider.
      # Replace with custom settings when overriding the provider.
      configuration = {
        # Log restart attempts.
        loggingEnabled = true
        # Child actor restart-on-failure window.
        withinTimeRange = 3s
        # Maximum number of restart attempts before child actor is stopped.
        maxNrOfRetries = 3
      }
    }
  }
  # Metrics collector actor.
  collector {
    # Enable or disable metrics collector for load-balancing nodes.
    # Metrics collection can also be controlled at runtime by sending control messages
    # to /system/cluster-metrics actor: `akka.cluster.metrics.{CollectionStartMessage,CollectionStopMessage}`
    enabled = on
    # FQCN of the metrics collector implementation.
    # It must implement `akka.cluster.metrics.MetricsCollector` and
    # have public constructor with akka.actor.ActorSystem parameter.
    # Will try to load in the following order of priority:
    # 1) configured custom collector 2) internal `SigarMetricsCollector` 3) internal `JmxMetricsCollector`
    provider = &quot;&quot;
    # Try all 3 available collector providers, or else fail on the configured custom collector provider.
    fallback = true
    # How often metrics are sampled on a node.
    # Shorter interval will collect the metrics more often.
    # Also controls frequency of the metrics publication to the node system event bus.
    sample-interval = 3s
    # How often a node publishes metrics information to the other nodes in the cluster.
    # Shorter interval will publish the metrics gossip more often.
    gossip-interval = 3s
    # How quickly the exponential weighting of past data is decayed compared to
    # new data. Set lower to increase the bias toward newer values.
    # The relevance of each data sample is halved for every passing half-life
    # duration, i.e. after 4 times the half-life, a data sample’s relevance is
    # reduced to 6% of its original relevance. The initial relevance of a data
    # sample is given by 1 – 0.5 ^ (collect-interval / half-life).
    # See http://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average
    moving-average-half-life = 12s
  }
}

# Cluster metrics extension serializers and routers.
akka.actor {
  # Protobuf serializer for remote cluster metrics messages.
  serializers {
    akka-cluster-metrics = &quot;akka.cluster.metrics.protobuf.MessageSerializer&quot;
  }
  # Interface binding for remote cluster metrics messages.
  serialization-bindings {
    &quot;akka.cluster.metrics.ClusterMetricsMessage&quot; = akka-cluster-metrics
    &quot;akka.cluster.metrics.AdaptiveLoadBalancingPool&quot; = akka-cluster-metrics
    &quot;akka.cluster.metrics.MixMetricsSelector&quot; = akka-cluster-metrics
    &quot;akka.cluster.metrics.CpuMetricsSelector$&quot; = akka-cluster-metrics
    &quot;akka.cluster.metrics.HeapMetricsSelector$&quot; = akka-cluster-metrics
    &quot;akka.cluster.metrics.SystemLoadAverageMetricsSelector$&quot; = akka-cluster-metrics
  }
  # Globally unique metrics extension serializer identifier.
  serialization-identifiers {
    &quot;akka.cluster.metrics.protobuf.MessageSerializer&quot; = 10
  }
  #  Provide routing of messages based on cluster metrics.
  router.type-mapping {
    cluster-metrics-adaptive-pool  = &quot;akka.cluster.metrics.AdaptiveLoadBalancingPool&quot;
    cluster-metrics-adaptive-group = &quot;akka.cluster.metrics.AdaptiveLoadBalancingGroup&quot;
  }
}</code></pre>
<a id="config-cluster-tools"></a>
<h3><a href="#akka-cluster-tools" name="akka-cluster-tools" class="anchor"><span class="anchor-link"></span></a>akka-cluster-tools</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-cluster-tools/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">############################################
# Akka Cluster Tools Reference Config File #
############################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

# //#pub-sub-ext-config
# Settings for the DistributedPubSub extension
akka.cluster.pub-sub {
  # Actor name of the mediator actor, /system/distributedPubSubMediator
  name = distributedPubSubMediator

  # Start the mediator on members tagged with this role.
  # All members are used if undefined or empty.
  role = &quot;&quot;

  # The routing logic to use for &#39;Send&#39;
  # Possible values: random, round-robin, broadcast
  routing-logic = random

  # How often the DistributedPubSubMediator should send out gossip information
  gossip-interval = 1s

  # Removed entries are pruned after this duration
  removed-time-to-live = 120s

  # Maximum number of elements to transfer in one message when synchronizing the registries.
  # Next chunk will be transferred in next round of gossip.
  max-delta-elements = 3000

  # When a message is published to a topic with no subscribers send it to the dead letters.
  send-to-dead-letters-when-no-subscribers = on
  
  # The id of the dispatcher to use for DistributedPubSubMediator actors. 
  # If specified you need to define the settings of the actual dispatcher.
  use-dispatcher = &quot;akka.actor.internal-dispatcher&quot;
}
# //#pub-sub-ext-config

# Protobuf serializer for cluster DistributedPubSubMeditor messages
akka.actor {
  serializers {
    akka-pubsub = &quot;akka.cluster.pubsub.protobuf.DistributedPubSubMessageSerializer&quot;
  }
  serialization-bindings {
    &quot;akka.cluster.pubsub.DistributedPubSubMessage&quot; = akka-pubsub
    &quot;akka.cluster.pubsub.DistributedPubSubMediator$Internal$SendToOneSubscriber&quot; = akka-pubsub
  }
  serialization-identifiers {
    &quot;akka.cluster.pubsub.protobuf.DistributedPubSubMessageSerializer&quot; = 9
  }
}


# //#receptionist-ext-config
# Settings for the ClusterClientReceptionist extension
akka.cluster.client.receptionist {
  # Actor name of the ClusterReceptionist actor, /system/receptionist
  name = receptionist

  # Start the receptionist on members tagged with this role.
  # All members are used if undefined or empty.
  role = &quot;&quot;

  # The receptionist will send this number of contact points to the client
  number-of-contacts = 3

  # The actor that tunnel response messages to the client will be stopped
  # after this time of inactivity.
  response-tunnel-receive-timeout = 30s
  
  # The id of the dispatcher to use for ClusterReceptionist actors.
  # If specified you need to define the settings of the actual dispatcher.
  use-dispatcher = &quot;akka.actor.internal-dispatcher&quot;

  # How often failure detection heartbeat messages should be received for
  # each ClusterClient
  heartbeat-interval = 2s

  # Number of potentially lost/delayed heartbeats that will be
  # accepted before considering it to be an anomaly.
  # The ClusterReceptionist is using the akka.remote.DeadlineFailureDetector, which
  # will trigger if there are no heartbeats within the duration
  # heartbeat-interval + acceptable-heartbeat-pause, i.e. 15 seconds with
  # the default settings.
  acceptable-heartbeat-pause = 13s

  # Failure detection checking interval for checking all ClusterClients
  failure-detection-interval = 2s
}
# //#receptionist-ext-config

# //#cluster-client-config
# Settings for the ClusterClient
akka.cluster.client {
  # Actor paths of the ClusterReceptionist actors on the servers (cluster nodes)
  # that the client will try to contact initially. It is mandatory to specify
  # at least one initial contact. 
  # Comma separated full actor paths defined by a string on the form of
  # &quot;akka://system@hostname:port/system/receptionist&quot;
  initial-contacts = []
  
  # Interval at which the client retries to establish contact with one of 
  # ClusterReceptionist on the servers (cluster nodes)
  establishing-get-contacts-interval = 3s
  
  # Interval at which the client will ask the ClusterReceptionist for
  # new contact points to be used for next reconnect.
  refresh-contacts-interval = 60s
  
  # How often failure detection heartbeat messages should be sent
  heartbeat-interval = 2s
  
  # Number of potentially lost/delayed heartbeats that will be
  # accepted before considering it to be an anomaly.
  # The ClusterClient is using the akka.remote.DeadlineFailureDetector, which
  # will trigger if there are no heartbeats within the duration 
  # heartbeat-interval + acceptable-heartbeat-pause, i.e. 15 seconds with
  # the default settings.
  acceptable-heartbeat-pause = 13s
  
  # If connection to the receptionist is not established the client will buffer
  # this number of messages and deliver them the connection is established.
  # When the buffer is full old messages will be dropped when new messages are sent
  # via the client. Use 0 to disable buffering, i.e. messages will be dropped
  # immediately if the location of the singleton is unknown.
  # Maximum allowed buffer size is 10000.
  buffer-size = 1000

  # If connection to the receiptionist is lost and the client has not been
  # able to acquire a new connection for this long the client will stop itself.
  # This duration makes it possible to watch the cluster client and react on a more permanent
  # loss of connection with the cluster, for example by accessing some kind of
  # service registry for an updated set of initial contacts to start a new cluster client with.
  # If this is not wanted it can be set to &quot;off&quot; to disable the timeout and retry
  # forever.
  reconnect-timeout = off
}
# //#cluster-client-config

# Protobuf serializer for ClusterClient messages
akka.actor {
  serializers {
    akka-cluster-client = &quot;akka.cluster.client.protobuf.ClusterClientMessageSerializer&quot;
  }
  serialization-bindings {
    &quot;akka.cluster.client.ClusterClientMessage&quot; = akka-cluster-client
  }
  serialization-identifiers {
    &quot;akka.cluster.client.protobuf.ClusterClientMessageSerializer&quot; = 15
  }
}

# //#singleton-config
akka.cluster.singleton {
  # The actor name of the child singleton actor.
  singleton-name = &quot;singleton&quot;
  
  # Singleton among the nodes tagged with specified role.
  # If the role is not specified it&#39;s a singleton among all nodes in the cluster.
  role = &quot;&quot;
  
  # When a node is becoming oldest it sends hand-over request to previous oldest, 
  # that might be leaving the cluster. This is retried with this interval until 
  # the previous oldest confirms that the hand over has started or the previous 
  # oldest member is removed from the cluster (+ akka.cluster.down-removal-margin).
  hand-over-retry-interval = 1s
  
  # The number of retries are derived from hand-over-retry-interval and
  # akka.cluster.down-removal-margin (or ClusterSingletonManagerSettings.removalMargin),
  # but it will never be less than this property.
  # After the hand over retries and it&#39;s still not able to exchange the hand over messages
  # with the previous oldest it will restart itself by throwing ClusterSingletonManagerIsStuck,
  # to start from a clean state. After that it will still not start the singleton instance
  # until the previous oldest node has been removed from the cluster.
  # On the other side, on the previous oldest node, the same number of retries - 3 are used
  # and after that the singleton instance is stopped.
  # For large clusters it might be necessary to increase this to avoid too early timeouts while
  # gossip dissemination of the Leaving to Exiting phase occurs. For normal leaving scenarios
  # it will not be a quicker hand over by reducing this value, but in extreme failure scenarios
  # the recovery might be faster.
  min-number-of-hand-over-retries = 15

  # Config path of the lease to be taken before creating the singleton actor
  # if the lease is lost then the actor is restarted and it will need to re-acquire the lease
  # the default is no lease
  use-lease = &quot;&quot;

  # The interval between retries for acquiring the lease
  lease-retry-interval = 5s
}
# //#singleton-config

# //#singleton-proxy-config
akka.cluster.singleton-proxy {
  # The actor name of the singleton actor that is started by the ClusterSingletonManager
  singleton-name = ${akka.cluster.singleton.singleton-name}
  
  # The role of the cluster nodes where the singleton can be deployed. 
  # If the role is not specified then any node will do.
  role = &quot;&quot;
  
  # Interval at which the proxy will try to resolve the singleton instance.
  singleton-identification-interval = 1s
  
  # If the location of the singleton is unknown the proxy will buffer this
  # number of messages and deliver them when the singleton is identified. 
  # When the buffer is full old messages will be dropped when new messages are
  # sent via the proxy.
  # Use 0 to disable buffering, i.e. messages will be dropped immediately if
  # the location of the singleton is unknown.
  # Maximum allowed buffer size is 10000.
  buffer-size = 1000 
}
# //#singleton-proxy-config

# Serializer for cluster ClusterSingleton messages
akka.actor {
  serializers {
    akka-singleton = &quot;akka.cluster.singleton.protobuf.ClusterSingletonMessageSerializer&quot;
  }
  serialization-bindings {
    &quot;akka.cluster.singleton.ClusterSingletonMessage&quot; = akka-singleton
  }
  serialization-identifiers {
    &quot;akka.cluster.singleton.protobuf.ClusterSingletonMessageSerializer&quot; = 14
  }
}</code></pre>
<a id="config-cluster-sharding-typed"></a>
<h3><a href="#akka-cluster-sharding-typed" name="akka-cluster-sharding-typed" class="anchor"><span class="anchor-link"></span></a>akka-cluster-sharding-typed</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-cluster-sharding-typed/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf"><br/># //#sharding-ext-config
# //#number-of-shards
akka.cluster.sharding {
  # Number of shards used by the default HashCodeMessageExtractor
  # when no other message extractor is defined. This value must be
  # the same for all nodes in the cluster and that is verified by
  # configuration check when joining. Changing the value requires
  # stopping all nodes in the cluster.
  number-of-shards = 1000
}
# //#number-of-shards
# //#sharding-ext-config

akka.cluster.configuration-compatibility-check.checkers {
  akka-cluster-sharding-hash-extractor = &quot;akka.cluster.sharding.typed.internal.JoinConfigCompatCheckerClusterSharding&quot;
}

akka.actor {
  serializers {
    typed-sharding = &quot;akka.cluster.sharding.typed.internal.ShardingSerializer&quot;
  }
  serialization-identifiers {
    &quot;akka.cluster.sharding.typed.internal.ShardingSerializer&quot; = 25
  }
  serialization-bindings {
    &quot;akka.cluster.sharding.typed.ShardingEnvelope&quot; = typed-sharding
  }
}
</code></pre>
<a id="config-cluster-sharding"></a>
<h3><a href="#akka-cluster-sharding" name="akka-cluster-sharding" class="anchor"><span class="anchor-link"></span></a>akka-cluster-sharding</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-cluster-sharding/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">###############################################
# Akka Cluster Sharding Reference Config File #
###############################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.


# //#sharding-ext-config
# Settings for the ClusterShardingExtension
akka.cluster.sharding {

  # The extension creates a top level actor with this name in top level system scope,
  # e.g. &#39;/system/sharding&#39;
  guardian-name = sharding

  # Specifies that entities runs on cluster nodes with a specific role.
  # If the role is not specified (or empty) all nodes in the cluster are used.
  role = &quot;&quot;

  # When this is set to &#39;on&#39; the active entity actors will automatically be restarted
  # upon Shard restart. i.e. if the Shard is started on a different ShardRegion
  # due to rebalance or crash.
  remember-entities = off

  # Set this to a time duration to have sharding passivate entities when they have not
  # received any message in this length of time. Set to &#39;off&#39; to disable.
  # It is always disabled if `remember-entities` is enabled.
  passivate-idle-entity-after = 120s

  # If the coordinator can&#39;t store state changes it will be stopped
  # and started again after this duration, with an exponential back-off
  # of up to 5 times this duration.
  coordinator-failure-backoff = 5 s

  # The ShardRegion retries registration and shard location requests to the
  # ShardCoordinator with this interval if it does not reply.
  retry-interval = 2 s

  # Maximum number of messages that are buffered by a ShardRegion actor.
  buffer-size = 100000

  # Timeout of the shard rebalancing process.
  # Additionally, if an entity doesn&#39;t handle the stopMessage
  # after (handoff-timeout - 5.seconds).max(1.second) it will be stopped forcefully
  handoff-timeout = 60 s

  # Time given to a region to acknowledge it&#39;s hosting a shard.
  shard-start-timeout = 10 s

  # If the shard is remembering entities and can&#39;t store state changes
  # will be stopped and then started again after this duration. Any messages
  # sent to an affected entity may be lost in this process.
  shard-failure-backoff = 10 s

  # If the shard is remembering entities and an entity stops itself without
  # using passivate. The entity will be restarted after this duration or when
  # the next message for it is received, which ever occurs first.
  entity-restart-backoff = 10 s

  # Rebalance check is performed periodically with this interval.
  rebalance-interval = 10 s

  # Absolute path to the journal plugin configuration entity that is to be
  # used for the internal persistence of ClusterSharding. If not defined
  # the default journal plugin is used. Note that this is not related to
  # persistence used by the entity actors.
  # Only used when state-store-mode=persistence
  journal-plugin-id = &quot;&quot;

  # Absolute path to the snapshot plugin configuration entity that is to be
  # used for the internal persistence of ClusterSharding. If not defined
  # the default snapshot plugin is used. Note that this is not related to
  # persistence used by the entity actors.
  # Only used when state-store-mode=persistence
  snapshot-plugin-id = &quot;&quot;

  # Defines how the coordinator stores its state. Same is also used by the
  # shards for rememberEntities.
  # Valid values are &quot;ddata&quot; or &quot;persistence&quot;. 
  state-store-mode = &quot;ddata&quot;

  # The shard saves persistent snapshots after this number of persistent
  # events. Snapshots are used to reduce recovery times.
  # Only used when state-store-mode=persistence
  snapshot-after = 1000

  # The shard deletes persistent events (messages and snapshots) after doing snapshot
  # keeping this number of old persistent batches.
  # Batch is of size `snapshot-after`.
  # When set to 0 after snapshot is successfully done all events with equal or lower sequence number will be deleted.
  # Default value of 2 leaves last maximum 2*`snapshot-after` events and 3 snapshots (2 old ones + latest snapshot)
  keep-nr-of-batches = 2

  # Setting for the default shard allocation strategy
  least-shard-allocation-strategy {
    # Threshold of how large the difference between most and least number of
    # allocated shards must be to begin the rebalancing.
    # The difference between number of shards in the region with most shards and
    # the region with least shards must be greater than (&gt;) the `rebalanceThreshold`
    # for the rebalance to occur.
    # It is also the maximum number of shards that will start rebalancing per rebalance-interval
    # 1 gives the best distribution and therefore typically the best choice.
    # Increasing the threshold can result in quicker rebalance but has the
    # drawback of increased difference between number of shards (and therefore load)
    # on different nodes before rebalance will occur.
    rebalance-threshold = 1

    # The number of ongoing rebalancing processes is limited to this number.
    max-simultaneous-rebalance = 3
  }

  external-shard-allocation-strategy {
    # How long to wait for the client to persist an allocation to ddata or get a all shard locations
    client-timeout = 5s
  }

  # Timeout of waiting the initial distributed state for the shard coordinator (an initial state will be queried again if the timeout happened)
  # and for a shard to get its state when remembered entities is enabled
  # The read from ddata is a ReadMajority, for small clusters (&lt; majority-min-cap) every node needs to respond
  # so is more likely to time out if there are nodes restarting e.g. when there is a rolling re-deploy happening
  # Only used when state-store-mode=ddata
  waiting-for-state-timeout = 2 s

  # Timeout of waiting for update the distributed state (update will be retried if the timeout happened)
  # Only used when state-store-mode=ddata
  updating-state-timeout = 5 s

  # Timeout to wait for querying all shards for a given `ShardRegion`.
  shard-region-query-timeout = 3 s

  # The shard uses this strategy to determines how to recover the underlying entity actors. The strategy is only used
  # by the persistent shard when rebalancing or restarting. The value can either be &quot;all&quot; or &quot;constant&quot;. The &quot;all&quot;
  # strategy start all the underlying entity actors at the same time. The constant strategy will start the underlying
  # entity actors at a fix rate. The default strategy &quot;all&quot;.
  entity-recovery-strategy = &quot;all&quot;

  # Default settings for the constant rate entity recovery strategy
  entity-recovery-constant-rate-strategy {
    # Sets the frequency at which a batch of entity actors is started.
    frequency = 100 ms
    # Sets the number of entity actors to be restart at a particular interval
    number-of-entities = 5
  }

  # Settings for the coordinator singleton. Same layout as akka.cluster.singleton.
  # The &quot;role&quot; of the singleton configuration is not used. The singleton role will
  # be the same as &quot;akka.cluster.sharding.role&quot;.
  # A lease can be configured in these settings for the coordinator singleton
  coordinator-singleton = ${akka.cluster.singleton}
  
  # Settings for the Distributed Data replicator. 
  # Same layout as akka.cluster.distributed-data.
  # The &quot;role&quot; of the distributed-data configuration is not used. The distributed-data
  # role will be the same as &quot;akka.cluster.sharding.role&quot;.
  # Note that there is one Replicator per role and it&#39;s not possible
  # to have different distributed-data settings for different sharding entity types.
  # Only used when state-store-mode=ddata
  distributed-data = ${akka.cluster.distributed-data}
  distributed-data {
    # minCap parameter to MajorityWrite and MajorityRead consistency level.
    majority-min-cap = 5
    durable.keys = [&quot;shard-*&quot;]
    
    # When using many entities with &quot;remember entities&quot; the Gossip message
    # can become to large if including to many in same message. Limit to
    # the same number as the number of ORSet per shard.
    max-delta-elements = 5
    
  }

  # The id of the dispatcher to use for ClusterSharding actors.
  # If specified you need to define the settings of the actual dispatcher.
  # This dispatcher for the entity actors is defined by the user provided
  # Props, i.e. this dispatcher is not used for the entity actors.
  use-dispatcher = &quot;akka.actor.internal-dispatcher&quot;

  # Config path of the lease that each shard must acquire before starting entity actors
  # default is no lease
  # A lease can also be used for the singleton coordinator by settings it in the coordinator-singleton properties
  use-lease = &quot;&quot;

  # The interval between retries for acquiring the lease
  lease-retry-interval = 5s
}
# //#sharding-ext-config

akka.cluster {
  configuration-compatibility-check {
    checkers {
      akka-cluster-sharding = &quot;akka.cluster.sharding.JoinConfigCompatCheckSharding&quot;
    }
  }
}

# Protobuf serializer for Cluster Sharding messages
akka.actor {
  serializers {
    akka-sharding = &quot;akka.cluster.sharding.protobuf.ClusterShardingMessageSerializer&quot;
  }
  serialization-bindings {
    &quot;akka.cluster.sharding.ClusterShardingSerializable&quot; = akka-sharding
  }
  serialization-identifiers {
    &quot;akka.cluster.sharding.protobuf.ClusterShardingMessageSerializer&quot; = 13
  }
}</code></pre>
<a id="config-distributed-data"></a>
<h3><a href="#akka-distributed-data" name="akka-distributed-data" class="anchor"><span class="anchor-link"></span></a>akka-distributed-data</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-distributed-data/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">##############################################
# Akka Distributed DataReference Config File #
##############################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.


#//#distributed-data
# Settings for the DistributedData extension
akka.cluster.distributed-data {
  # Actor name of the Replicator actor, /system/ddataReplicator
  name = ddataReplicator

  # Replicas are running on members tagged with this role.
  # All members are used if undefined or empty.
  role = &quot;&quot;

  # How often the Replicator should send out gossip information
  gossip-interval = 2 s
  
  # How often the subscribers will be notified of changes, if any
  notify-subscribers-interval = 500 ms

  # Maximum number of entries to transfer in one gossip message when synchronizing
  # the replicas. Next chunk will be transferred in next round of gossip.
  max-delta-elements = 500
  
  # The id of the dispatcher to use for Replicator actors.
  # If specified you need to define the settings of the actual dispatcher.
  use-dispatcher = &quot;akka.actor.internal-dispatcher&quot;

  # How often the Replicator checks for pruning of data associated with
  # removed cluster nodes. If this is set to &#39;off&#39; the pruning feature will
  # be completely disabled.
  pruning-interval = 120 s
  
  # How long time it takes to spread the data to all other replica nodes.
  # This is used when initiating and completing the pruning process of data associated
  # with removed cluster nodes. The time measurement is stopped when any replica is 
  # unreachable, but it&#39;s still recommended to configure this with certain margin.
  # It should be in the magnitude of minutes even though typical dissemination time
  # is shorter (grows logarithmic with number of nodes). There is no advantage of 
  # setting this too low. Setting it to large value will delay the pruning process.
  max-pruning-dissemination = 300 s
  
  # The markers of that pruning has been performed for a removed node are kept for this
  # time and thereafter removed. If and old data entry that was never pruned is somehow
  # injected and merged with existing data after this time the value will not be correct.
  # This would be possible (although unlikely) in the case of a long network partition.
  # It should be in the magnitude of hours. For durable data it is configured by 
  # &#39;akka.cluster.distributed-data.durable.pruning-marker-time-to-live&#39;.
 pruning-marker-time-to-live = 6 h
  
  # Serialized Write and Read messages are cached when they are sent to 
  # several nodes. If no further activity they are removed from the cache
  # after this duration.
  serializer-cache-time-to-live = 10s
  
  # Settings for delta-CRDT
  delta-crdt {
    # enable or disable delta-CRDT replication
    enabled = on
    
    # Some complex deltas grow in size for each update and above this
    # threshold such deltas are discarded and sent as full state instead.
    # This is number of elements or similar size hint, not size in bytes.
    max-delta-size = 50
  }
  
  durable {
    # List of keys that are durable. Prefix matching is supported by using * at the
    # end of a key.  
    keys = []
    
    # The markers of that pruning has been performed for a removed node are kept for this
    # time and thereafter removed. If and old data entry that was never pruned is
    # injected and merged with existing data after this time the value will not be correct.
    # This would be possible if replica with durable data didn&#39;t participate in the pruning
    # (e.g. it was shutdown) and later started after this time. A durable replica should not 
    # be stopped for longer time than this duration and if it is joining again after this
    # duration its data should first be manually removed (from the lmdb directory).
    # It should be in the magnitude of days. Note that there is a corresponding setting
    # for non-durable data: &#39;akka.cluster.distributed-data.pruning-marker-time-to-live&#39;.
    pruning-marker-time-to-live = 10 d
    
    # Fully qualified class name of the durable store actor. It must be a subclass
    # of akka.actor.Actor and handle the protocol defined in 
    # akka.cluster.ddata.DurableStore. The class must have a constructor with 
    # com.typesafe.config.Config parameter.
    store-actor-class = akka.cluster.ddata.LmdbDurableStore
    
    use-dispatcher = akka.cluster.distributed-data.durable.pinned-store
    
    pinned-store {
      executor = thread-pool-executor
      type = PinnedDispatcher
    }
    
    # Config for the LmdbDurableStore
    lmdb {
      # Directory of LMDB file. There are two options:
      # 1. A relative or absolute path to a directory that ends with &#39;ddata&#39;
      #    the full name of the directory will contain name of the ActorSystem
      #    and its remote port.
      # 2. Otherwise the path is used as is, as a relative or absolute path to
      #    a directory.
      #
      # When running in production you may want to configure this to a specific
      # path (alt 2), since the default directory contains the remote port of the
      # actor system to make the name unique. If using a dynamically assigned 
      # port (0) it will be different each time and the previously stored data 
      # will not be loaded.
      dir = &quot;ddata&quot;
      
      # Size in bytes of the memory mapped file.
      map-size = 100 MiB
      
      # Accumulate changes before storing improves performance with the
      # risk of losing the last writes if the JVM crashes.
      # The interval is by default set to &#39;off&#39; to write each update immediately.
      # Enabling write behind by specifying a duration, e.g. 200ms, is especially 
      # efficient when performing many writes to the same key, because it is only 
      # the last value for each key that will be serialized and stored.  
      # write-behind-interval = 200 ms
      write-behind-interval = off
    }
  }
  
}
#//#distributed-data

# Protobuf serializer for cluster DistributedData messages
akka.actor {
  serializers {
    akka-data-replication = &quot;akka.cluster.ddata.protobuf.ReplicatorMessageSerializer&quot;
    akka-replicated-data = &quot;akka.cluster.ddata.protobuf.ReplicatedDataSerializer&quot;
  }
  serialization-bindings {
    &quot;akka.cluster.ddata.Replicator$ReplicatorMessage&quot; = akka-data-replication
    &quot;akka.cluster.ddata.ReplicatedDataSerialization&quot; = akka-replicated-data
  }
  serialization-identifiers {
    &quot;akka.cluster.ddata.protobuf.ReplicatedDataSerializer&quot; = 11
    &quot;akka.cluster.ddata.protobuf.ReplicatorMessageSerializer&quot; = 12
  }
}</code></pre>
<a id="config-akka-stream"></a>
<h3><a href="#akka-stream" name="akka-stream" class="anchor"><span class="anchor-link"></span></a>akka-stream</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-stream/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">#####################################
# Akka Stream Reference Config File #
#####################################

# eager creation of the system wide materializer
akka.library-extensions += &quot;akka.stream.SystemMaterializer&quot;
akka {
  stream {

    # Default materializer settings
    materializer {

      # Initial size of buffers used in stream elements
      initial-input-buffer-size = 4
      # Maximum size of buffers used in stream elements
      max-input-buffer-size = 16

      # Fully qualified config path which holds the dispatcher configuration
      # or full dispatcher configuration to be used by ActorMaterializer when creating Actors.
      dispatcher = &quot;akka.actor.default-dispatcher&quot;

      # Fully qualified config path which holds the dispatcher configuration
      # or full dispatcher configuration to be used by stream operators that
      # perform blocking operations
      blocking-io-dispatcher = &quot;akka.actor.default-blocking-io-dispatcher&quot;

      # Cleanup leaked publishers and subscribers when they are not used within a given
      # deadline
      subscription-timeout {
        # when the subscription timeout is reached one of the following strategies on
        # the &quot;stale&quot; publisher:
        # cancel - cancel it (via `onError` or subscribing to the publisher and
        #          `cancel()`ing the subscription right away
        # warn   - log a warning statement about the stale element (then drop the
        #          reference to it)
        # noop   - do nothing (not recommended)
        mode = cancel

        # time after which a subscriber / publisher is considered stale and eligible
        # for cancelation (see `akka.stream.subscription-timeout.mode`)
        timeout = 5s
      }

      # Enable additional troubleshooting logging at DEBUG log level
      debug-logging = off

      # Maximum number of elements emitted in batch if downstream signals large demand
      output-burst-limit = 1000

      # Enable automatic fusing of all graphs that are run. For short-lived streams
      # this may cause an initial runtime overhead, but most of the time fusing is
      # desirable since it reduces the number of Actors that are created.
      # Deprecated, since Akka 2.5.0, setting does not have any effect.
      auto-fusing = on

      # Those stream elements which have explicit buffers (like mapAsync, mapAsyncUnordered,
      # buffer, flatMapMerge, Source.actorRef, Source.queue, etc.) will preallocate a fixed
      # buffer upon stream materialization if the requested buffer size is less than this
      # configuration parameter. The default is very high because failing early is better
      # than failing under load.
      #
      # Buffers sized larger than this will dynamically grow/shrink and consume more memory
      # per element than the fixed size buffers.
      max-fixed-buffer-size = 1000000000

      # Maximum number of sync messages that actor can process for stream to substream communication.
      # Parameter allows to interrupt synchronous processing to get upstream/downstream messages.
      # Allows to accelerate message processing that happening within same actor but keep system responsive.
      sync-processing-limit = 1000

      debug {
        # Enables the fuzzing mode which increases the chance of race conditions
        # by aggressively reordering events and making certain operations more
        # concurrent than usual.
        # This setting is for testing purposes, NEVER enable this in a production
        # environment!
        # To get the best results, try combining this setting with a throughput
        # of 1 on the corresponding dispatchers.
        fuzzing-mode = off
      }

      io.tcp {
        # The outgoing bytes are accumulated in a buffer while waiting for acknowledgment
        # of pending write. This improves throughput for small messages (frames) without
        # sacrificing latency. While waiting for the ack the stage will eagerly pull
        # from upstream until the buffer exceeds this size. That means that the buffer may hold
        # slightly more bytes than this limit (at most one element more). It can be set to 0
        # to disable the usage of the buffer.
        write-buffer-size = 16 KiB
      }

      # Time to wait for async materializer creation before throwing an exception
      creation-timeout = 20 seconds

      //#stream-ref
      # configure defaults for SourceRef and SinkRef
      stream-ref {
        # Buffer of a SinkRef that is used to batch Request elements from the other side of the stream ref
        #
        # The buffer will be attempted to be filled eagerly even while the local stage did not request elements,
        # because the delay of requesting over network boundaries is much higher.
        buffer-capacity = 32

        # Demand is signalled by sending a cumulative demand message (&quot;requesting messages until the n-th sequence number)
        # Using a cumulative demand model allows us to re-deliver the demand message in case of message loss (which should
        # be very rare in any case, yet possible -- mostly under connection break-down and re-establishment).
        #
        # The semantics of handling and updating the demand however are in-line with what Reactive Streams dictates.
        #
        # In normal operation, demand is signalled in response to arriving elements, however if no new elements arrive
        # within `demand-redelivery-interval` a re-delivery of the demand will be triggered, assuming that it may have gotten lost.
        demand-redelivery-interval = 1 second

        # Subscription timeout, during which the &quot;remote side&quot; MUST subscribe (materialize) the handed out stream ref.
        # This timeout does not have to be very low in normal situations, since the remote side may also need to
        # prepare things before it is ready to materialize the reference. However the timeout is needed to avoid leaking
        # in-active streams which are never subscribed to.
        subscription-timeout = 30 seconds

        # In order to guard the receiving end of a stream ref from never terminating (since awaiting a Completion or Failed
        # message) after / before a Terminated is seen, a special timeout is applied once Terminated is received by it.
        # This allows us to terminate stream refs that have been targeted to other nodes which are Downed, and as such the
        # other side of the stream ref would never send the &quot;final&quot; terminal message.
        #
        # The timeout specifically means the time between the Terminated signal being received and when the local SourceRef
        # determines to fail itself, assuming there was message loss or a complete partition of the completion signal.
        final-termination-signal-deadline = 2 seconds
      }
      //#stream-ref
    }

    # Deprecated, left here to not break Akka HTTP which refers to it
    blocking-io-dispatcher = &quot;akka.actor.default-blocking-io-dispatcher&quot;

    # Deprecated, will not be used unless user code refer to it, use &#39;akka.stream.materializer.blocking-io-dispatcher&#39;
    # instead, or if from code, prefer the &#39;ActorAttributes.IODispatcher&#39; attribute
    default-blocking-io-dispatcher = &quot;akka.actor.default-blocking-io-dispatcher&quot;
  }

  # configure overrides to ssl-configuration here (to be used by akka-streams, and akka-http – i.e. when serving https connections)
  ssl-config {
    protocol = &quot;TLSv1.2&quot;
  }

  actor {

    serializers {
      akka-stream-ref = &quot;akka.stream.serialization.StreamRefSerializer&quot;
    }

    serialization-bindings {
      &quot;akka.stream.SinkRef&quot;                           = akka-stream-ref
      &quot;akka.stream.SourceRef&quot;                         = akka-stream-ref
      &quot;akka.stream.impl.streamref.StreamRefsProtocol&quot; = akka-stream-ref
    }

    serialization-identifiers {
      &quot;akka.stream.serialization.StreamRefSerializer&quot; = 30
    }
  }
}

# ssl configuration
# folded in from former ssl-config-akka module
ssl-config {
  logger = &quot;com.typesafe.sslconfig.akka.util.AkkaLoggerBridge&quot;
}</code></pre>
<a id="config-akka-stream-testkit"></a>
<h3><a href="#akka-stream-testkit" name="akka-stream-testkit" class="anchor"><span class="anchor-link"></span></a>akka-stream-testkit</h3>
<pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-stream-testkit/src/main/resources/reference.conf" target="_blank" title="Go to snippet source"></a><code class="language-conf">akka.stream.testkit {
  all-stages-stopped-timeout = 5 s
}</code></pre>
</div>
</article>
<div class="row">
<div class="small-12 column">
<section class="nav-prev-next row">
<div class="nav-prev small-6 column">
<a href="../general/configuration.html"><i class="icon-prev"></i> <span class="link-prev">Configuration</span></a>
</div>
<div class="nav-next small-6 column clearfix">
<a class="float-right" href="../typed/index.html">Actors <i class="icon-next"></i></a>
</div>
</section>
</div>
</div>
<div class="source-github row">
Found an error in this documentation? The source code for this page can be found <a href="https://github.com/akka/akka/tree/v2.6.3+1-dc0ae30c+20200312-2058/akka-docs-zh/src/main/paradox/general/configuration-reference.md">here</a>.
Please feel free to edit and contribute a pull request.
</div>

<footer class="page-footer row clearfix">
<img class="akka-icon float-left show-for-medium" src="../images/akka-icon.svg" />
<section class="copyright">
<div>Akka is Open Source and available under the Apache 2 License.</div>
<p class="legal">
&copy; 2011-2020 <a href="https://www.lightbend.com" target="_blank">Lightbend, Inc.</a> |
<a href="https://www.lightbend.com/legal/licenses" target="_blank">Licenses</a> |
<a href="https://www.lightbend.com/legal/terms" target="_blank">Terms</a> |
<a href="https://www.lightbend.com/legal/privacy" target="_blank">Privacy Policy</a> |
<a href="https://akka.io/cookie/" target="_blank">Cookie Listing</a> |
<a class="optanon-toggle-display">Cookie Settings</a>
</p>
</section>

</footer>
</section>
</main>
</div>

<script type="text/javascript" src="../js/scrollsneak.js"></script>
<script type="text/javascript">jQuery(document).foundation();</script>
<script type="text/javascript" src="../js/groups.js"></script>
<script type="text/javascript" src="../js/page.js"></script>
<script type="text/javascript" src="../js/magellan.js"></script>
<script type="text/javascript" src="../js/metadata-toggle.js"></script>

<style type="text/css">@import "../lib/prettify/prettify.css";</style>
<script type="text/javascript" src="../lib/prettify/prettify.js"></script>
<script type="text/javascript" src="../lib/prettify/lang-scala.js"></script>
<script type="text/javascript">//<![CDATA[
jQuery(function(){window.prettyPrint && prettyPrint()});
//]]></script>
<!-- Algolia docs search -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/2/docsearch.min.js"></script>
<style>.algolia-autocomplete { display: block !important }</style>
<script type="text/javascript">
docsearch({
apiKey: '543bad5ad786495d9ccd445ed34ed082',
indexName: 'akka_io',
inputSelector: '#search',
algoliaOptions: {
hitsPerPage: 5
}
});

docsearch({
apiKey: '543bad5ad786495d9ccd445ed34ed082',
indexName: 'akka_io',
inputSelector: '#overlay-search',
algoliaOptions: {
hitsPerPage: 5
}
});

// set up "/" as global shortcut for focusing on search
jQuery(document).keypress(function (event) {
if (event.keyCode == 47) {
jQuery("#search").focus();
return false; // swallow key event, otherwise the / char would be input into the search box
}
});
</script>

<script type="text/javascript" src="../assets/js/warnOldDocs.js"></script>
<script type="text/javascript" src="../assets/js/scalafiddle.js"></script>


</body>
</html>
